---
title: "Assessing the predictive ability of Demoniche"
author: "Fiona Spooner"
date: "September 6, 2017"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
---

```{r, eval=FALSE, message=FALSE}
install.packages('climates',,'http://www.rforge.net/')
install.packages("dismo")
install.packages("maps")
install.packages("mapdata")
install.packages("popbio")
install.packages("demoniche", repos="http://R-Forge.R-project.org")

```

```{r, message= FALSE, warning=FALSE}
library(zoo)
library(dismo)
```

#####Bioclim Variables 

Creating the 19 bioclim variables for each year between 1950 & 2016 for Europe using the E-OBS dataset - downloaded from http://www.ecad.eu/download/ensembles/download.php

```{r, eval=FALSE, message=FALSE, warning=FALSE}
rr<-brick(paste(wd, "/rr_0.25deg_reg_v15.0.nc", sep="")) #precipitation
tg<-brick(paste(wd, "/tg_0.25deg_reg_v15.0.nc", sep="")) #mean temp
tn<-brick(paste(wd, "/tn_0.25deg_reg_v15.0.nc", sep="")) #min temp
tx<-brick(paste(wd, "/tx_0.25deg_reg_v15.0.nc", sep="")) #max temp
#dates<-as.Date((gsub("X", "",names(rr))), format="%Y.%m.%d")


rr_mon<-zApply(rr, by=as.yearmon, fun = mean)
tg_mon<-zApply(tg, by=as.yearmon, fun = mean)
tn_mon<-zApply(tn, by=as.yearmon, fun = mean)
tx_mon<-zApply(tx, by=as.yearmon, fun = mean)

jans<-seq(1,804, by=12)
years<-as.character(1950:2016)

for (i in 1:length(years)){
  jan_sel<-jans[i]
  dec_sel<-jan_sel+11
  bio_vars_all<-biovars(rr_mon[[jan_sel:dec_sel]], tn_mon[[jan_sel:dec_sel]], tx_mon[[jan_sel:dec_sel]])  
  writeRaster(bio_vars_all, paste("C:/Users/Fiona/Documents/PhD/PhD_Method/Bioclim/", years[i],"_bioclim_variable_stack.tif", sep=""), overwrite=T)
  print(years[i])
  }
```

####Species distribution modelling with dismo

Extracting Alpine ibex (*Capra ibex*) data from GBIF and with additional locations added from the LPI dataset. These points are then formatted to a SpatialPointsDataFrame.
```{r, cache=TRUE, message= FALSE, warning=FALSE}
library(dismo)
library(demoniche)
library(maps)
library(mapdata)
library(rgeos)
```

Extracting Alpine ibex data from GBIF and cleaning the data so that only points from the Alps remain.

```{r, cache=TRUE, message= FALSE, warning=FALSE}

wd<- getwd()
capra <-gbif(genus ="Capra", species = "ibex")
capgeo <- subset(capra, !is.na(lon) & !is.na(lat) & (lon!="NA" & lat !="NA") | year!="NA") 
dups <- duplicated(capgeo[, c("lon", "lat")])
capg <-capgeo[!dups, ]
capg2 <- capg[capg$lon > 0 & capg$lon<16 & capg$lat > 43 & capg$lat < 47.9 & capg$year>=2006, ] 
capg2<-data.frame(capg2$lon,capg2$lat)
colnames(capg2)<-c("Longitude", "Latitude")

species<-"Capra_ibex"
df2<-read.csv("LPI_pops_20160523_edited.csv")
pyr<-subset(df2, Binomial ==species & Specific_location==1)    #record 11470 had wrong longitude - in Russia!
pyrs<-pyr[,c("Longitude","Latitude")]
capg2<-rbind(capg2, pyrs)
capg2<-na.omit(capg2)
capg2$presence<-rep(1)
capg2$ID<-1:nrow(capg2)

capc<-as.matrix(capg2[ , c( "Longitude","Latitude", "presence")])
capc<-matrix(capc[complete.cases(capc)], ncol=3)
xy<-as.matrix(capc[,c(1,2)])
df<-data.frame(capc[,3])

write.csv(df, "Capra_ibex_gbif.csv")
```

```{r}
df<-read.csv("Capra_ibex_gbif.csv")

sp<-SpatialPointsDataFrame(coords=xy, data=df)
x <- circles(sp, d=50000, lonlat=TRUE)
pol <- polygons(x)
```

Mapping the occurence points

```{r, message=FALSE, warning=FALSE}
e<-extent(sp)
e_big<-e+4
maps:::map('world',c('Italy', 'Switzerland', 'Austria', 'Monaco','Liechtenstein','Germany', 'Slovenia', 'France'),  col="light grey", fill=T, xlim=c(e_big[1],e_big[2]), ylim=c(e_big[3],e_big[4]))
plot(pol,add=T)
points(sp, col="red", pch=20)

```

Creating the 2006-2016 average for each bioclim variable and then selecting out the layers we want to use in the model:

*	Bioclim 1 â Annual mean temperature

*	Bioclim 5 â Max temperature of the warmest month

*	Bioclim 6 â Min temperature of the coldest month

*	Bioclim 13 â Precipitation of the wettest month

*	Bioclim 15 â Precipitation seasonality (coefficient of variation)

*	Bioclim 18 â Precipitation of warmest quarter

*	Bioclim 19 â Precipitation of coldest quarter

Snow depth seems to be an important predictor for alpine ibex but I have struggled to find historical data on this. Existing papers are based on historical data from one weather station, which means there is no spatial variation and therefore it is not appropriate for these models.

```{r,cache=TRUE, message=FALSE, warning=FALSE}
e<-extent(sp)+4

lf<-list.files(paste(wd, "/Bioclim/", sep=""))

first<-which(grepl("2006_bioclim", lf)) #was initially 1985
last<-which(grepl("2016_bioclim", lf))
all_years<-stack(paste(wd, "/Bioclim/",lf[first:last], sep=""))

bios<-seq(1,nlayers(all_years), by=19)
cellStats(all_years[[bios]], stat="mean")
#creating a 1985-2016 average of each bioclim variable
for (i in 1:19){
  layers<-bios
  bio_layer<-mean(all_years[[layers]])
  writeRaster(bio_layer, paste(wd, "/Bioclim/Bio_",i,"_2006_2016_average.tif",sep=""), overwrite=TRUE) #was initially 1985_2016
  bios<-bios+1
  #print(layers)
}

#pred_nf<-stack(paste(wd, "/Bioclim/Bio_", bio_layer_pred,"_1985_2016_average.tif",sep="" ))
```

Selecting out the bioclim layers I'm interested in:

```{r}


bio_layer_pred<-c(1,5,6,13,15,18,19)  #picking out the bioclim layers we want to use in the model

pred_nf<-stack(paste(wd, "/Bioclim/Bio_", bio_layer_pred,"_2006_2016_average.tif",sep="" ))

pred_crop<-crop(pred_nf, e)

```


####Creating the testing and training datasets

Using K=4 so 75% of points are used for training and 25% for testing.

```{r, cache=TRUE, message=FALSE, warning=FALSE}

set.seed(10)

k<-4
group_pres<-kfold(sp, k)
#write.csv(group_pres, "k_folds_presence.csv")
write.csv(group_pres, "k_folds_presence_2006.csv")
#group_pres<-read.csv("k_folds_presence.csv")
group_pres<-read.csv("k_folds_presence_2006.csv")
group_pres<-group_pres[,-1]  #all presence points

sp_ras<-rasterize(sp, pred_crop[[1]])[[3]]
sp_ras[is.na(sp_ras)]<-0
blank<-sp_ras+1

sp_train<-sp[group_pres!=1,] #presence points split into training and test
sp_test<-sp[group_pres ==1,]

bg_sam<-sample(1:ncell(sp_ras), 1000,replace=F) 
bg_sp<-xyFromCell(blank, bg_sam)
bg_val<-extract(blank, bg_sp)

bg_pse<-data.frame(bg_sp[bg_val==1,])
#write.csv(bg_pse, "background_random_points2.csv")
bg_pse<-read.csv("background_random_points2.csv")
bg_pse<-bg_pse[,-1]

group_back<-kfold(bg_pse, k)
#write.csv(group_back, "k_folds_background2.csv")
group_back<-read.csv("k_folds_background2.csv")
group_back<-group_back[,-1]

sp_backg_train <- bg_pse[group_back != 1, ] #background points split into training and test
sp_backg_test <- bg_pse[group_back == 1, ]
colnames(sp_backg_train)<-c("lon", "lat")
colnames(sp_backg_test)<-c("lon", "lat")

sp_train<-sp_train@coords #presence training points
colnames(sp_train)<-c("lon", "lat")
train <- rbind(sp_train, sp_backg_train)  #presence and background training points combined

sp_test<-sp_test@coords #presence test points
colnames(sp_test)<-c("lon", "lat")
test<-rbind(sp_test, sp_backg_test)    #presence and background test points combined

pb_train <- c(rep(1, nrow(sp_train)), rep(0, nrow(sp_backg_train)))  
envtrain <- extract(pred_nf, train)
envtrain <- data.frame( cbind(pa=pb_train, envtrain) ) #training points with environmental  variables

envtrain<-na.omit(envtrain)

pb_test<-c(rep(1, nrow(sp_test)), rep(0, nrow(sp_backg_test)))
envtest <- extract(pred_nf, test)
envtest <- data.frame( cbind(pa=pb_test, envtest) ) #test points with environmental  variables
summary(envtest)
envtest<-na.omit(envtest)

env_all<-rbind(envtrain, envtest) #all of the training and test data with environmental variables

env_pres<-extract(pred_nf, sp)
pa<-rep(1, nrow(env_pres))
env_pres<-data.frame(pa, env_pres)  #presence points with environmental variables
colnames(env_pres)<-c("pa","Bio_1_2006_2016_average", "Bio_5_2006_2016_average","Bio_6_2006_2016_average","Bio_13_2006_2016_average","Bio_15_2006_2016_average","Bio_18_2006_2016_average","Bio_19_2006_2016_average")
env_pres_xy<-data.frame(sp@coords, env_pres)
env_pres_xy<-na.omit(env_pres_xy)

env_back<-extract(pred_nf, bg_pse)
ap<-rep(0, nrow(env_back))
env_back<-data.frame(ap, env_back) #background points with environmental variables
colnames(env_back)<-c("pa","Bio_1_2006_2016_average", "Bio_5_2006_2016_average","Bio_6_2006_2016_average","Bio_13_2006_2016_average","Bio_15_2006_2016_average","Bio_18_2006_2016_average","Bio_19_2006_2016_average")
env_back_xy<-data.frame(bg_pse, env_back)
env_back_xy<-na.omit(env_back_xy)

group_pres<-group_pres[1:nrow(env_pres_xy)]
group_back<-group_back[1:nrow(env_back_xy)]

```

####Bioclim

Running the Bioclim envelope model and evaluating it using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r, cache=TRUE, message=FALSE, warning=FALSE}

evl_bc<- list()
tss_bc<-list()
for (i in 1:k){
  pres_train<-sp[group_pres!=i,]
  pres_test<-sp[group_pres==i,]
  #backg_train<-sp[group_back!=i,]
  backg_test<-bg_pse[group_back==i,]
  bc <- bioclim(pred_nf,pres_train)
  evl_bc[[i]] <- dismo:::evaluate(pres_test, backg_test, bc,pred_nf,type="response")#test presence, test absence, model, predictor variables (raster stack)
     #print(i)
}

auc_bc <- sapply( evl_bc, function(x){slot(x, "auc")} )
print(auc_bc)


bc_auc<-mean(auc_bc)
#kap_bc<-sapply( evl_bc, function(x){threshold(x)['spec_sens']} )


```

####GAM

Running a GAM and evaluating it to get an AUC value using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r, cache= TRUE, message=FALSE, warning=FALSE}
library(mgcv)

gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=env_all)

gp<-predict(pred_nf, gm1)
r<-raster:::calc(gp, fun=function(x){ exp(x)/(1+exp(x))})

evl_gam<- list()
tss_gam<-list()
for (i in 1:k){
  pres_train<-env_pres_xy[group_pres!=i ,-c(1,2)]
  pres_test<-env_pres_xy[(group_pres==i) ,-c(1,2)]
  back_test<-env_back_xy[(group_back==i),-c(1,2)]
  back_train<-env_back_xy[(group_back!=i),-c(1,2)]
  envtrain<-rbind(pres_train, back_train)
  gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=envtrain)

  evl_gam[[i]] <- dismo:::evaluate(p = pres_test, a = back_test,model= gm1,type="response")
 
 # evaluate(sp, bg_ps, gm1, ,type="response")
   }

auc_gam <- sapply( evl_gam, function(x){slot(x, "auc")} )
print(auc_gam)

gam_auc<-mean(auc_gam)


```

####Random Forest

Running a random forest model and evaluating it using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r, cache= TRUE, message= FALSE, warning=FALSE}
library(randomForest)

model<-pa~  Bio_1_2006_2016_average+Bio_5_2006_2016_average+ 
  Bio_6_2006_2016_average+ Bio_13_2006_2016_average+ Bio_15_2006_2016_average+ 
  Bio_18_2006_2016_average+ Bio_19_2006_2016_average

evl_rf<- list()
for (i in 1:k){
  pres_train<-env_pres_xy[group_pres!=i,-c(1,2)]
  pres_test<-env_pres_xy[(group_pres==i) ,-c(1,2)]
  back_test<-env_back_xy[(group_back==i),-c(1,2)]
  back_train<-env_back_xy[group_back !=i,-c(1,2)]
  envtrain<-rbind(pres_train, back_train)
  rf1 <- randomForest(model, data=envtrain)
  evl_rf[[i]] <- dismo:::evaluate(pres_test, back_test, rf1,type="response")
  }

auc_rf <- sapply( evl_rf, function(x){slot(x, "auc")} )
print(auc_rf)

rf_auc<-mean(auc_rf)

```


#### Ensemble Model

Creating a weighted (based on AUC) ensemble average suitability model for 2006-2016 from the Bioclim, GAM and Random Forest models. This will be used to predict habitat suitability for Alpine ibex for each year 1950-2016.


```{r, cache=TRUE, warning=FALSE, message=FALSE}
#total models
library(randomForest)
bc <- bioclim(pred_nf, sp)
gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=env_all)
rf1 <- randomForest(model, data=env_all)

pb <- predict(pred_nf, bc, ext=e, progress='') #bioclim predict
pg <- predict(pred_nf, gm1, ext=e) #gam predict
pgl<-raster:::calc(pg, fun=function(x){ exp(x)/(1+exp(x))}) #backtransforming from logit space
pr <- predict(pred_nf, rf1, ext=e) #random forest predict

models <- stack(pb, pgl, pr)
names(models) <- c("bioclim", "gam", "random forest")
plot(models)

auc<-c(bc_auc, gam_auc, rf_auc)
w <- (auc-0.5)^2
wm <- weighted.mean( models[[c("bioclim", "gam", "random.forest")]], w)
plot(wm, main="Ensemble model")
points(sp)

```


####Weighted Threshold

```{r}

source("ensemble_evaluate.R")

abs_xy<-env_back_xy[,c(1,2)]

ens<-ensemble_evaluate(sp,abs_xy , wm)
thresh<-threshold(ens, stat="spec_sens")

```


####Annual Habitat Suitability Predictions

Using the ensemble model to predict suitability for each year - 1950-2016 and for each year creating a binary presence/absence map based on a three different thresholding techniques. I will go forward using true skill statistic based on Allouche 2006.

```{r, cache=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
library(dismo)
#wd<-"C:/Users/Fiona/Documents/Demoniche"
wd<-getwd()
bc <- bioclim(pred_nf, sp)
gm1<-mgcv:::gam(pa~ s(Bio_1_2006_2016_average)+ s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+s(Bio_18_2006_2016_average)+ s(Bio_19_2006_2016_average), data=env_all)
rf1 <- randomForest:::randomForest(model, data=env_all)


years<-1950:2016
library(raster)
library(mgcv)
library(randomForest)
for (i in 1:length(years)){
  
  pred_nf<-stack(paste(wd, "/Bioclim/", years[i], "_bioclim_variable_stack.tif", sep="" ))  
  pred_nf<-pred_nf[[bio_layer_pred]]
 # names(pred_nf)<-c("Bio_1_1985_2016_average","Bio_5_1985_2016_average", "Bio_6_1985_2016_average", "Bio_13_1985_2016_average" ,"Bio_15_1985_2016_average","Bio_18_1985_2016_average", "Bio_19_1985_2016_average")
  names(pred_nf)<-c("Bio_1_2006_2016_average","Bio_5_2006_2016_average", "Bio_6_2006_2016_average", "Bio_13_2006_2016_average" ,"Bio_15_2006_2016_average","Bio_18_2006_2016_average", "Bio_19_2006_2016_average")
  
  pb <- predict(pred_nf, bc, ext=e, progress='')
  pg <- predict(pred_nf, gm1, ext=e) #gam predict
  pgl<-raster:::calc(pg, fun=function(x){ exp(x)/(1+exp(x))})
  pr <- predict(pred_nf, rf1, ext=e)
  
  models <- stack(pb, pgl, pr)
  names(models) <- c("bioclim", "gam", "random forest")
  wm <- weighted.mean( models[[c("bioclim", "gam", "random.forest")]], w)
  
  pa_sss<-wm>thresh
 
 writeRaster(wm , paste(wd, "/Alp_SDMs/New_Ensembles_2006_2016/weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)
  writeRaster(pa_sss , paste(wd, "/Alp_SDMs/New_Ensembles_2006_2016/pres_abs_sss_weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)

  plot(pa_sss, main=years[i])
}

```

####Trends in habitat suitability 1950-2016

```{r}
library(raster)
years<-1950:2016
#wd<-("C:/Users/Fiona/Documents/Demoniche")

wd<-getwd()
t<-stack(paste(wd,"/Alp_SDMs/Ensembles_2006_2016/weighted_ensemble_sdm_", years,".tif", sep=""))
s<-round(seq(1,67,len=16))

plot(t[[s]])

patch<-stack(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/pres_abs_sss_weighted_ensemble_sdm_", years,".tif", sep=""))
plot(patch[[s]])

m<-cellStats(t, stat="mean")
sd<-cellStats(t, stat="sd")

plot(years,m, type="l", main="Average habitat suitability over time", ylim=c(0,0.7), ylab="Suitability index", xlab="Years")
lines(years, m+(2*sd), col="red", lty=3)
lines(years, m-(2*sd), col="red", lty=3)




```

####Patches

Plots of the number of cells with predicted presence and number of patches (contiguous presence) over 1950-2016.

```{r, warning=FALSE, echo=FALSE}
year_patch<-data.frame(years = years, patch_num = numeric(length(years)) )


for (i in 1:length(years)){
c<-clump(patch[[i]])
year_patch[i,2]<-max(na.omit(values(c)))
#print(i)
}
par(mar=c(4,4,4,5))

mk<-cellStats(patch, stat="sum")
plot(years,mk, type="l", main="Predicted patch presence", ylab="Suitable squares", xlab="Years", col="red")
par(new=TRUE)
par(mar=c(4,4,4,5))
plot(year_patch$years, year_patch$patch_num,type="l",col="blue",xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("Number of Patches",side=4,line=3)
legend("topright",col=c("red","blue"),lty=1,legend=c("Suitable Squares","Number of Patches"))

```



## Demoniche 

####Formatting the population occurrence points

Formatting the LPI population data for use in Demoniche, they start as the "seed" populations. Might be better to use GBIF data for this - unrealistic that the LPI populations are the only existing populations in 1950 - alternatively a historical map of where the ibex were in 1950?

```{r, warning=FALSE, message=FALSE}
library(demoniche)
library(rgdal)
library(raster)
species<-"Capra_ibex"

df2<-read.csv("LPI_pops_20160523_edited.csv")
pyr<-subset(df2, Binomial ==species & Specific_location==1)    #record 11470 had wrong longitude - in Russia!

#formatting the data for use in demoniche
pyrs<-pyr[,c("ID","Longitude","Latitude")]

id<-pyrs$ID*100
lam<-rep(1,length(id))    #not sure what the value here pertains to - think it sets starting population so should use values from LPI?
pyrxy<-SpatialPoints(pyr[,c("Longitude","Latitude")])

wd<-getwd()
sdm<-raster(paste(wd,"/Alp_SDMs/Ensembles_2006_2016/pres_abs_kappa_weighted_ensemble_sdm_1950.tif", sep=""))
e2<-extent(sdm)

r<-raster(e2, resolution=res(sdm))

rz<-rasterize(pyrxy,r,lam )
rid<-rasterize(pyrxy,r,id)
# plot(rz)
# plot(rid)

rz_spdf<-xyFromCell(rz, 1:ncell(rid))

rzm<-as.vector(rz)
ridm<-as.vector(rid)

df<-data.frame(ridm,rz_spdf,rzm)
colnames(df)<-c( "PatchID","X","Y","area")

Populations<-data.frame(na.omit(df)) 

```

####Formatting the habitat suitability models

Formatting the habitat suitability model maps into vectors for use in Demoniche and plotting the average habitat suitability over time. 
Here we also create a fake set of habitat suitability models where the suitability is driven down at a constant rate over time.

```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(raster)

years<-1950:2016

sdm_patch_df<-data.frame(ID=1:ncell(rid))
sdm_df<-data.frame(ID=1:ncell(rid))
sdm_fake_df<-data.frame(ID=1:ncell(rid))

#formatting data for demoniche
for (i in 1:length(years)){
  
  #a selection of different threshold techniques for presence absence, as well as a suitability surface
  sdm<-raster(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/weighted_ensemble_sdm_", years[i],".tif", sep=""))   #14.6
  e<-extent(sdm)
  patch<-raster(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/pres_abs_sss_weighted_ensemble_sdm_", years[i],".tif", sep="")) #21.1%  
  patch<-crop(patch, e)

  #fake<-raster(paste(wd, "/Alp_SDMs/Fake_Landscape/Fake_Landscape_", years[i], ".tif", sep=""))
  if (i ==1){
    vec<-as.data.frame(sdm, xy = TRUE)
    vec_pat<-as.data.frame(patch, xy=TRUE)
    vec_fake<-as.data.frame(fake, xy=TRUE)
  } else{
    vec<-as.data.frame(sdm)
    vec_pat<-as.data.frame(patch)
    vec_fake<-as.data.frame(fake)
  }
  
  sdm_df<-cbind(sdm_df, vec)
  sdm_patch_df<-cbind(sdm_patch_df,vec_pat)
  sdm_fake_df<-cbind(sdm_fake_df, vec_fake)
  #print(i)
}

sdm_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]
sdm_patch_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]
sdm_fake_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]

niche_map_mine<-sdm_df
colnames(niche_map_mine)[1:3]<-c("gridID", "X", "Y")

patch_map_mine<-sdm_patch_df
colnames(patch_map_mine)[1:3]<-c("gridID", "X", "Y")

fake_map_mine<-sdm_fake_df
colnames(fake_map_mine)[1:3]<-c("gridID", "X", "Y")

niche_spin_up<-matrix(rep(niche_map_mine[,4], 99), nrow=nrow(niche_map_mine))
niche_spin_up<-cbind(niche_map_mine[,1:3],niche_spin_up, niche_map_mine[,4:ncol(niche_map_mine)])

patch_spin_up<-matrix(rep(patch_map_mine[,4], 99), nrow=nrow(patch_map_mine))
patch_spin_up<-cbind(patch_map_mine[,1:3],patch_spin_up, patch_map_mine[,4:ncol(patch_map_mine)]) #last patch used to be niche

fake_spin_up<-matrix(rep(fake_map_mine[,4], 99), nrow=nrow(fake_map_mine))
fake_spin_up<-cbind(fake_map_mine[,1:3],fake_spin_up, fake_map_mine[,4:ncol(fake_map_mine)])


col_years_short<-paste("Year_", 1950:2016, sep="")
col_years<-paste("Year_", 1850:2016, sep="")

colnames(niche_map_mine)[4:length(colnames(niche_map_mine))]<-col_years_short
colnames(patch_map_mine)[4:length(colnames(patch_map_mine))]<-col_years_short
colnames(fake_map_mine)[4:length(colnames(fake_map_mine))]<-col_years_short

colnames(niche_spin_up)[4:length(colnames(niche_spin_up))]<-col_years
colnames(patch_spin_up)[4:length(colnames(patch_spin_up))]<-col_years
colnames(fake_spin_up)[4:length(colnames(fake_spin_up))]<-col_years


fake_spin_up[is.na(fake_spin_up)]<-0
#niche_formulas <- as.formula(paste(paste(colnames(niche_map_mine)[-c(1:3)], collapse="+"),"X+Y",sep="~"))

#print(levelplot(niche_formulas, niche_map_mine, col.regions=rev(heat.colors(100)), main = "Niche Values"))

no_yrs_mine<-1 #number of years each time period represents 

years_short<-1950:2016
plot(years_short,colMeans(na.omit(niche_map_mine)[4:length(colnames(niche_map_mine))]), type="l", ylab="Mean suitability index")
#

#plot(years_short,colMeans(na.omit(niche_map_mine)[904:length(colnames(niche_map_mine))]), type="l", ylab="Mean suitability index")

niche_map_mine<-na.omit(niche_map_mine)
patch_map_mine<-na.omit(patch_map_mine)
fake_map_mine<-na.omit(fake_map_mine)

niche_spin_up<-na.omit(niche_spin_up)
patch_spin_up<-na.omit(patch_spin_up)
fake_spin_up<-na.omit(fake_spin_up)

```

####COMADRE

Accessing the population matrices from COMADRE - there are 5 matrices available for the alpine ibex but four are for the same area and only represent survival over two time periods in good/bad conditions. 

<span style="color:red">Could I use these to calibrate the survival aspect of the matrices?</span>

####Demoniche setup
Parameterising the demoniche model

```{r, warning=FALSE, message=FALSE}
#Population matrix set up
#wd<-("C:/Users/Fiona/Documents/PhD/PhD_Method")

load(paste(wd, "COMADRE_v.2.0.1.RData", sep="/"))

#load(paste(wd, "COMADRE_v.1.0.0.RData", sep="/"))

species<-"Capra_ibex"

tempMetadata<-subset(comadre$metadata, SpeciesAccepted==species)

keep<-as.numeric(rownames(tempMetadata))

tempMat<-comadre$mat[keep]   #MatA is matrix pop model, can be split into U, F and/or C

MatList<-list(tempMat[[1]][[1]])  #varies depending on number of matrices - need to find a way to code this better - now have five matrices available so need to sort this
AllMat<-unlist(MatList)
matrices<-matrix(AllMat, ncol=length(MatList))
colnames(matrices)<- c("Reference_matrix")


prob_scenario<-c(0.5,0.5)    #need to check this

noise<-0.90     #not yet active in demoniche

stages<-comadre$matrixClass[keep][[1]]$MatrixClassAuthor
#stages<-comadre$matrixClass[keep][[2]]$MatrixClassAuthor
#stagesf<-stages[1:3]

list_names_matrices<-colnames(matrices)

sumweight<-rep(1, length(stages)) #weight of stages  - should be equal for all mine just 
#in plants seed not included in calculating population sizes - or if you wanted to just 
#calculate the female population it would be c(1,1,1,0,0,0)
#sumweightf<-c(1,1,1)

transition_affected_niche<-c(2,11,20)   #which parts of the matrix are affected by the c(1,2) is juveniles - as if the matrix is a vector L-R
transition_affected_niche<-"all"  #which parts of the matrix are affected by the c(1,2) is juveniles
#niche values

transition_affected_env <- "all"

transition_affected_demogr <- "all"

env_stochas_type<-"normal"   #can also be lognormal


matrices_var <- matrix(1, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 
#standard deviation of matrices

proportion_initial<- rep(1/length(stages), length(stages)) #proportion of population in 
#each stage - no idea what this should be and will likely have a big impact on results! 
#- just doing eqaul splits for now
#proportion_initialf<- c(1/3,1/3,1/3)

density_individuals <- 4000  #4292.32 to 16096.2 based on density being between 8 and 30 per 100 ha and the area of each cell being 53654 ha - 


K_weight<-c(rep(1, length(stages)))  #the weight with which carrying capacity affects each stage was FALSE


#niche_map_mine[is.na(niche_map_mine)]<-0
patch_map_mine[is.na(patch_map_mine)]<-0
```


```{r, cache=TRUE, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}

#Scaling carrying capacity (as estimated above) in three different ways, linear, sigmoidal and linear threshold.
#plotting functions linking k and hsi

k<-5000#set to one when using filzbach estimates - otherwise set to a standard value across all pops
lin<-function(x){
  x*k
  }

sig<-function(x){
  k*(1/(1+exp(-10*x+5)))
  }   #could also try with 18x + 9 - closer to SM in Damaris paper

lt<-function(x) { 
  val = (4/3) * x - (1/3)
  val[x < 0.25] = 0 
  val<-val*k
  return(val)
}


#carrying capacity function 

lf<-list.files(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/", sep=""))   

files<-lf[grepl("^weighted_ensemble_sdm_.*.tif$", lf)]

sdms<-stack(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/", files, sep=""))


# ks_df<-read.csv("carrying_capacity_log_likelihood_capra_ibex.csv")
# ks_df$PatchID<-ks_df$ID*100
# 
# #for 1950-2016
# #sdms<-sdms[[901:967]]
# 
# 
# ks_xy<-merge(Populations, ks_df[,c(2:4)], by="PatchID")
# 

hsi<-extract(sdms, ks_xy[,c(2,3)])


link<-lin(hsi)
#links<-link*ks_xy$ks

sigk<-sig(hsi)
#sigks<-sigk*ks_xy$ks

ltk<-lt(hsi)
#ltks<-ltk*ks_xy$ks

#plot(links[,c(900:967)], type="l")

spin<-replicate(100,link[,1])
link_spin<-cbind(spin, link)

colnames(link_spin)[1:100]<-paste("weighted_ensemble_sdm_", spin_years, sep="")
link_spin<-link_spin[,-ncol(link_spin)]

```

####Varying standard deviation of population matrix, long distance dispersal and kernel shape


Changed the demoniche_setup function (now demoniche_setup_me.R) to change the dispersal function to a decay curve where the half-life is the median estimated dispersal distance.This was based on Bowman et al 2012 where it suggests that the maximum dispersal is 40x the square root of a species home range and median dispersal is 7x the square root of HR. 



```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, eval=FALSE}
#setwd("C:Users/Fiona/Documents/Demoniche")

sd_seq<-1
#matrices_var<-matrix(0.45, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 
#k_seq<-c(1000,2000,4000,8000,16000,32000)
LDD_seq<-c(0.9)
kern_seq<-list(c(19.775,113),c(13.5975, 77.7), c(1000,1000))

var_grid<-expand.grid(sd_seq, LDD_seq, kern_seq)
colnames(var_grid)<-c("SD", "LDD", "Kern")

kern_mat<-matrix(c(rep(c(19.775,113), (nrow(var_grid)/ncol(var_grid))),rep(c(13.5975, 77.7), (nrow(var_grid)/ncol(var_grid))),rep(c(1000,1000),(nrow(var_grid)/ncol(var_grid)))), ncol=2, byrow=T)



source("demoniche_setup_me.R")
source("demoniche_model_me.R")

for (s in 1:nrow(var_grid)){

  print(paste (s, " out of ", nrow(var_grid) ), sep="")
  
  SD<-var_grid[s,1]
  LDD<-var_grid[s,2]
  
  
  matrices_var<-matrix(SD, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

start.time <- Sys.time()

 max_disp<-as.character(kern_mat[s,2])
dir.create(paste(wd,"/Demoniche_Repetitions/Kern_kap_new/max_disp_",max_disp,sep=""),showWarnings = TRUE)

reps<-12

rep_demoniche<-function(i){
  library(demoniche)
  source("demoniche_model_me.R")
 demoniche_setup_me(modelname = "Capra_k_16000",Populations = Populations, Nichemap = patch_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 2671,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = 0.1, fraction_SDD = 0.1,
                  dispersal_constants = kern_mat[s,],
                #dispersal_constants = c(0.7, 0.7, 0.1,3), 
                transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=link_spin, Kweight = K_weight, 
                  sumweight =sumweight)
 

c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("Demoniche_Repetitions/Kern_kap_new/max_disp_",max_disp,"/",i, sep=""))
}


#lapply(1:reps, rep_demoniche)

library(doParallel)

if (Sys.info()["nodename"] == "FIONA-PC"){
 cl <- makeCluster(4) 
} else {
 cl <- makeCluster(2)
}


registerDoParallel(cl)
foreach(i=(1:reps)) %dopar% rep_demoniche(i)
stopCluster(cl)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken 
}

#lapply(1:reps, rep_demoniche)

```

```{r,message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
library(dplyr)

 rep_df_all<-data.frame()
 plot_rep<-function(proj_path){
  
  load(proj_path)
  #id<-gsub("C:/Users/Fiona/Documents/PhD/PhD_Method/Demoniche_Repetitions/Kern_kap/max_disp_", "", proj_path)
  id<-gsub("D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Kern_kap_new/max_disp_", "", proj_path)
  id<-gsub("Projection_rep1_Reference_matrix.rda", "",id)
  md_id<-strsplit(id, "/")[[1]][1]
  rep_id<- gsub(".*[/]([^/]+)[/]*", "\\1", id)
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),])
  tid<-cbind(md_id, rep_id, trend)
  return(tid)
  }

wd<-getwd()
wd<-paste(wd, "/Demoniche_Repetitions/Kern_kap_new/", sep="")

folders<-list.files(wd)

for (folder in folders){

  print(folder)

  f<-paste(wd,folder, sep="")

  lf<-list.dirs(f, recursive = F)

#path<-paste(f, lf, sep="")

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  rep_df$md_id<-as.factor(rep_df$md_id)

  #  spin<-ggplot(rep_df, aes(x = year, y= trend, group=md_id))+
  #   geom_line( alpha=0.5)
  # 
  # plot(spin)
  
  rep_df_short<-rep_df[rep_df$year >=1950,]


  # p<-ggplot(rep_df_short, aes(x = year, y= trend, group=md_id))+
  #   geom_line( alpha=0.5)
  

  rep_df_all<-rbind(rep_df,rep_df_all)
  
}

#(rep_df_all, "kern_kap_new_params.csv")
```


```{r, message=FALSE, warning=FALSE}

rep_df_all<-read.csv("kern_k---
title: "Assessing the predictive ability of Demoniche"
author: "Fiona Spooner"
date: "September 6, 2017"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
---

```{r, eval=FALSE, message=FALSE}
install.packages('climates',,'http://www.rforge.net/')
install.packages("dismo")
install.packages("maps")
install.packages("mapdata")
install.packages("popbio")
install.packages("demoniche", repos="http://R-Forge.R-project.org")

```

```{r, message= FALSE, warning=FALSE}
library(zoo)
library(dismo)
```

#####Bioclim Variables 

Creating the 19 bioclim variables for each year between 1950 & 2016 for Europe using the E-OBS dataset - downloaded from http://www.ecad.eu/download/ensembles/download.php

```{r, eval=FALSE, message=FALSE, warning=FALSE}
rr<-brick(paste(wd, "/rr_0.25deg_reg_v15.0.nc", sep="")) #precipitation
tg<-brick(paste(wd, "/tg_0.25deg_reg_v15.0.nc", sep="")) #mean temp
tn<-brick(paste(wd, "/tn_0.25deg_reg_v15.0.nc", sep="")) #min temp
tx<-brick(paste(wd, "/tx_0.25deg_reg_v15.0.nc", sep="")) #max temp
#dates<-as.Date((gsub("X", "",names(rr))), format="%Y.%m.%d")


rr_mon<-zApply(rr, by=as.yearmon, fun = mean)
tg_mon<-zApply(tg, by=as.yearmon, fun = mean)
tn_mon<-zApply(tn, by=as.yearmon, fun = mean)
tx_mon<-zApply(tx, by=as.yearmon, fun = mean)

jans<-seq(1,804, by=12)
years<-as.character(1950:2016)

for (i in 1:length(years)){
  jan_sel<-jans[i]
  dec_sel<-jan_sel+11
  bio_vars_all<-biovars(rr_mon[[jan_sel:dec_sel]], tn_mon[[jan_sel:dec_sel]], tx_mon[[jan_sel:dec_sel]])  
  writeRaster(bio_vars_all, paste("C:/Users/Fiona/Documents/PhD/PhD_Method/Bioclim/", years[i],"_bioclim_variable_stack.tif", sep=""), overwrite=T)
  print(years[i])
  }
```

####Species distribution modelling with dismo

Extracting Alpine ibex (*Capra ibex*) data from GBIF and with additional locations added from the LPI dataset. These points are then formatted to a SpatialPointsDataFrame.
```{r, cache=TRUE, message= FALSE, warning=FALSE}
library(dismo)
library(demoniche)
library(maps)
library(mapdata)
library(rgeos)
```

Extracting Alpine ibex data from GBIF and cleaning the data so that only points from the Alps remain.

```{r, cache=TRUE, message= FALSE, warning=FALSE}

wd<- getwd()
capra <-gbif(genus ="Capra", species = "ibex")
capgeo <- subset(capra, !is.na(lon) & !is.na(lat) & (lon!="NA" & lat !="NA") | year!="NA") 
dups <- duplicated(capgeo[, c("lon", "lat")])
capg <-capgeo[!dups, ]
capg2 <- capg[capg$lon > 0 & capg$lon<16 & capg$lat > 43 & capg$lat < 47.9 & capg$year>=2006, ] 
capg2<-data.frame(capg2$lon,capg2$lat)
colnames(capg2)<-c("Longitude", "Latitude")

species<-"Capra_ibex"
df2<-read.csv("LPI_pops_20160523_edited.csv")
pyr<-subset(df2, Binomial ==species & Specific_location==1)    #record 11470 had wrong longitude - in Russia!
pyrs<-pyr[,c("Longitude","Latitude")]
capg2<-rbind(capg2, pyrs)
capg2<-na.omit(capg2)
capg2$presence<-rep(1)
capg2$ID<-1:nrow(capg2)

capc<-as.matrix(capg2[ , c( "Longitude","Latitude", "presence")])
capc<-matrix(capc[complete.cases(capc)], ncol=3)
xy<-as.matrix(capc[,c(1,2)])
df<-data.frame(capc[,3])

write.csv(df, "Capra_ibex_gbif.csv")
```

```{r}
df<-read.csv("Capra_ibex_gbif.csv")

sp<-SpatialPointsDataFrame(coords=xy, data=df)
x <- circles(sp, d=50000, lonlat=TRUE)
pol <- polygons(x)
```

Mapping the occurence points

```{r, message=FALSE, warning=FALSE}
e<-extent(sp)
e_big<-e+4
maps:::map('world',c('Italy', 'Switzerland', 'Austria', 'Monaco','Liechtenstein','Germany', 'Slovenia', 'France'),  col="light grey", fill=T, xlim=c(e_big[1],e_big[2]), ylim=c(e_big[3],e_big[4]))
plot(pol,add=T)
points(sp, col="red", pch=20)

```

Creating the 2006-2016 average for each bioclim variable and then selecting out the layers we want to use in the model:

*	Bioclim 1 â Annual mean temperature

*	Bioclim 5 â Max temperature of the warmest month

*	Bioclim 6 â Min temperature of the coldest month

*	Bioclim 13 â Precipitation of the wettest month

*	Bioclim 15 â Precipitation seasonality (coefficient of variation)

*	Bioclim 18 â Precipitation of warmest quarter

*	Bioclim 19 â Precipitation of coldest quarter

Snow depth seems to be an important predictor for alpine ibex but I have struggled to find historical data on this. Existing papers are based on historical data from one weather station, which means there is no spatial variation and therefore it is not appropriate for these models.

```{r,cache=TRUE, message=FALSE, warning=FALSE}
e<-extent(sp)+4

lf<-list.files(paste(wd, "/Bioclim/", sep=""))

first<-which(grepl("2006_bioclim", lf)) #was initially 1985
last<-which(grepl("2016_bioclim", lf))
all_years<-stack(paste(wd, "/Bioclim/",lf[first:last], sep=""))

bios<-seq(1,nlayers(all_years), by=19)
cellStats(all_years[[bios]], stat="mean")
#creating a 1985-2016 average of each bioclim variable
for (i in 1:19){
  layers<-bios
  bio_layer<-mean(all_years[[layers]])
  writeRaster(bio_layer, paste(wd, "/Bioclim/Bio_",i,"_2006_2016_average.tif",sep=""), overwrite=TRUE) #was initially 1985_2016
  bios<-bios+1
  #print(layers)
}

#pred_nf<-stack(paste(wd, "/Bioclim/Bio_", bio_layer_pred,"_1985_2016_average.tif",sep="" ))
```

Selecting out the bioclim layers I'm interested in:

```{r}


bio_layer_pred<-c(1,5,6,13,15,18,19)  #picking out the bioclim layers we want to use in the model

pred_nf<-stack(paste(wd, "/Bioclim/Bio_", bio_layer_pred,"_2006_2016_average.tif",sep="" ))

pred_crop<-crop(pred_nf, e)

```


####Creating the testing and training datasets

Using K=4 so 75% of points are used for training and 25% for testing.

```{r, cache=TRUE, message=FALSE, warning=FALSE}

set.seed(10)

k<-4
group_pres<-kfold(sp, k)
#write.csv(group_pres, "k_folds_presence.csv")
write.csv(group_pres, "k_folds_presence_2006.csv")
#group_pres<-read.csv("k_folds_presence.csv")
group_pres<-read.csv("k_folds_presence_2006.csv")
group_pres<-group_pres[,-1]  #all presence points

sp_ras<-rasterize(sp, pred_crop[[1]])[[3]]
sp_ras[is.na(sp_ras)]<-0
blank<-sp_ras+1

sp_train<-sp[group_pres!=1,] #presence points split into training and test
sp_test<-sp[group_pres ==1,]

bg_sam<-sample(1:ncell(sp_ras), 1000,replace=F) 
bg_sp<-xyFromCell(blank, bg_sam)
bg_val<-extract(blank, bg_sp)

bg_pse<-data.frame(bg_sp[bg_val==1,])
#write.csv(bg_pse, "background_random_points2.csv")
bg_pse<-read.csv("background_random_points2.csv")
bg_pse<-bg_pse[,-1]

group_back<-kfold(bg_pse, k)
#write.csv(group_back, "k_folds_background2.csv")
group_back<-read.csv("k_folds_background2.csv")
group_back<-group_back[,-1]

sp_backg_train <- bg_pse[group_back != 1, ] #background points split into training and test
sp_backg_test <- bg_pse[group_back == 1, ]
colnames(sp_backg_train)<-c("lon", "lat")
colnames(sp_backg_test)<-c("lon", "lat")

sp_train<-sp_train@coords #presence training points
colnames(sp_train)<-c("lon", "lat")
train <- rbind(sp_train, sp_backg_train)  #presence and background training points combined

sp_test<-sp_test@coords #presence test points
colnames(sp_test)<-c("lon", "lat")
test<-rbind(sp_test, sp_backg_test)    #presence and background test points combined

pb_train <- c(rep(1, nrow(sp_train)), rep(0, nrow(sp_backg_train)))  
envtrain <- extract(pred_nf, train)
envtrain <- data.frame( cbind(pa=pb_train, envtrain) ) #training points with environmental  variables

envtrain<-na.omit(envtrain)

pb_test<-c(rep(1, nrow(sp_test)), rep(0, nrow(sp_backg_test)))
envtest <- extract(pred_nf, test)
envtest <- data.frame( cbind(pa=pb_test, envtest) ) #test points with environmental  variables
summary(envtest)
envtest<-na.omit(envtest)

env_all<-rbind(envtrain, envtest) #all of the training and test data with environmental variables

env_pres<-extract(pred_nf, sp)
pa<-rep(1, nrow(env_pres))
env_pres<-data.frame(pa, env_pres)  #presence points with environmental variables
colnames(env_pres)<-c("pa","Bio_1_2006_2016_average", "Bio_5_2006_2016_average","Bio_6_2006_2016_average","Bio_13_2006_2016_average","Bio_15_2006_2016_average","Bio_18_2006_2016_average","Bio_19_2006_2016_average")
env_pres_xy<-data.frame(sp@coords, env_pres)
env_pres_xy<-na.omit(env_pres_xy)

env_back<-extract(pred_nf, bg_pse)
ap<-rep(0, nrow(env_back))
env_back<-data.frame(ap, env_back) #background points with environmental variables
colnames(env_back)<-c("pa","Bio_1_2006_2016_average", "Bio_5_2006_2016_average","Bio_6_2006_2016_average","Bio_13_2006_2016_average","Bio_15_2006_2016_average","Bio_18_2006_2016_average","Bio_19_2006_2016_average")
env_back_xy<-data.frame(bg_pse, env_back)
env_back_xy<-na.omit(env_back_xy)

group_pres<-group_pres[1:nrow(env_pres_xy)]
group_back<-group_back[1:nrow(env_back_xy)]

```

####Bioclim

Running the Bioclim envelope model and evaluating it using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r, cache=TRUE, message=FALSE, warning=FALSE}

evl_bc<- list()
tss_bc<-list()
for (i in 1:k){
  pres_train<-sp[group_pres!=i,]
  pres_test<-sp[group_pres==i,]
  #backg_train<-sp[group_back!=i,]
  backg_test<-bg_pse[group_back==i,]
  bc <- bioclim(pred_nf,pres_train)
  evl_bc[[i]] <- dismo:::evaluate(pres_test, backg_test, bc,pred_nf,type="response")#test presence, test absence, model, predictor variables (raster stack)
     #print(i)
}

auc_bc <- sapply( evl_bc, function(x){slot(x, "auc")} )
print(auc_bc)


bc_auc<-mean(auc_bc)
#kap_bc<-sapply( evl_bc, function(x){threshold(x)['spec_sens']} )


```

####GAM

Running a GAM and evaluating it to get an AUC value using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r, cache= TRUE, message=FALSE, warning=FALSE}
library(mgcv)

gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=env_all)

gp<-predict(pred_nf, gm1)
r<-raster:::calc(gp, fun=function(x){ exp(x)/(1+exp(x))})

evl_gam<- list()
tss_gam<-list()
for (i in 1:k){
  pres_train<-env_pres_xy[group_pres!=i ,-c(1,2)]
  pres_test<-env_pres_xy[(group_pres==i) ,-c(1,2)]
  back_test<-env_back_xy[(group_back==i),-c(1,2)]
  back_train<-env_back_xy[(group_back!=i),-c(1,2)]
  envtrain<-rbind(pres_train, back_train)
  gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=envtrain)

  evl_gam[[i]] <- dismo:::evaluate(p = pres_test, a = back_test,model= gm1,type="response")
 
 # evaluate(sp, bg_ps, gm1, ,type="response")
   }

auc_gam <- sapply( evl_gam, function(x){slot(x, "auc")} )
print(auc_gam)

gam_auc<-mean(auc_gam)


```

####Random Forest

Running a random forest model and evaluating it using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r, cache= TRUE, message= FALSE, warning=FALSE}
library(randomForest)

model<-pa~  Bio_1_2006_2016_average+Bio_5_2006_2016_average+ 
  Bio_6_2006_2016_average+ Bio_13_2006_2016_average+ Bio_15_2006_2016_average+ 
  Bio_18_2006_2016_average+ Bio_19_2006_2016_average

evl_rf<- list()
for (i in 1:k){
  pres_train<-env_pres_xy[group_pres!=i,-c(1,2)]
  pres_test<-env_pres_xy[(group_pres==i) ,-c(1,2)]
  back_test<-env_back_xy[(group_back==i),-c(1,2)]
  back_train<-env_back_xy[group_back !=i,-c(1,2)]
  envtrain<-rbind(pres_train, back_train)
  rf1 <- randomForest(model, data=envtrain)
  evl_rf[[i]] <- dismo:::evaluate(pres_test, back_test, rf1,type="response")
  }

auc_rf <- sapply( evl_rf, function(x){slot(x, "auc")} )
print(auc_rf)

rf_auc<-mean(auc_rf)

```


#### Ensemble Model

Creating a weighted (based on AUC) ensemble average suitability model for 2006-2016 from the Bioclim, GAM and Random Forest models. This will be used to predict habitat suitability for Alpine ibex for each year 1950-2016.


```{r, cache=TRUE, warning=FALSE, message=FALSE}
#total models
library(randomForest)
bc <- bioclim(pred_nf, sp)
gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=env_all)
rf1 <- randomForest(model, data=env_all)

pb <- predict(pred_nf, bc, ext=e, progress='') #bioclim predict
pg <- predict(pred_nf, gm1, ext=e) #gam predict
pgl<-raster:::calc(pg, fun=function(x){ exp(x)/(1+exp(x))}) #backtransforming from logit space
pr <- predict(pred_nf, rf1, ext=e) #random forest predict

models <- stack(pb, pgl, pr)
names(models) <- c("bioclim", "gam", "random forest")
plot(models)

auc<-c(bc_auc, gam_auc, rf_auc)
w <- (auc-0.5)^2
wm <- weighted.mean( models[[c("bioclim", "gam", "random.forest")]], w)
plot(wm, main="Ensemble model")
points(sp)

```


####Weighted Threshold

```{r}

source("ensemble_evaluate.R")

abs_xy<-env_back_xy[,c(1,2)]

ens<-ensemble_evaluate(sp,abs_xy , wm)
thresh<-threshold(ens, stat="spec_sens")

```


####Annual Habitat Suitability Predictions

Using the ensemble model to predict suitability for each year - 1950-2016 and for each year creating a binary presence/absence map based on a three different thresholding techniques. I will go forward using true skill statistic based on Allouche 2006.

```{r, cache=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
library(dismo)
#wd<-"C:/Users/Fiona/Documents/Demoniche"
wd<-getwd()
bc <- bioclim(pred_nf, sp)
gm1<-mgcv:::gam(pa~ s(Bio_1_2006_2016_average)+ s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+s(Bio_18_2006_2016_average)+ s(Bio_19_2006_2016_average), data=env_all)
rf1 <- randomForest:::randomForest(model, data=env_all)


years<-1950:2016
library(raster)
library(mgcv)
library(randomForest)
for (i in 1:length(years)){
  
  pred_nf<-stack(paste(wd, "/Bioclim/", years[i], "_bioclim_variable_stack.tif", sep="" ))  
  pred_nf<-pred_nf[[bio_layer_pred]]
 # names(pred_nf)<-c("Bio_1_1985_2016_average","Bio_5_1985_2016_average", "Bio_6_1985_2016_average", "Bio_13_1985_2016_average" ,"Bio_15_1985_2016_average","Bio_18_1985_2016_average", "Bio_19_1985_2016_average")
  names(pred_nf)<-c("Bio_1_2006_2016_average","Bio_5_2006_2016_average", "Bio_6_2006_2016_average", "Bio_13_2006_2016_average" ,"Bio_15_2006_2016_average","Bio_18_2006_2016_average", "Bio_19_2006_2016_average")
  
  pb <- predict(pred_nf, bc, ext=e, progress='')
  pg <- predict(pred_nf, gm1, ext=e) #gam predict
  pgl<-raster:::calc(pg, fun=function(x){ exp(x)/(1+exp(x))})
  pr <- predict(pred_nf, rf1, ext=e)
  
  models <- stack(pb, pgl, pr)
  names(models) <- c("bioclim", "gam", "random forest")
  wm <- weighted.mean( models[[c("bioclim", "gam", "random.forest")]], w)
  
  pa_sss<-wm>thresh
 
 writeRaster(wm , paste(wd, "/Alp_SDMs/New_Ensembles_2006_2016/weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)
  writeRaster(pa_sss , paste(wd, "/Alp_SDMs/New_Ensembles_2006_2016/pres_abs_sss_weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)

  plot(pa_sss, main=years[i])
}

```

####Trends in habitat suitability 1950-2016

```{r}
library(raster)
years<-1950:2016
#wd<-("C:/Users/Fiona/Documents/Demoniche")

wd<-getwd()
t<-stack(paste(wd,"/Alp_SDMs/Ensembles_2006_2016/weighted_ensemble_sdm_", years,".tif", sep=""))
s<-round(seq(1,67,len=16))

plot(t[[s]])

patch<-stack(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/pres_abs_sss_weighted_ensemble_sdm_", years,".tif", sep=""))
plot(patch[[s]])

m<-cellStats(t, stat="mean")
sd<-cellStats(t, stat="sd")

plot(years,m, type="l", main="Average habitat suitability over time", ylim=c(0,0.7), ylab="Suitability index", xlab="Years")
lines(years, m+(2*sd), col="red", lty=3)
lines(years, m-(2*sd), col="red", lty=3)




```

####Patches

Plots of the number of cells with predicted presence and number of patches (contiguous presence) over 1950-2016.

```{r, warning=FALSE, echo=FALSE}
year_patch<-data.frame(years = years, patch_num = numeric(length(years)) )


for (i in 1:length(years)){
c<-clump(patch[[i]])
year_patch[i,2]<-max(na.omit(values(c)))
#print(i)
}
par(mar=c(4,4,4,5))

mk<-cellStats(patch, stat="sum")
plot(years,mk, type="l", main="Predicted patch presence", ylab="Suitable squares", xlab="Years", col="red")
par(new=TRUE)
par(mar=c(4,4,4,5))
plot(year_patch$years, year_patch$patch_num,type="l",col="blue",xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("Number of Patches",side=4,line=3)
legend("topright",col=c("red","blue"),lty=1,legend=c("Suitable Squares","Number of Patches"))

```



## Demoniche 

####Formatting the population occurrence points

Formatting the LPI population data for use in Demoniche, they start as the "seed" populations. Might be better to use GBIF data for this - unrealistic that the LPI populations are the only existing populations in 1950 - alternatively a historical map of where the ibex were in 1950?

```{r, warning=FALSE, message=FALSE}
library(demoniche)
library(rgdal)
library(raster)
species<-"Capra_ibex"

df2<-read.csv("LPI_pops_20160523_edited.csv")
pyr<-subset(df2, Binomial ==species & Specific_location==1)    #record 11470 had wrong longitude - in Russia!

#formatting the data for use in demoniche
pyrs<-pyr[,c("ID","Longitude","Latitude")]

id<-pyrs$ID*100
lam<-rep(1,length(id))    #not sure what the value here pertains to - think it sets starting population so should use values from LPI?
pyrxy<-SpatialPoints(pyr[,c("Longitude","Latitude")])

wd<-getwd()
sdm<-raster(paste(wd,"/Alp_SDMs/Ensembles_2006_2016/pres_abs_kappa_weighted_ensemble_sdm_1950.tif", sep=""))
e2<-extent(sdm)

r<-raster(e2, resolution=res(sdm))

rz<-rasterize(pyrxy,r,lam )
rid<-rasterize(pyrxy,r,id)
# plot(rz)
# plot(rid)

rz_spdf<-xyFromCell(rz, 1:ncell(rid))

rzm<-as.vector(rz)
ridm<-as.vector(rid)

df<-data.frame(ridm,rz_spdf,rzm)
colnames(df)<-c( "PatchID","X","Y","area")

Populations<-data.frame(na.omit(df)) 

```

####Formatting the habitat suitability models

Formatting the habitat suitability model maps into vectors for use in Demoniche and plotting the average habitat suitability over time. 
Here we also create a fake set of habitat suitability models where the suitability is driven down at a constant rate over time.

```{r, cache=TRUE, message=FALSE, warning=FALSE}
library(raster)

years<-1950:2016

sdm_patch_df<-data.frame(ID=1:ncell(rid))
sdm_df<-data.frame(ID=1:ncell(rid))
sdm_fake_df<-data.frame(ID=1:ncell(rid))

#formatting data for demoniche
for (i in 1:length(years)){
  
  #a selection of different threshold techniques for presence absence, as well as a suitability surface
  sdm<-raster(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/weighted_ensemble_sdm_", years[i],".tif", sep=""))   #14.6
  e<-extent(sdm)
  patch<-raster(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/pres_abs_sss_weighted_ensemble_sdm_", years[i],".tif", sep="")) #21.1%  
  patch<-crop(patch, e)

  #fake<-raster(paste(wd, "/Alp_SDMs/Fake_Landscape/Fake_Landscape_", years[i], ".tif", sep=""))
  if (i ==1){
    vec<-as.data.frame(sdm, xy = TRUE)
    vec_pat<-as.data.frame(patch, xy=TRUE)
    vec_fake<-as.data.frame(fake, xy=TRUE)
  } else{
    vec<-as.data.frame(sdm)
    vec_pat<-as.data.frame(patch)
    vec_fake<-as.data.frame(fake)
  }
  
  sdm_df<-cbind(sdm_df, vec)
  sdm_patch_df<-cbind(sdm_patch_df,vec_pat)
  sdm_fake_df<-cbind(sdm_fake_df, vec_fake)
  #print(i)
}

sdm_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]
sdm_patch_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]
sdm_fake_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]

niche_map_mine<-sdm_df
colnames(niche_map_mine)[1:3]<-c("gridID", "X", "Y")

patch_map_mine<-sdm_patch_df
colnames(patch_map_mine)[1:3]<-c("gridID", "X", "Y")

fake_map_mine<-sdm_fake_df
colnames(fake_map_mine)[1:3]<-c("gridID", "X", "Y")

niche_spin_up<-matrix(rep(niche_map_mine[,4], 99), nrow=nrow(niche_map_mine))
niche_spin_up<-cbind(niche_map_mine[,1:3],niche_spin_up, niche_map_mine[,4:ncol(niche_map_mine)])

patch_spin_up<-matrix(rep(patch_map_mine[,4], 99), nrow=nrow(patch_map_mine))
patch_spin_up<-cbind(patch_map_mine[,1:3],patch_spin_up, patch_map_mine[,4:ncol(patch_map_mine)]) #last patch used to be niche

fake_spin_up<-matrix(rep(fake_map_mine[,4], 99), nrow=nrow(fake_map_mine))
fake_spin_up<-cbind(fake_map_mine[,1:3],fake_spin_up, fake_map_mine[,4:ncol(fake_map_mine)])


col_years_short<-paste("Year_", 1950:2016, sep="")
col_years<-paste("Year_", 1850:2016, sep="")

colnames(niche_map_mine)[4:length(colnames(niche_map_mine))]<-col_years_short
colnames(patch_map_mine)[4:length(colnames(patch_map_mine))]<-col_years_short
colnames(fake_map_mine)[4:length(colnames(fake_map_mine))]<-col_years_short

colnames(niche_spin_up)[4:length(colnames(niche_spin_up))]<-col_years
colnames(patch_spin_up)[4:length(colnames(patch_spin_up))]<-col_years
colnames(fake_spin_up)[4:length(colnames(fake_spin_up))]<-col_years


fake_spin_up[is.na(fake_spin_up)]<-0
#niche_formulas <- as.formula(paste(paste(colnames(niche_map_mine)[-c(1:3)], collapse="+"),"X+Y",sep="~"))

#print(levelplot(niche_formulas, niche_map_mine, col.regions=rev(heat.colors(100)), main = "Niche Values"))

no_yrs_mine<-1 #number of years each time period represents 

years_short<-1950:2016
plot(years_short,colMeans(na.omit(niche_map_mine)[4:length(colnames(niche_map_mine))]), type="l", ylab="Mean suitability index")
#

#plot(years_short,colMeans(na.omit(niche_map_mine)[904:length(colnames(niche_map_mine))]), type="l", ylab="Mean suitability index")

niche_map_mine<-na.omit(niche_map_mine)
patch_map_mine<-na.omit(patch_map_mine)
fake_map_mine<-na.omit(fake_map_mine)

niche_spin_up<-na.omit(niche_spin_up)
patch_spin_up<-na.omit(patch_spin_up)
fake_spin_up<-na.omit(fake_spin_up)

```

####COMADRE

Accessing the population matrices from COMADRE - there are 5 matrices available for the alpine ibex but four are for the same area and only represent survival over two time periods in good/bad conditions. 

<span style="color:red">Could I use these to calibrate the survival aspect of the matrices?</span>

####Demoniche setup
Parameterising the demoniche model

```{r, warning=FALSE, message=FALSE}
#Population matrix set up
#wd<-("C:/Users/Fiona/Documents/PhD/PhD_Method")

load(paste(wd, "COMADRE_v.2.0.1.RData", sep="/"))

#load(paste(wd, "COMADRE_v.1.0.0.RData", sep="/"))

species<-"Capra_ibex"

tempMetadata<-subset(comadre$metadata, SpeciesAccepted==species)

keep<-as.numeric(rownames(tempMetadata))

tempMat<-comadre$mat[keep]   #MatA is matrix pop model, can be split into U, F and/or C

MatList<-list(tempMat[[1]][[1]])  #varies depending on number of matrices - need to find a way to code this better - now have five matrices available so need to sort this
AllMat<-unlist(MatList)
matrices<-matrix(AllMat, ncol=length(MatList))
colnames(matrices)<- c("Reference_matrix")


prob_scenario<-c(0.5,0.5)    #need to check this

noise<-0.90     #not yet active in demoniche

stages<-comadre$matrixClass[keep][[1]]$MatrixClassAuthor
#stages<-comadre$matrixClass[keep][[2]]$MatrixClassAuthor
#stagesf<-stages[1:3]

list_names_matrices<-colnames(matrices)

sumweight<-rep(1, length(stages)) #weight of stages  - should be equal for all mine just 
#in plants seed not included in calculating population sizes - or if you wanted to just 
#calculate the female population it would be c(1,1,1,0,0,0)
#sumweightf<-c(1,1,1)

transition_affected_niche<-c(2,11,20)   #which parts of the matrix are affected by the c(1,2) is juveniles - as if the matrix is a vector L-R
transition_affected_niche<-"all"  #which parts of the matrix are affected by the c(1,2) is juveniles
#niche values

transition_affected_env <- "all"

transition_affected_demogr <- "all"

env_stochas_type<-"normal"   #can also be lognormal


matrices_var <- matrix(1, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 
#standard deviation of matrices

proportion_initial<- rep(1/length(stages), length(stages)) #proportion of population in 
#each stage - no idea what this should be and will likely have a big impact on results! 
#- just doing eqaul splits for now
#proportion_initialf<- c(1/3,1/3,1/3)

density_individuals <- 4000  #4292.32 to 16096.2 based on density being between 8 and 30 per 100 ha and the area of each cell being 53654 ha - 


K_weight<-c(rep(1, length(stages)))  #the weight with which carrying capacity affects each stage was FALSE


#niche_map_mine[is.na(niche_map_mine)]<-0
patch_map_mine[is.na(patch_map_mine)]<-0
```


```{r, cache=TRUE, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}

#Scaling carrying capacity (as estimated above) in three different ways, linear, sigmoidal and linear threshold.
#plotting functions linking k and hsi

k<-5000#set to one when using filzbach estimates - otherwise set to a standard value across all pops
lin<-function(x){
  x*k
  }

sig<-function(x){
  k*(1/(1+exp(-10*x+5)))
  }   #could also try with 18x + 9 - closer to SM in Damaris paper

lt<-function(x) { 
  val = (4/3) * x - (1/3)
  val[x < 0.25] = 0 
  val<-val*k
  return(val)
}


#carrying capacity function 

lf<-list.files(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/", sep=""))   

files<-lf[grepl("^weighted_ensemble_sdm_.*.tif$", lf)]

sdms<-stack(paste(wd,"/Alp_SDMs/New_Ensembles_2006_2016/", files, sep=""))


# ks_df<-read.csv("carrying_capacity_log_likelihood_capra_ibex.csv")
# ks_df$PatchID<-ks_df$ID*100
# 
# #for 1950-2016
# #sdms<-sdms[[901:967]]
# 
# 
# ks_xy<-merge(Populations, ks_df[,c(2:4)], by="PatchID")
# 

hsi<-extract(sdms, ks_xy[,c(2,3)])


link<-lin(hsi)
#links<-link*ks_xy$ks

sigk<-sig(hsi)
#sigks<-sigk*ks_xy$ks

ltk<-lt(hsi)
#ltks<-ltk*ks_xy$ks

#plot(links[,c(900:967)], type="l")

spin<-replicate(100,link[,1])
link_spin<-cbind(spin, link)

colnames(link_spin)[1:100]<-paste("weighted_ensemble_sdm_", spin_years, sep="")
link_spin<-link_spin[,-ncol(link_spin)]

```

####Varying standard deviation of population matrix, long distance dispersal and kernel shape


Changed the demoniche_setup function (now demoniche_setup_me.R) to change the dispersal function to a decay curve where the half-life is the median estimated dispersal distance.This was based on Bowman et al 2012 where it suggests that the maximum dispersal is 40x the square root of a species home range and median dispersal is 7x the square root of HR. 



```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, eval=FALSE}
#setwd("C:Users/Fiona/Documents/Demoniche")

sd_seq<-0.5
#matrices_var<-matrix(0.45, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 
#k_seq<-c(1000,2000,4000,8000,16000,32000)
LDD_seq<-c(0.9)
kern_seq<-list(c(19.775,113),c(13.5975, 77.7), c(1000,1000))

var_grid<-expand.grid(sd_seq, LDD_seq, kern_seq)
colnames(var_grid)<-c("SD", "LDD", "Kern")

kern_mat<-matrix(c(rep(c(19.775,113), (nrow(var_grid)/ncol(var_grid))),rep(c(13.5975, 77.7), (nrow(var_grid)/ncol(var_grid))),rep(c(1000,1000),(nrow(var_grid)/ncol(var_grid)))), ncol=2, byrow=T)



source("demoniche_setup_me.R")
source("demoniche_model_me.R")

for (s in 1:nrow(var_grid)){

  print(paste (s, " out of ", nrow(var_grid) ), sep="")
  
  SD<-var_grid[s,1]
  LDD<-var_grid[s,2]
  
  
  matrices_var<-matrix(SD, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

start.time <- Sys.time()

 max_disp<-as.character(kern_mat[s,2])
dir.create(paste(wd,"/Demoniche_Repetitions/Kern_kap_new_0_5sd/max_disp_",max_disp,sep=""),showWarnings = TRUE)

reps<-12

rep_demoniche<-function(i){
  library(demoniche)
  source("demoniche_model_me.R")
 demoniche_setup_me(modelname = "Capra_k_16000",Populations = Populations, Nichemap = patch_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 2671,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = 0.1, fraction_SDD = 0.1,
                  dispersal_constants = kern_mat[s,],
                #dispersal_constants = c(0.7, 0.7, 0.1,3), 
                transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=link_spin, Kweight = K_weight, 
                  sumweight =sumweight)
 

c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("Demoniche_Repetitions/Kern_kap_new_0_5sd/max_disp_",max_disp,"/",i, sep=""))
}


#lapply(1:reps, rep_demoniche)

library(doParallel)

if (Sys.info()["nodename"] == "FIONA-PC"){
 cl <- makeCluster(4) 
} else {
 cl <- makeCluster(2)
}


registerDoParallel(cl)
foreach(i=(1:reps)) %dopar% rep_demoniche(i)
stopCluster(cl)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken 
}

#lapply(1:reps, rep_demoniche)

```

```{r,message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
library(dplyr)

 rep_df_all<-data.frame()
 plot_rep<-function(proj_path){
  
  load(proj_path)
  #id<-gsub("C:/Users/Fiona/Documents/PhD/PhD_Method/Demoniche_Repetitions/Kern_kap/max_disp_", "", proj_path)
  id<-gsub("D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Kern_kap_new_0_5sd/max_disp_", "", proj_path)
  id<-gsub("Projection_rep1_Reference_matrix.rda", "",id)
  md_id<-strsplit(id, "/")[[1]][1]
  rep_id<- gsub(".*[/]([^/]+)[/]*", "\\1", id)
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),])
  tid<-cbind(md_id, rep_id, trend)
  return(tid)
  }

wd<-getwd()
wd<-paste(wd, "/Demoniche_Repetitions/Kern_kap_new_0_5sd/", sep="")

folders<-list.files(wd)

for (folder in folders){

  print(folder)

  f<-paste(wd,folder, sep="")

  lf<-list.dirs(f, recursive = F)

#path<-paste(f, lf, sep="")

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  rep_df$md_id<-as.factor(rep_df$md_id)

  #  spin<-ggplot(rep_df, aes(x = year, y= trend, group=md_id))+
  #   geom_line( alpha=0.5)
  # 
  # plot(spin)
  
  rep_df_short<-rep_df[rep_df$year >=1950,]


  # p<-ggplot(rep_df_short, aes(x = year, y= trend, group=md_id))+
  #   geom_line( alpha=0.5)
  

  rep_df_all<-rbind(rep_df,rep_df_all)
  
}

#write.csv(rep_df_all, "kern_kap_new_params_0_5sd.csv")
```


```{r, message=FALSE, warning=FALSE}

rep_df_all<-read.csv("kern_kap_new_params_0_5sd.csv")

rep_df_all$rep_id<-factor(rep_df_all$rep_id)
rep_df_all$md_id<-factor(rep_df_all$md_id)

rep_df_all$trend<-as.numeric(as.character(rep_df_all$trend))

```


```{r}

library(ggplot2)

p01<-ggplot(rep_df_all, aes(x=year, y=trend, group=interaction(rep_id, md_id),colour=md_id))+
  geom_line()+ 
   theme(text = element_text(size=9))+ 
  labs(color='Maximum \ndispersal \ndistance') 
p01
```



```{r}
library(data.table)
wd<-getwd()
highfoldernames<-c("max_disp_77.7","max_disp_113", "max_disp_1000")
lowfoldernames<-rep(c("1", "2", "3", "4", "5", "6"), each=3)

foldernames<-paste(highfoldernames, lowfoldernames, sep="/")

lpi<-read.csv("LPI_pops_20160523_edited.csv")

alpine<-lpi[lpi$ID == 10696 | lpi$ID == 10714 | lpi$ID == 10694 | lpi$ID == 10717 | lpi$ID == 10713 |lpi$ID == 10718 |lpi$ID == 10695 |lpi$ID == 539 |lpi$ID == 10710 ,]

xy<-cbind(alpine$Longitude, alpine$Latitude)

convert_pop_out<-function(foldername){
  
  pop_out<-read.csv(paste(wd,"/Demoniche_repetitions/Kern_kap_new_0_5sd/" ,foldername, "/pop_output.csv", sep=""), header = TRUE)
  pop_out<-pop_out[,-1]
  coordinates(pop_out) <- ~ X + Y
  gridded(pop_out) <- TRUE
  rasterDF <- stack(pop_out)
  proj4string(rasterDF)<-CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ")
  trends<-extract(rasterDF,xy)
  max_disp<-strsplit(foldername, "[/_]")[[1]][3]
  rep_id<-strsplit(foldername, "[/_]")[[1]][4]
  trends_df<-data.frame(alpine$ID,max_disp, rep_id,trends)
#  write.csv(trends_df, paste(wd, "/", foldername, "/pop_trend_output.csv", sep=""))
}

demoniche_pop_out<-lapply(foldernames, convert_pop_out)
df <- do.call("rbind", demoniche_pop_out)
dfm<-as.matrix(df)

lambda<-function(x){

  l10<-10^diff(log10(as.numeric(x[4:length(x)])))
  
}

dft<-t(apply(dfm,1,lambda))

df_lambda<-data.frame(dfm[,1:3],dft)

colnames(df_lambda)[4:ncol(df_lambda)]<-colnames(dfm)[5:ncol(dfm)]

melt_df<-melt(df, id=1:3)
melt_df$year<-as.numeric(gsub("Year_", "", melt_df$variable))

melt_lambda<-melt(df_lambda, id=1:3)
melt_lambda$year<-as.numeric(gsub("Year_", "", melt_lambda$variable))

melt_short<-melt_df[melt_df$year>1949,]
melt_short$alpine.ID<-as.factor(melt_short$alpine.ID)

melt_lambda_short<-melt_lambda[melt_lambda$year>1950,]
melt_lambda_short$alpine.ID<-as.factor(melt_lambda_short$alpine.ID)

ggplot(melt_short, aes(x= year, y=value, group=interaction(rep_id, max_disp), colour= alpine.ID))+
  geom_line()+
  facet_grid(max_disp~ alpine.ID)

ggplot(melt_lambda_short, aes(x= year, y=value, group=interaction(rep_id, max_disp), colour= alpine.ID))+
  geom_line()+
  facet_grid(max_disp~ alpine.ID)


# library(gghighlight)
# 
# ggplot(melt_short, aes(x= year, y=value, group=interaction(rep_id, max_disp), colour= alpine.ID))+
#   geom_line()+
#   facet_wrap(.~max_disp)
# 
# 
# gghighlight_line(melt_short, aes(x= year, y=value, group=rep_id), max_disp =="77.7")+
#   facet_wrap(.~max_disp)

```


```{r, message=FALSE}

pops<-alpine[,c(1,65:130)]
colnames(pops)[2:ncol(pops)]<-paste("Year", 1950:2015, sep="_")
pops[pops=="NULL"]<-NA
pops$rep_id<-"Observed"
pops$md_id<-"Observed"

library(taRifx)
library(mgcv)
library(plyr)
popsm<-as.matrix(pops)

gam_lpi<-function(x){
   #subsetting the population data by each population 
  spid = x[2:(length(x)-2)]                     #subsetting only the dates
  names(spid)<-1950:2015              #renaming the date column names as R doesn't like numbered column names
  spid<-as.numeric(spid)
  pop_datab <- (!is.na(spid) )
  points = sum(pop_datab)
  id<-x[1]
  Date<-1950:2015
  spidt<-destring(t(spid))
  time<-length(min(which(!is.na(spidt))):max(which(!is.na(spidt))))
  missing<-time-points
  
  Year<-Date[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population<-spidt[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population[Population == 0] <- mean(Population, na.rm=TRUE)*0.01 #if a population is zero one year thhis is replaced with 1% of the average population estimate - because you can log zeros
  
  df<-data.frame(Year,Population)
  
  #not sure what this does - adding a constant of 1 so that logging doesn't go weird?
  if (sum(na.omit(df$Population<1))>0) {
    df$Population<-df$Population+1
  } 
    
  
  if (points >=6) {           
    PopN = df$Population
    if (length(na.omit(PopN)) >=6) {
      SmoothParm = round(length(na.omit(PopN))/2)    
    } else {
      SmoothParm=3
    }
    
    mg2<-mgcv:::gam(PopN ~ s(Year, k=SmoothParm), fx=TRUE)
    pv2 <- predict(mg2,df,type="response",se=TRUE) 
    R_sq2<-summary(mg2)$r.sq
    model<-1
    pv2$fit[pv2$fit <= 0] <- NA
    

    lambda2<-pv2$fit

    ial<-data.frame(id, Year,lambda2)
   
    colnames(ial)<-c("ID", "Year", "Abundance")
  }

  return(ial)
}

gam_lpi_r<-apply(popsm,  1, gam_lpi)
gam_r<-do.call( "rbind", gam_lpi_r)

fill<-data.frame(rep(pops$ID, each=length(1950:2015)), 1950:2015)
colnames(fill)<-c("ID", "Year")

all_year_ab<-join(fill, gam_r, type="right")

all_year_ab$max_disp<-"Observed"
all_year_ab$rep_id<-"Observed"

colnames(all_year_ab)[1:3]<-c("alpine.ID", "year", "value")


```

```{r}
mldab<-melt_short[,-4]
all_year_ab$alpine.ID<-as.factor(all_year_ab$alpine.ID)
all_year_ab$max_disp<-as.factor(all_year_ab$max_disp)
all_year_ab$rep_id<-as.factor(all_year_ab$rep_id)
all_year_ab$value<-as.numeric(all_year_ab$value)
all_year_ab$year<-as.numeric(all_year_ab$year)


both_df_ab<-rbind(mldab, all_year_ab)

both_df_ab[both_df_ab$alpine.ID == "  539",]$alpine.ID<-539

```

```{r}
library(ggplot2)


ggplot(mldab, aes(x= year, y=value, group=interaction(rep_id, max_disp,alpine.ID), colour= alpine.ID))+
  geom_line(colour="grey")+
  geom_line(data=both_df_ab[both_df_ab$max_disp=="Observed",], aes(x=year, y=value), colour="red")+
  facet_grid(.~ alpine.ID)


```

```{r, warning=FALSE, message=FALSE} 


pops<-alpine[,c(1,65:130)]
colnames(pops)[2:ncol(pops)]<-paste("Year", 1950:2015, sep="_")
pops[pops=="NULL"]<-NA
pops$rep_id<-"Observed"
pops$md_id<-"Observed"

library(taRifx)
popsm<-as.matrix(pops)

gam_lpi<-function(x){
   #subsetting the population data by each population 
  spid = x[2:(length(x)-2)]                     #subsetting only the dates
  names(spid)<-1950:2015              #renaming the date column names as R doesn't like numbered column names
  spid<-as.numeric(spid)
  pop_datab <- (!is.na(spid) )
  points = sum(pop_datab)
  id<-x[1]
  Date<-1950:2015
  spidt<-destring(t(spid))
  time<-length(min(which(!is.na(spidt))):max(which(!is.na(spidt))))
  missing<-time-points
  
  Year<-Date[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population<-spidt[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population[Population == 0] <- mean(Population, na.rm=TRUE)*0.01 #if a population is zero one year thhis is replaced with 1% of the average population estimate - because you can log zeros
  
  df<-data.frame(Year,Population)
  
  #not sure what this does - adding a constant of 1 so that logging doesn't go weird?
  if (sum(na.omit(df$Population<1))>0) {
    df$Population<-df$Population+1
  } 
    
  
  if (points >=6) {           
    PopN = log10(df$Population)
    if (length(na.omit(PopN)) >=6) {
      SmoothParm = round(length(na.omit(PopN))/2)    
    } else {
      SmoothParm=3
    }
    
    mg2<-mgcv:::gam(PopN ~ s(Year, k=SmoothParm), fx=TRUE)
    pv2 <- predict(mg2,df,type="response",se=TRUE) 
    R_sq2<-summary(mg2)$r.sq
    model<-1
    pv2$fit[pv2$fit <= 0] <- NA
    

    lambda2<-diff(pv2$fit)

    ial<-data.frame(id, Year[-length(Year)], 10^lambda2)
   
    colnames(ial)<-c("ID", "Year", "R")
  }

  return(ial)
}

gam_lpi_r<-apply(popsm,  1, gam_lpi)
gam_r<-do.call( "rbind", gam_lpi_r)

fill<-data.frame(rep(pops$ID, each=length(1950:2015)), 1950:2015)
colnames(fill)<-c("ID", "Year")

all_year_r<-join(fill, gam_r, type="right")

all_year_r$max_disp<-"Observed"
all_year_r$rep_id<-"Observed"

colnames(all_year_r)[1:3]<-c("alpine.ID", "year", "value")

```



```{r}

mld<-melt_lambda_short[,-4]
all_year_r$alpine.ID<-as.factor(all_year_r$alpine.ID)
all_year_r$max_disp<-as.factor(all_year_r$max_disp)
all_year_r$rep_id<-as.factor(all_year_r$rep_id)
all_year_r$value<-as.numeric(all_year_r$value)
all_year_r$year<-as.numeric(all_year_r$year)


both_df<-rbind(mld, all_year_r)

```


need to add in x axis. do plots separately for each of the dispersal options?
```{r}
library(ggplot2)

both_df<-both_df[both_df$max_disp != "1000",]

ggplot(both_df, aes(x= year, y=value, group=interaction(rep_id, max_disp,alpine.ID), colour= alpine.ID))+
  geom_line(colour="grey")+
  geom_line(data=both_df[both_df$max_disp=="Observed",], aes(x=year, y=value), colour="red")+
  facet_grid(.~ alpine.ID)


```





#############ignore below here


```{r, eval=FALSE, echo=FALSE}

start.time <- Sys.time()

library(demoniche)
source("demoniche_model_me.R")
#source("demoniche_model_me_par.R")
sd<-0.01

matrices_var<-matrix(sd, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

  demoniche_setup(modelname = "niche_2000k",Populations = Populations, Nichemap = fake_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 4000,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = 0.1, fraction_SDD = 0.9,
                  dispersal_constants = c(0.7,0.7,0.1,2),
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=200000, Kweight = K_weight, 
                  sumweight =sumweight)
niche_test <- demoniche_model_me(modelname = "niche_2000k", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("SD_", sd, sep=""))

#result <- foreach(i=10:10000) %dopar% getPrimeNumbers(i)
  
n_2000<-(niche_test[,"Meanpop","Reference_matrix"])

plot(n_2000[(nrow(n_2000-67)):length(n_2000)], type="l", ylab="Number of Alpine Ibex", xlab="")

10^mean(diff(log10(n_2000[(nrow(n_2000-67)):length(n_2000))])))

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken 

```


####Testing impact of variables

Varying carrying capacity, long distance dispersal, short distance dispersal and density.

```{r, message=FALSE, warning=FALSE, cache=TRUE, eval=FALSE}
#setwd("C:Users/Fiona/Documents/Demoniche")

sd_seq<-c(0.25,0.3,0.35,0.4,0.45)
matrices_var<-matrix(0.45, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

k_seq<-c(1000,2000,4000,8000,16000,32000)
LDD_seq<-c(0.1, 0.5, 0.9)
SDD_seq<-c(0.1, 0.5, 0.9)
dens_seq<-c(100, 400, 1000, 4000)

var_grid<-expand.grid(k_seq, LDD_seq, SDD_seq, dens_seq)
colnames(var_grid)<-c("K", "LDD", "SDD", "density")

for (s in 1:nrow(var_grid)){
print(s)

  K<-var_grid[s,1]
  LDD<-var_grid[s,2]
  SDD<-var_grid[s,3]
  density<-var_grid[s,4]
#sdf<-gsub("\\.", "_", s)  

start.time <- Sys.time()

dir.create(paste("D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Four_Vars_Prob/K_",K,"_LDD_",LDD,"_SDD_", SDD, "_dens_", density ,sep=""))

reps<-5

rep_demoniche<-function(i){
  library(demoniche)
  source("demoniche_model_me.R")
 demoniche_setup(modelname = "Capra_k_16000",Populations = Populations, Nichemap = niche_spin_up,   #CHANGED TO NICHE
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = density,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = LDD, fraction_SDD = SDD,
                  dispersal_constants = c(0.7,0.7,0.1,2),
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=K, Kweight = K_weight, 
                  sumweight =sumweight)
c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("Demoniche_Repetitions/Four_Vars/K_",K,"_LDD_",LDD,"_SDD_", SDD, "_dens_", density,"/rep_",i, sep=""))
}


#lapply(1:reps, rep_demoniche)

library(doParallel)

if (Sys.info()["nodename"] == "FIONA-PC"){
 cl <- makeCluster(4) 
} else {
 cl <- makeCluster(2)
}

registerDoParallel(cl)
foreach(i=(1:reps)) %dopar% rep_demoniche(i)
stopCluster(cl)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken 
}


```

```{r,message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
library(ggplot2)
library(dplyr)

wd<-"D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Four_Vars/"

folders<-list.files(wd)

for (folder in folders){

  print(folder)

  f<-paste(wd,folder, sep="")

  lf<-list.dirs(f, recursive = F)

#path<-paste(f, lf, sep="")

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  plot_rep<-function(proj_path){
  
  load(proj_path)
  id<-gsub("\\D", "", proj_path)
  id<-as.numeric(substr(id, 1, nchar(id)-1))
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),])
  tid<-cbind(id, trend)
  return(tid)
  }

  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  rep_df$id<-as.factor(rep_df$id)


  spin<-ggplot(rep_df, aes(x = year, y= trend, group=id))+
    geom_line( alpha=0.5)

  #plot(spin)
  
  rep_df_short<-rep_df[rep_df$year >=1950,]


  p<-ggplot(rep_df_short, aes(x = year, y= trend, group=id))+
    geom_line( alpha=0.5)
  
  #plot(p)
  
  lambdas<-rep_df_short %>% 
  group_by(id) %>%
  summarise(lambda = 10^mean(diff(log10(trend))))
  
  #print(lambdas)
  
 if (!is.nan(sum(lambdas$lambda))){
  boxplot(lambdas$lambda)
}

  }
```


####Plotting the impact of different variables 

```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}

library(ggplot2)

wd_rep<-paste(wd, "/Demoniche_Repetitions/Four_Vars/", sep="")


folders<-list.files(wd_rep)

rep_df_all<-data.frame()

for (folder in folders){

  #print(folder)

  f<-paste(wd,folder, sep="")

  lf<-list.dirs(f, recursive = F)

#path<-paste(f, lf, sep="")

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  plot_rep<-function(proj_path){
  
  load(proj_path)
  k_id<-strsplit(proj_path, "[_/]")[[1]][12]
  ldd_id<-strsplit(proj_path, "[_/]")[[1]][14]
  sdd_id<-strsplit(proj_path, "[_/]")[[1]][16]
  dens_id<-strsplit(proj_path, "[_/]")[[1]][18]
  rep_id<-strsplit(proj_path, "[_/]")[[1]][20]
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),901:966])
  tid<-cbind(k_id, ldd_id, sdd_id, dens_id, rep_id, trend)
  
  return(tid)
  }
  
  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  #rep_df$id<-as.factor(rep_df$id)

  rep_df_all<-rbind(rep_df,rep_df_all)
  
}

#write.csv(rep_df_all, "fourvars_sdd_ldd_dens_k.csv")

```

```{r, message=FALSE, warning=FALSE}

rep_df_all<-read.csv("fourvars_sdd_ldd_dens_k.csv")

rep_df_all$trend<-as.numeric(as.character(rep_df_all$trend))

rep_df_all$dens_id_f<-factor(rep_df_all$dens_id,labels=c("dens:100", "dens:400", "dens:1000", "dens:4000") ,levels=c("100", "400", "1000", "4000"))

rep_df_all$k_id_f<-factor(rep_df_all$k_id, labels=c("K:1000","K:2000",  "K:4000", "K:8000", "K:16000", "K:32000"), levels=c("1000","2000",  "4000", "8000", "16000", "32000"))

rep_df_all$sdd_id_f<-factor(rep_df_all$sdd_id,labels=c("SDD:0.1","SDD:0.5","SDD:0.9") ,levels=c("0.1","0.5","0.9"))

rep_df_all$ldd_id_f<-factor(rep_df_all$ldd_id,labels=c("LDD:0.1","LDD:0.5","LDD:0.9") ,levels=c("0.1","0.5","0.9"))

rep_df_all$rep_id_f<-factor(rep_df_all$rep_id)

```

Plotting how the short distance dispersal, carrying capacity and density impact population trends when the probability of long distance dispersal is low (**0.1**).

```{r}
#devtools::install_github("thomasp85/patchwork")
library(ggplot2)
#library(patchwork)

df_ldd_01<-rep_df_all[rep_df_all$ldd_id == 0.1,]

p01<-ggplot(df_ldd_01, aes(x=year, y=trend, group=interaction(rep_id_f, sdd_id_f), colour=sdd_id_f))+
  geom_line() + 
  facet_grid(k_id_f ~ dens_id_f, labeller = label_context)+
   theme(text = element_text(size=10))+ 
  labs(color='Chance of short \ndistance dispersal') 
p01
```

Plotting how the short distance dispersal, carrying capacity and density impact population trends when the probability of long distance dispersal is **0.5**.

```{r}
df_ldd_05<-rep_df_all[rep_df_all$ldd_id == 0.5,]

p05<-ggplot(df_ldd_05, aes(x=year, y=trend,group=interaction(rep_id_f, sdd_id_f) ,colour=sdd_id_f))+
  geom_line() + 
  facet_grid(k_id_f ~ dens_id_f, labeller = label_context)+
 theme(text = element_text(size=9))+
  labs(color='Chance of short \ndistance dispersal') 
  p05
```

Plotting how the short distance dispersal, carrying capacity and density impact population trends when the probability of long distance dispersal is **0.9**.

```{r}
df_ldd_09<-rep_df_all[rep_df_all$ldd_id == 0.9,]

p09<-ggplot(df_ldd_09, aes(x=year, y=trend, group=interaction(rep_id_f, sdd_id_f),colour=sdd_id_f))+
  geom_line() + 
  facet_grid(k_id_f ~ dens_id_f, labeller = label_context)+ 
  theme(text = element_text(size=9))+
  labs(color='Chance of short \ndistance dispersal') 

p09


```




####Varying carrying capacity, long distance dispersal and standard deviation of population matrix

```{r, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}

library(ggplot2)

wd<-"D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Three_Vars/"

folders<-list.files(wd)

rep_df_all<-data.frame()

for (folder in folders){

  #print(folder)

  f<-paste(wd,folder, sep="")

  lf<-list.dirs(f, recursive = F)

#path<-paste(f, lf, sep="")

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  plot_rep<-function(proj_path){
  
  load(proj_path)
  k_id<-strsplit(proj_path, "[_/]")[[1]][12]
  ldd_id<-strsplit(proj_path, "[_/]")[[1]][14]
  sd_id<-strsplit(proj_path, "[_/]")[[1]][16]
  rep_id<-strsplit(proj_path, "[_/]")[[1]][20]
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),901:966])
  tid<-cbind(k_id, ldd_id, sd_id, rep_id, trend)
  
  return(tid)
  }
  
  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  #rep_df$id<-as.factor(rep_df$id)

  rep_df_all<-rbind(rep_df,rep_df_all)
  
}

write.csv(rep_df_all, "threevars_sd_ldd_k.csv")

```


```{r, message=FALSE, warning=FALSE}

rep_df_all<-read.csv("threevars_sd_ldd_k.csv")

rep_df_all$trend<-as.numeric(as.character(rep_df_all$trend))

rep_df_all$k_id_f<-factor(rep_df_all$k_id,levels=c("1000","2000",  "4000", "8000", "16000", "32000") ,labels=c("K:1000","K:2000",  "K:4000", "K:8000", "K:16000", "K:32000"))

rep_df_all$sd_id_f<-factor(rep_df_all$sd_id,levels=c("0.25","0.3","0.35","0.4","0.45") ,labels=c("SD:0.25","SD:0.3","SD:0.35","SD:0.4","SD:0.45"))

rep_df_all$ldd_id_f<-factor(rep_df_all$ldd_id, levels=c("0.1","0.5","0.9"))

rep_df_all$rep_id_f<-factor(rep_df_all$rep_id)

```


```{r}
library(ggplot2)

p01<-ggplot(rep_df_all, aes(x=year, y=trend, group=interaction(rep_id_f, ldd_id_f),colour=ldd_id_f))+
  geom_line() + 
  facet_grid(k_id_f ~ sd_id_f, labeller = label_context)+
  theme(text = element_text(size=9))+ 
  labs(color='Chance of long \ndistance dispersal')
  
p01
```

####Using simulated habitat data

Basing the models on environmental data where the trend is known and constant - to better understand the impacts of the other variables.

```{r, message=FALSE, warning=FALSE, cache=TRUE, eval=FALSE}

plot(years_short,colMeans(na.omit(fake_map_mine)[4:length(colnames(fake_map_mine))]), type="l", ylab="Mean fake suitability index")

#setwd("C:Users/Fiona/Documents/Demoniche")

sd_seq<-c(0.5, 0.75,1, 1.25, 1.5)
#matrices_var<-matrix(0.45, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 
#k_seq<-c(1000,2000,4000,8000,16000,32000)
LDD_seq<-c(0.1, 0.5, 0.9)
kern_seq<-list(c(0.5,1,1,1),c(0.5,1,1,5), c(1,1,1,1), c(1,1,1,5))

var_grid<-expand.grid(sd_seq, LDD_seq, kern_seq)
colnames(var_grid)<-c("SD", "LDD", "Kern")

kern_mat<-matrix(c(rep(c(0.5,1,1,1), (nrow(var_grid)/length(unique(kern_seq)))),rep(c(0.5,1,1,5), (nrow(var_grid)/length(unique(kern_seq)))),rep(c(1,1,1,1),(nrow(var_grid)/length(unique(kern_seq)))),rep(c(1,1,1,5), (nrow(var_grid)/length(unique(kern_seq))))), ncol=4, byrow=T)


for (s in 1:nrow(var_grid)){

  print(paste (s, " out of ", nrow(var_grid) ), sep="")
  
  SD<-var_grid[s,1]
  LDD<-var_grid[s,2]
  
  
  matrices_var<-matrix(SD, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

start.time <- Sys.time()

dir.create(paste("D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Fake_Three_Vars_kern/Kern_", s,"LDD_",LDD,"SD_", SD,sep=""))

reps<-5

rep_demoniche<-function(i){
  library(demoniche)
  source("demoniche_model_me.R")
 demoniche_setup(modelname = "Capra_k_16000",Populations = Populations, Nichemap = fake_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = LDD, fraction_SDD = 0.5,
                  dispersal_constants = kern_mat[i,],
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=2000, Kweight = K_weight, 
                  sumweight =sumweight)
c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("Demoniche_Repetitions/Fake_Three_Vars_kern/Kern_", s,"LDD_",LDD,"SD_", SD,"/rep",i,sep=""))
}


#lapply(1:reps, rep_demoniche)

library(doParallel)

if (Sys.info()["nodename"] == "FIONA-PC"){
 cl <- makeCluster(4) 
} else {
 cl <- makeCluster(2)
}


registerDoParallel(cl)
foreach(i=(1:reps)) %dopar% rep_demoniche(i)
stopCluster(cl)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken 
}

```


* Scaling population matrices to habitat suitability â only have one stage matrix from a particular point in time
*	Other matrices are just transition matrices but available in good and bad conditions, use these to great upper and lower bounds of survival? â need to check location, date and existence of these matrices

*	Noise is currently not supported but a value of 1 imputes white noise, and values higher or lower than this give positive or negative temporal autocorrelation â more important when you have multiple matrices?

*	Transition_affected_niche has more impact when specified values are inputted â if(is.numeric(transition_affected_niche){}

*	Transition affected niche pulls out parts of the matrix that are multiplied by the niche value â so if just presence/absence then it is either no change or 0 

*	Potential problem with the way I have seeded the model â only ibex in the original populations whereas it might be more accurate to seed ibex more widely and then just sample from the original population sites.

* Calculate dispersal kernel from gps data?

* Density_individuals  = is the starting populations for each locations that is "seeded" in Populations

* Proportion_initial is how density individual is divided between stages, e.g all juveniles or  evenly spread etc 

* Need to check if you can run multiple matrices_var in one run






```{r, eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
#Running the demoniche model - running 9 different models, for each method of scaling carrying capacity I have run demoniche with 3 different dispersal probabilities (0.1, 0.5 and 0.9).

library(demoniche)
source("demoniche_model_me.R")


foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

k_relationships<-rep(list(links, sigks, ltks), each=3)  #need to change names of folders to match this

foldernames<-c("patch_low_disp" ,"patch_mid_disp" ,"patch_high_disp")

k_relationships<-40000 #need to change names of folders to match this

dispersal_levels<-rep(c(0.001,0.01,0.1, each=1))

for (i in 1:length(foldernames)){

  print(paste("processing of ", foldernames[i]," beginning, ", i, " of ", length(foldernames), sep=""))
  foldername = foldernames[i]
  dispersal = dispersal_levels[i]
  #K = matrix(unlist(k_relationships[i]),nrow=9)
  K = k_relationships
  
  demoniche_setup(modelname = foldername,Populations = Populations, Nichemap =patch_map_mine,
                matrices = matrices, matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = density_individuals,
                fraction_LDD = dispersal, 
                fraction_SDD = dispersal,
                dispersal_constants = c(0.7,0.7,0.1,1),
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=K, Kweight = K_weight, 
                sumweight =sumweight)

patch_run <- demoniche_model_me(modelname = foldernames[i], Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 10,
                                     foldername = foldernames[i])
years<-1450:2016
plot(years,patch_run[,"Meanpop","Reference_matrix"], type="l", xlim=c(1949,2016), main=foldernames[i])

}

```


```{r, eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}


#Extracting the predicted alpine ibex population trends for each population from the demoniche output.

foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

lpi<-read.csv("LPI_pops_20160523_edited.csv")

alpine<-lpi[lpi$ID == 10696 | lpi$ID == 10714 | lpi$ID == 10694 | lpi$ID == 10717 | lpi$ID == 10713 |lpi$ID == 10718 |lpi$ID == 10695 |lpi$ID == 539 |lpi$ID == 10710 ,]

xy<-cbind(alpine$Longitude, alpine$Latitude)

convert_pop_out<-function(foldername){
  
  pop_out<-read.csv(paste(wd, "/", foldername, "/pop_output.csv", sep=""), header = TRUE)
  pop_out<-pop_out[,-1]
  coordinates(pop_out) <- ~ X + Y
  gridded(pop_out) <- TRUE
  rasterDF <- stack(pop_out)
  trends<-extract(rasterDF,xy)
  trends_df<-data.frame(trends)
  write.csv(trends_df, paste(wd, "/", foldername, "/pop_trend_output.csv", sep=""))
}

lapply(foldernames, convert_pop_out)


```



```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}

#Plots of the real trends vs predicted trends

lpi<-read.csv("LPI_pops_20160523_edited.csv")

alpine<-lpi[lpi$ID == 10696 | lpi$ID == 10714 | lpi$ID == 10694 | lpi$ID == 10717 | lpi$ID == 10713 |lpi$ID == 10718 |lpi$ID == 10695 |lpi$ID == 539 |lpi$ID == 10710 ,]

pop<-3
years<-1950:2016

trends<-read.csv(paste(wd, "/patch_link_low_disp/pop_trend_output.csv", sep=""))

#plot(years, trends[pop,901:967], type="l", ylim=c(0,5000), xlim=c(1950,2016))
lpi_pop<-alpine[,c(65:130)]
pop_trends_pred<-data.frame(cbind(Populations$PatchID, trends))

library(reshape)
melt_pop<-melt(pop_trends_pred)

melt_pop<-melt_pop[-c(1:9),]

lpi_pop<-data.frame(cbind(Populations$PatchID, lpi_pop))
lpi_pop$Populations.PatchID<-as.character(lpi_pop$Populations.PatchID)
melt_lpi<-melt(lpi_pop, id.vars = "Populations.PatchID")


melt_pop$ID<-as.factor(lpi_pop$Populations.PatchID)
melt_pop<-melt_pop[-c(1:9),]
melt_pop$Year<-rep(1450:2016 , each=9)

melt_pop_1950<-subset(melt_pop, melt_pop$Year >=1950)

library(ggplot2)
#plot of predicted trends
# ggplot(data = melt_pop_1950, aes(y= value, x= Year, group=ID, col=ID))+
#   geom_line()

col_years<-paste("Year_", 1950:2015, sep="")
colnames(lpi_pop)<-col_years


melt_lpi$Year<-rep(1950:2015 , each=9)
melt_lpi$value<-as.numeric(as.character(melt_lpi$value))

#plot of actual trends
ggplot(data = melt_lpi, aes(y= value, x= Year, group=Populations.PatchID, col=Populations.PatchID))+
  geom_line()

melt_lpi$model_type<-"Real"
melt_lpi$ID<-as.numeric(melt_lpi$Populations.PatchID)/100
melt_lpi<-melt_lpi[-1]

```

```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}
library(reshape2)
foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

bdf<-data.frame()
for(i in 1:length(foldernames)){
trends<-read.csv(paste(wd, "/",foldernames[i],"/pop_trend_output.csv", sep=""))
trends<-trends[,-1]
m_t<-melt(trends)
m_t$Year<-rep(1450:2016, each=9)
m_t$model_type<-foldernames[i]
m_t$ID<-alpine$ID
bdf<-rbind(bdf,m_t)
#print(i)
}

bdf_lpi<-rbind(bdf,melt_lpi)

pop_pred_539<-bdf_lpi[bdf_lpi$ID == 539 & bdf_lpi$Year >=1950,]
pop_pred_10694<-bdf_lpi[bdf_lpi$ID == 10694 & bdf_lpi$Year >=1950,]
pop_pred_10695<-bdf_lpi[bdf_lpi$ID == 10695 & bdf_lpi$Year >=1950,]
pop_pred_10696<-bdf_lpi[bdf_lpi$ID == 10696 & bdf_lpi$Year >=1950,]
pop_pred_10710<-bdf_lpi[bdf_lpi$ID == 10710 & bdf_lpi$Year >=1950,]
pop_pred_10713<-bdf_lpi[bdf_lpi$ID == 10713 & bdf_lpi$Year >=1950,]
pop_pred_10714<-bdf_lpi[bdf_lpi$ID == 10714 & bdf_lpi$Year >=1950,]
pop_pred_10717<-bdf_lpi[bdf_lpi$ID == 10717 & bdf_lpi$Year >=1950,]
pop_pred_10718<-bdf_lpi[bdf_lpi$ID == 10718 & bdf_lpi$Year >=1950,]

ggplot(pop_pred_539, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 539")
  
ggplot(pop_pred_10694, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10694")
  
ggplot(pop_pred_10695, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10695")
  
ggplot(pop_pred_10696, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10696")
  
ggplot(pop_pred_10710, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10710")
  
ggplot(pop_pred_10713, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10713")
  
ggplot(pop_pred_10714, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10714")
  
ggplot(pop_pred_10717, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10717")
  
ggplot(pop_pred_10718, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10718")
  

```


```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}

#Comparison of the demoniche models to the lpi correlation models
library(lme4)
dt<-read.csv("Mammals_scaled_ready_for_models.csv")

foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

m0<-lmer(lambda_mean ~ change_rate_scale+mean_slope_scale+change_rate_scale:mean_slope_scale+Bodymass_scale+(1|Binomial)+(1|loc_id),data=dt, REML=F)
m1b<-lmer(lambda_mean ~ change_rate_scale+(1|Binomial)+(1|loc_id),data=dt, REML=F)
m1c<-lmer(lambda_mean ~ mean_slope_scale+(1|Binomial)+(1|loc_id),data=dt)


capra_df<-dt[dt$ID == 10696 | dt$ID == 10714 |dt$ID == 10694 | dt$ID == 10717 | dt$ID == 10713 |dt$ID == 10718 |dt$ID == 10695 |dt$ID == 539 |dt$ID == 10710 ,]


capras<-which(dt$ID == 10696 | dt$ID == 10714 | dt$ID == 10694 | dt$ID == 10717 | dt$ID == 10713 |dt$ID == 10718 |dt$ID == 10695 |dt$ID == 539 |dt$ID == 10710 )


pred<-10^(predict(m0)[capras])
pred_clim<-10^predict(m1c)[capras]   #climate only model
pred_luc<-10^predict(m1b)[capras]   #land use only model
real<-10^capra_df$lambda_mean

dlnl<-read.csv(paste(wd, "/", foldernames[1], "/pop_trend_output.csv", sep=""))  
dlnm<-read.csv(paste(wd, "/", foldernames[2], "/pop_trend_output.csv", sep=""))  
dlnh<-read.csv(paste(wd, "/", foldernames[3], "/pop_trend_output.csv", sep=""))  
dsgl<-read.csv(paste(wd, "/", foldernames[4], "/pop_trend_output.csv", sep=""))  
dsgm<-read.csv(paste(wd, "/", foldernames[5], "/pop_trend_output.csv", sep=""))  
dsgh<-read.csv(paste(wd, "/", foldernames[6], "/pop_trend_output.csv", sep=""))  
dltl<-read.csv(paste(wd, "/", foldernames[7], "/pop_trend_output.csv", sep=""))  
dltm<-read.csv(paste(wd, "/", foldernames[8], "/pop_trend_output.csv", sep=""))  
dlth<-read.csv(paste(wd, "/", foldernames[9], "/pop_trend_output.csv", sep=""))  

demo_link_low<-10^rowMeans(diff(as.matrix(log10(dlnl[,c(900:967)]),nrow=9)))
demo_link_mid<-10^rowMeans(diff(as.matrix(log10(dlnm[,c(900:967)]),nrow=9)))
demo_link_high<-10^rowMeans(diff(as.matrix(log10(dlnh[,c(900:967)]),nrow=9)))
demo_sigk_low<-10^rowMeans(diff(as.matrix(log10(dsgl[,c(900:967)]),nrow=9)))
demo_sigk_mid<-10^rowMeans(diff(as.matrix(log10(dsgm[,c(900:967)]),nrow=9)))
demo_sigk_high<-10^rowMeans(diff(as.matrix(log10(dsgh[,c(900:967)]),nrow=9)))
demo_lt_low<-10^rowMeans(diff(as.matrix(log10(dltl[,c(900:967)]),nrow=9)))
demo_lt_mid<-10^rowMeans(diff(as.matrix(log10(dltm[,c(900:967)]),nrow=9)))
demo_lt_high<-10^rowMeans(diff(as.matrix(log10(dlth[,c(900:967)]),nrow=9)))

lambda_preds<-cbind(real,pred, pred_clim,pred_luc,  demo_link_low, demo_link_mid,demo_link_high,demo_sigk_low, demo_sigk_mid, demo_sigk_high,demo_lt_low,demo_lt_mid,demo_lt_high)


#pairs(lambda_preds)

```



```{r, eval=FALSE, echo=FALSE}
#Comparison of model predictions with the real values

par(mfrow=c(3,4))

for (i in 2:ncol(lambda_preds-1)){
  plot(lambda_preds[,1], lambda_preds[,i], main=colnames(lambda_preds)[i], ylab=colnames(lambda_preds)[i], xlab=colnames(lambda_preds)[1])
 #print(i) 
}


```


```{r, eval=FALSE, echo=FALSE, warning=FALSE}

patch_run_dz <- demoniche_model_VE(modelname = "Capra_ibex_patch", Niche = TRUE, 
                                     Dispersal = T, repetitions = 1,
                                     foldername = "damaris_function")

patch_run_dz[,"Meanpop","Reference_matrix"]

years<-1450:2016
#plot(RPyran_disp_niche[,"Meanpop","Reference_matrix"])
bleh<-(patch_run[,"Meanpop","Reference_matrix"])

plot(years, bleh, type="l", xlim=c(1950,2016))

```


```{r,cache=TRUE, echo=FALSE, warning=FALSE, eval=FALSE}


#Varying the carrying capacity - 16000, 4000, 2000, 1000


matrices_var<-matrix(1, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

source("demoniche_setup_me.R")
  demoniche_setup_me(modelname = "Capra_k_16000",Populations = Populations, Nichemap = patch_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = 0.5, fraction_SDD = 0.5,
                  dispersal_constants = c(13.6, 77),
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=2671, Kweight = K_weight, 
                  sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_4000",Populations = Populations, Nichemap = patch_spin_up,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=4000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_2000",Populations = Populations, Nichemap = patch_spin_up,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=2000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_1000",Populations = Populations, Nichemap = patch_spin_up,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=1000, Kweight = K_weight, 
                sumweight =sumweight)

source("demoniche_model_me.R")
c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


c_ibex_k_4000 <- demoniche_model_me(modelname = "Capra_k_4000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 2,
                                     foldername = "non_damaris_function")

c_ibex_k_2000 <- demoniche_model(modelname = "Capra_k_2000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

c_ibex_k_1000 <- demoniche_model(modelname = "Capra_k_1000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

plot(c_ibex_k_4000[,"Meanpop","Reference_matrix"], type="l")
lines(c_ibex_k_2000[,"Meanpop","Reference_matrix"])

p_16000<-(c_ibex_k_16000[,"Meanpop",1])
p_4000<-(c_ibex_k_4000[,"Meanpop","Reference_matrix"])
p_2000<-(c_ibex_k_2000[,"Meanpop","Reference_matrix"])
p_1000<-(c_ibex_k_1000[,"Meanpop","Reference_matrix"])

plot(p_16000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="")
lines(p_4000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="",col="green")
lines(p_2000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="red")
lines(p_1000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="blue")

10^mean(diff(log10(na.omit(p_16000[900:966]))))
10^mean(diff(log10(p_4000[900:966])))
10^mean(diff(log10(p_2000[900:966])))
10^mean(diff(log10(p_1000[900:966])))

```



```{r, eval=FALSE, echo=FALSE}
# RPyran_disp_niche_scale <- demoniche_model(modelname = "Capra_ibex_scale", Niche = TRUE, 
#                                      Dispersal = TRUE, repetitions = 1,
#                                      foldername = "RPyran_disp_niche")



years<-1950:2016
years<-1450:2016
#plot(RPyran_disp_niche[,"Meanpop","Reference_matrix"])
bleh<-(RPyran_disp_niche_scale[,"Meanpop","Reference_matrix"])
link_years<-(RPyran_disp_niche_scale_lk[,"Meanpop","Reference_matrix"])
lk_years<-(RPyran_disp_niche_scale_link[,"Meanpop","Reference_matrix"])
#plot(years, bleh, type="l", ylab="Number of Alpine Ibex")


plot(years[(length(years-67)):length(years)], bleh[(length(years-67)):length(years)], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="")
lines(years[(length(years-67)):length(years)], lk_years[(length(years-67)):length(years)], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="", col="red")
lines(years[(length(years-67)):length(years)], link_years[(length(years-67)):length(years)], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="", col="green")


mean(diff(log10(bleh[900:967])), type="l")
mean(diff(log10(lk_years[900:967])), type="l")
mean(diff(log10(link_years[900:967])), type="l")

```


ap_params.csv")

rep_df_all$rep_id<-factor(rep_df_all$rep_id)
rep_df_all$md_id<-factor(rep_df_all$md_id)

rep_df_all$trend<-as.numeric(as.character(rep_df_all$trend))

```


```{r}
#devtools::install_github("thomasp85/patchwork")
library(ggplot2)
#library(patchwork)

p01<-ggplot(rep_df_all, aes(x=year, y=trend, group=interaction(rep_id, md_id),colour=md_id))+
  geom_line()+ 
   theme(text = element_text(size=9))+ 
  labs(color='Maximum \ndispersal \ndistance') 
p01
```



```{r}
library(data.table)
wd<-getwd()
highfoldernames<-c("max_disp_77.7","max_disp_113", "max_disp_1000")
lowfoldernames<-rep(c("1", "2", "3", "4", "5", "6"), each=3)

foldernames<-paste(highfoldernames, lowfoldernames, sep="/")

lpi<-read.csv("LPI_pops_20160523_edited.csv")

alpine<-lpi[lpi$ID == 10696 | lpi$ID == 10714 | lpi$ID == 10694 | lpi$ID == 10717 | lpi$ID == 10713 |lpi$ID == 10718 |lpi$ID == 10695 |lpi$ID == 539 |lpi$ID == 10710 ,]

xy<-cbind(alpine$Longitude, alpine$Latitude)

convert_pop_out<-function(foldername){
  
  pop_out<-read.csv(paste(wd,"/Demoniche_repetitions/Kern_kap/" ,foldername, "/pop_output.csv", sep=""), header = TRUE)
  pop_out<-pop_out[,-1]
  coordinates(pop_out) <- ~ X + Y
  gridded(pop_out) <- TRUE
  rasterDF <- stack(pop_out)
  proj4string(rasterDF)<-CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ")
  trends<-extract(rasterDF,xy)
  max_disp<-strsplit(foldername, "[/_]")[[1]][3]
  rep_id<-strsplit(foldername, "[/_]")[[1]][4]
  trends_df<-data.frame(alpine$ID,max_disp, rep_id,trends)
#  write.csv(trends_df, paste(wd, "/", foldername, "/pop_trend_output.csv", sep=""))
}

demoniche_pop_out<-lapply(foldernames, convert_pop_out)
df <- do.call("rbind", demoniche_pop_out)
dfm<-as.matrix(df)

lambda<-function(x){

  l10<-10^diff(log10(as.numeric(x[4:length(x)])))
  
}

dft<-t(apply(dfm,1,lambda))

df_lambda<-data.frame(dfm[,1:3],dft)

colnames(df_lambda)[4:ncol(df_lambda)]<-colnames(dfm)[5:ncol(dfm)]

melt_df<-melt(df, id=1:3)
melt_df$year<-as.numeric(gsub("Year_", "", melt_df$variable))

melt_lambda<-melt(df_lambda, id=1:3)
melt_lambda$year<-as.numeric(gsub("Year_", "", melt_lambda$variable))

melt_short<-melt_df[melt_df$year>1949,]
melt_short$alpine.ID<-as.factor(melt_short$alpine.ID)

melt_lambda_short<-melt_lambda[melt_lambda$year>1950,]
melt_lambda_short$alpine.ID<-as.factor(melt_lambda_short$alpine.ID)

ggplot(melt_short, aes(x= year, y=value, group=interaction(rep_id, max_disp), colour= alpine.ID))+
  geom_line()+
  facet_grid(max_disp~ alpine.ID)

ggplot(melt_lambda_short, aes(x= year, y=value, group=interaction(rep_id, max_disp), colour= alpine.ID))+
  geom_line()+
  facet_grid(max_disp~ alpine.ID)


# library(gghighlight)
# 
# ggplot(melt_short, aes(x= year, y=value, group=interaction(rep_id, max_disp), colour= alpine.ID))+
#   geom_line()+
#   facet_wrap(.~max_disp)
# 
# 
# gghighlight_line(melt_short, aes(x= year, y=value, group=rep_id), max_disp =="77.7")+
#   facet_wrap(.~max_disp)

```


```{r, message=FALSE}

pops<-alpine[,c(1,65:130)]
colnames(pops)[2:ncol(pops)]<-paste("Year", 1950:2015, sep="_")
pops[pops=="NULL"]<-NA
pops$rep_id<-"Observed"
pops$md_id<-"Observed"

library(taRifx)
library(mgcv)
library(plyr)
popsm<-as.matrix(pops)

gam_lpi<-function(x){
   #subsetting the population data by each population 
  spid = x[2:(length(x)-2)]                     #subsetting only the dates
  names(spid)<-1950:2015              #renaming the date column names as R doesn't like numbered column names
  spid<-as.numeric(spid)
  pop_datab <- (!is.na(spid) )
  points = sum(pop_datab)
  id<-x[1]
  Date<-1950:2015
  spidt<-destring(t(spid))
  time<-length(min(which(!is.na(spidt))):max(which(!is.na(spidt))))
  missing<-time-points
  
  Year<-Date[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population<-spidt[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population[Population == 0] <- mean(Population, na.rm=TRUE)*0.01 #if a population is zero one year thhis is replaced with 1% of the average population estimate - because you can log zeros
  
  df<-data.frame(Year,Population)
  
  #not sure what this does - adding a constant of 1 so that logging doesn't go weird?
  if (sum(na.omit(df$Population<1))>0) {
    df$Population<-df$Population+1
  } 
    
  
  if (points >=6) {           
    PopN = df$Population
    if (length(na.omit(PopN)) >=6) {
      SmoothParm = round(length(na.omit(PopN))/2)    
    } else {
      SmoothParm=3
    }
    
    mg2<-mgcv:::gam(PopN ~ s(Year, k=SmoothParm), fx=TRUE)
    pv2 <- predict(mg2,df,type="response",se=TRUE) 
    R_sq2<-summary(mg2)$r.sq
    model<-1
    pv2$fit[pv2$fit <= 0] <- NA
    

    lambda2<-pv2$fit

    ial<-data.frame(id, Year,lambda2)
   
    colnames(ial)<-c("ID", "Year", "Abundance")
  }

  return(ial)
}

gam_lpi_r<-apply(popsm,  1, gam_lpi)
gam_r<-do.call( "rbind", gam_lpi_r)

fill<-data.frame(rep(pops$ID, each=length(1950:2015)), 1950:2015)
colnames(fill)<-c("ID", "Year")

all_year_ab<-join(fill, gam_r, type="right")

all_year_ab$max_disp<-"Observed"
all_year_ab$rep_id<-"Observed"

colnames(all_year_ab)[1:3]<-c("alpine.ID", "year", "value")


```

```{r}
mldab<-melt_short[,-4]
all_year_ab$alpine.ID<-as.factor(all_year_ab$alpine.ID)
all_year_ab$max_disp<-as.factor(all_year_ab$max_disp)
all_year_ab$rep_id<-as.factor(all_year_ab$rep_id)
all_year_ab$value<-as.numeric(all_year_ab$value)
all_year_ab$year<-as.numeric(all_year_ab$year)


both_df_ab<-rbind(mldab, all_year_ab)

both_df_ab[both_df_ab$alpine.ID == "  539",]$alpine.ID<-539

```

```{r}
library(ggplot2)


ggplot(mldab, aes(x= year, y=value, group=interaction(rep_id, max_disp,alpine.ID), colour= alpine.ID))+
  geom_line(colour="grey")+
  geom_line(data=both_df_ab[both_df_ab$max_disp=="Observed",], aes(x=year, y=value), colour="red")+
  facet_grid(.~ alpine.ID)


```

```{r, warning=FALSE, message=FALSE} 


pops<-alpine[,c(1,65:130)]
colnames(pops)[2:ncol(pops)]<-paste("Year", 1950:2015, sep="_")
pops[pops=="NULL"]<-NA
pops$rep_id<-"Observed"
pops$md_id<-"Observed"

library(taRifx)
popsm<-as.matrix(pops)

gam_lpi<-function(x){
   #subsetting the population data by each population 
  spid = x[2:(length(x)-2)]                     #subsetting only the dates
  names(spid)<-1950:2015              #renaming the date column names as R doesn't like numbered column names
  spid<-as.numeric(spid)
  pop_datab <- (!is.na(spid) )
  points = sum(pop_datab)
  id<-x[1]
  Date<-1950:2015
  spidt<-destring(t(spid))
  time<-length(min(which(!is.na(spidt))):max(which(!is.na(spidt))))
  missing<-time-points
  
  Year<-Date[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population<-spidt[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population[Population == 0] <- mean(Population, na.rm=TRUE)*0.01 #if a population is zero one year thhis is replaced with 1% of the average population estimate - because you can log zeros
  
  df<-data.frame(Year,Population)
  
  #not sure what this does - adding a constant of 1 so that logging doesn't go weird?
  if (sum(na.omit(df$Population<1))>0) {
    df$Population<-df$Population+1
  } 
    
  
  if (points >=6) {           
    PopN = log10(df$Population)
    if (length(na.omit(PopN)) >=6) {
      SmoothParm = round(length(na.omit(PopN))/2)    
    } else {
      SmoothParm=3
    }
    
    mg2<-mgcv:::gam(PopN ~ s(Year, k=SmoothParm), fx=TRUE)
    pv2 <- predict(mg2,df,type="response",se=TRUE) 
    R_sq2<-summary(mg2)$r.sq
    model<-1
    pv2$fit[pv2$fit <= 0] <- NA
    

    lambda2<-diff(pv2$fit)

    ial<-data.frame(id, Year[-length(Year)], 10^lambda2)
   
    colnames(ial)<-c("ID", "Year", "R")
  }

  return(ial)
}

gam_lpi_r<-apply(popsm,  1, gam_lpi)
gam_r<-do.call( "rbind", gam_lpi_r)

fill<-data.frame(rep(pops$ID, each=length(1950:2015)), 1950:2015)
colnames(fill)<-c("ID", "Year")

all_year_r<-join(fill, gam_r, type="right")

all_year_r$max_disp<-"Observed"
all_year_r$rep_id<-"Observed"

colnames(all_year_r)[1:3]<-c("alpine.ID", "year", "value")

```



```{r}

mld<-melt_lambda_short[,-4]
all_year_r$alpine.ID<-as.factor(all_year_r$alpine.ID)
all_year_r$max_disp<-as.factor(all_year_r$max_disp)
all_year_r$rep_id<-as.factor(all_year_r$rep_id)
all_year_r$value<-as.numeric(all_year_r$value)
all_year_r$year<-as.numeric(all_year_r$year)


both_df<-rbind(mld, all_year_r)

```


need to add in x axis. do plots separately for each of the dispersal options?
```{r}
library(ggplot2)


ggplot(both_df, aes(x= year, y=value, group=interaction(rep_id, max_disp,alpine.ID), colour= alpine.ID))+
  geom_line(colour="grey")+
  geom_line(data=both_df[both_df$max_disp=="Observed",], aes(x=year, y=value), colour="red")+
  facet_grid(.~ alpine.ID)


```





#############ignore below here


```{r, eval=FALSE, echo=FALSE}

start.time <- Sys.time()

library(demoniche)
source("demoniche_model_me.R")
#source("demoniche_model_me_par.R")
sd<-0.01

matrices_var<-matrix(sd, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

  demoniche_setup(modelname = "niche_2000k",Populations = Populations, Nichemap = fake_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 4000,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = 0.1, fraction_SDD = 0.9,
                  dispersal_constants = c(0.7,0.7,0.1,2),
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=200000, Kweight = K_weight, 
                  sumweight =sumweight)
niche_test <- demoniche_model_me(modelname = "niche_2000k", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("SD_", sd, sep=""))

#result <- foreach(i=10:10000) %dopar% getPrimeNumbers(i)
  
n_2000<-(niche_test[,"Meanpop","Reference_matrix"])

plot(n_2000[(nrow(n_2000-67)):length(n_2000)], type="l", ylab="Number of Alpine Ibex", xlab="")

10^mean(diff(log10(n_2000[(nrow(n_2000-67)):length(n_2000))])))

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken 

```


####Testing impact of variables

Varying carrying capacity, long distance dispersal, short distance dispersal and density.

```{r, message=FALSE, warning=FALSE, cache=TRUE, eval=FALSE}
#setwd("C:Users/Fiona/Documents/Demoniche")

sd_seq<-c(0.25,0.3,0.35,0.4,0.45)
matrices_var<-matrix(0.45, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

k_seq<-c(1000,2000,4000,8000,16000,32000)
LDD_seq<-c(0.1, 0.5, 0.9)
SDD_seq<-c(0.1, 0.5, 0.9)
dens_seq<-c(100, 400, 1000, 4000)

var_grid<-expand.grid(k_seq, LDD_seq, SDD_seq, dens_seq)
colnames(var_grid)<-c("K", "LDD", "SDD", "density")

for (s in 1:nrow(var_grid)){
print(s)

  K<-var_grid[s,1]
  LDD<-var_grid[s,2]
  SDD<-var_grid[s,3]
  density<-var_grid[s,4]
#sdf<-gsub("\\.", "_", s)  

start.time <- Sys.time()

dir.create(paste("D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Four_Vars_Prob/K_",K,"_LDD_",LDD,"_SDD_", SDD, "_dens_", density ,sep=""))

reps<-5

rep_demoniche<-function(i){
  library(demoniche)
  source("demoniche_model_me.R")
 demoniche_setup(modelname = "Capra_k_16000",Populations = Populations, Nichemap = niche_spin_up,   #CHANGED TO NICHE
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = density,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = LDD, fraction_SDD = SDD,
                  dispersal_constants = c(0.7,0.7,0.1,2),
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=K, Kweight = K_weight, 
                  sumweight =sumweight)
c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("Demoniche_Repetitions/Four_Vars/K_",K,"_LDD_",LDD,"_SDD_", SDD, "_dens_", density,"/rep_",i, sep=""))
}


#lapply(1:reps, rep_demoniche)

library(doParallel)

if (Sys.info()["nodename"] == "FIONA-PC"){
 cl <- makeCluster(4) 
} else {
 cl <- makeCluster(2)
}

registerDoParallel(cl)
foreach(i=(1:reps)) %dopar% rep_demoniche(i)
stopCluster(cl)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken 
}


```

```{r,message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
library(ggplot2)
library(dplyr)

wd<-"D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Four_Vars/"

folders<-list.files(wd)

for (folder in folders){

  print(folder)

  f<-paste(wd,folder, sep="")

  lf<-list.dirs(f, recursive = F)

#path<-paste(f, lf, sep="")

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  plot_rep<-function(proj_path){
  
  load(proj_path)
  id<-gsub("\\D", "", proj_path)
  id<-as.numeric(substr(id, 1, nchar(id)-1))
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),])
  tid<-cbind(id, trend)
  return(tid)
  }

  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  rep_df$id<-as.factor(rep_df$id)


  spin<-ggplot(rep_df, aes(x = year, y= trend, group=id))+
    geom_line( alpha=0.5)

  #plot(spin)
  
  rep_df_short<-rep_df[rep_df$year >=1950,]


  p<-ggplot(rep_df_short, aes(x = year, y= trend, group=id))+
    geom_line( alpha=0.5)
  
  #plot(p)
  
  lambdas<-rep_df_short %>% 
  group_by(id) %>%
  summarise(lambda = 10^mean(diff(log10(trend))))
  
  #print(lambdas)
  
 if (!is.nan(sum(lambdas$lambda))){
  boxplot(lambdas$lambda)
}

  }
```


####Plotting the impact of different variables 

```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}

library(ggplot2)

wd_rep<-paste(wd, "/Demoniche_Repetitions/Four_Vars/", sep="")


folders<-list.files(wd_rep)

rep_df_all<-data.frame()

for (folder in folders){

  #print(folder)

  f<-paste(wd,folder, sep="")

  lf<-list.dirs(f, recursive = F)

#path<-paste(f, lf, sep="")

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  plot_rep<-function(proj_path){
  
  load(proj_path)
  k_id<-strsplit(proj_path, "[_/]")[[1]][12]
  ldd_id<-strsplit(proj_path, "[_/]")[[1]][14]
  sdd_id<-strsplit(proj_path, "[_/]")[[1]][16]
  dens_id<-strsplit(proj_path, "[_/]")[[1]][18]
  rep_id<-strsplit(proj_path, "[_/]")[[1]][20]
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),901:966])
  tid<-cbind(k_id, ldd_id, sdd_id, dens_id, rep_id, trend)
  
  return(tid)
  }
  
  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  #rep_df$id<-as.factor(rep_df$id)

  rep_df_all<-rbind(rep_df,rep_df_all)
  
}

#write.csv(rep_df_all, "fourvars_sdd_ldd_dens_k.csv")

```

```{r, message=FALSE, warning=FALSE}

rep_df_all<-read.csv("fourvars_sdd_ldd_dens_k.csv")

rep_df_all$trend<-as.numeric(as.character(rep_df_all$trend))

rep_df_all$dens_id_f<-factor(rep_df_all$dens_id,labels=c("dens:100", "dens:400", "dens:1000", "dens:4000") ,levels=c("100", "400", "1000", "4000"))

rep_df_all$k_id_f<-factor(rep_df_all$k_id, labels=c("K:1000","K:2000",  "K:4000", "K:8000", "K:16000", "K:32000"), levels=c("1000","2000",  "4000", "8000", "16000", "32000"))

rep_df_all$sdd_id_f<-factor(rep_df_all$sdd_id,labels=c("SDD:0.1","SDD:0.5","SDD:0.9") ,levels=c("0.1","0.5","0.9"))

rep_df_all$ldd_id_f<-factor(rep_df_all$ldd_id,labels=c("LDD:0.1","LDD:0.5","LDD:0.9") ,levels=c("0.1","0.5","0.9"))

rep_df_all$rep_id_f<-factor(rep_df_all$rep_id)

```

Plotting how the short distance dispersal, carrying capacity and density impact population trends when the probability of long distance dispersal is low (**0.1**).

```{r}
#devtools::install_github("thomasp85/patchwork")
library(ggplot2)
#library(patchwork)

df_ldd_01<-rep_df_all[rep_df_all$ldd_id == 0.1,]

p01<-ggplot(df_ldd_01, aes(x=year, y=trend, group=interaction(rep_id_f, sdd_id_f), colour=sdd_id_f))+
  geom_line() + 
  facet_grid(k_id_f ~ dens_id_f, labeller = label_context)+
   theme(text = element_text(size=10))+ 
  labs(color='Chance of short \ndistance dispersal') 
p01
```

Plotting how the short distance dispersal, carrying capacity and density impact population trends when the probability of long distance dispersal is **0.5**.

```{r}
df_ldd_05<-rep_df_all[rep_df_all$ldd_id == 0.5,]

p05<-ggplot(df_ldd_05, aes(x=year, y=trend,group=interaction(rep_id_f, sdd_id_f) ,colour=sdd_id_f))+
  geom_line() + 
  facet_grid(k_id_f ~ dens_id_f, labeller = label_context)+
 theme(text = element_text(size=9))+
  labs(color='Chance of short \ndistance dispersal') 
  p05
```

Plotting how the short distance dispersal, carrying capacity and density impact population trends when the probability of long distance dispersal is **0.9**.

```{r}
df_ldd_09<-rep_df_all[rep_df_all$ldd_id == 0.9,]

p09<-ggplot(df_ldd_09, aes(x=year, y=trend, group=interaction(rep_id_f, sdd_id_f),colour=sdd_id_f))+
  geom_line() + 
  facet_grid(k_id_f ~ dens_id_f, labeller = label_context)+ 
  theme(text = element_text(size=9))+
  labs(color='Chance of short \ndistance dispersal') 

p09


```




####Varying carrying capacity, long distance dispersal and standard deviation of population matrix

```{r, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}

library(ggplot2)

wd<-"D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Three_Vars/"

folders<-list.files(wd)

rep_df_all<-data.frame()

for (folder in folders){

  #print(folder)

  f<-paste(wd,folder, sep="")

  lf<-list.dirs(f, recursive = F)

#path<-paste(f, lf, sep="")

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  plot_rep<-function(proj_path){
  
  load(proj_path)
  k_id<-strsplit(proj_path, "[_/]")[[1]][12]
  ldd_id<-strsplit(proj_path, "[_/]")[[1]][14]
  sd_id<-strsplit(proj_path, "[_/]")[[1]][16]
  rep_id<-strsplit(proj_path, "[_/]")[[1]][20]
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),901:966])
  tid<-cbind(k_id, ldd_id, sd_id, rep_id, trend)
  
  return(tid)
  }
  
  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  #rep_df$id<-as.factor(rep_df$id)

  rep_df_all<-rbind(rep_df,rep_df_all)
  
}

write.csv(rep_df_all, "threevars_sd_ldd_k.csv")

```


```{r, message=FALSE, warning=FALSE}

rep_df_all<-read.csv("threevars_sd_ldd_k.csv")

rep_df_all$trend<-as.numeric(as.character(rep_df_all$trend))

rep_df_all$k_id_f<-factor(rep_df_all$k_id,levels=c("1000","2000",  "4000", "8000", "16000", "32000") ,labels=c("K:1000","K:2000",  "K:4000", "K:8000", "K:16000", "K:32000"))

rep_df_all$sd_id_f<-factor(rep_df_all$sd_id,levels=c("0.25","0.3","0.35","0.4","0.45") ,labels=c("SD:0.25","SD:0.3","SD:0.35","SD:0.4","SD:0.45"))

rep_df_all$ldd_id_f<-factor(rep_df_all$ldd_id, levels=c("0.1","0.5","0.9"))

rep_df_all$rep_id_f<-factor(rep_df_all$rep_id)

```


```{r}
library(ggplot2)

p01<-ggplot(rep_df_all, aes(x=year, y=trend, group=interaction(rep_id_f, ldd_id_f),colour=ldd_id_f))+
  geom_line() + 
  facet_grid(k_id_f ~ sd_id_f, labeller = label_context)+
  theme(text = element_text(size=9))+ 
  labs(color='Chance of long \ndistance dispersal')
  
p01
```

####Using simulated habitat data

Basing the models on environmental data where the trend is known and constant - to better understand the impacts of the other variables.

```{r, message=FALSE, warning=FALSE, cache=TRUE, eval=FALSE}

plot(years_short,colMeans(na.omit(fake_map_mine)[4:length(colnames(fake_map_mine))]), type="l", ylab="Mean fake suitability index")

#setwd("C:Users/Fiona/Documents/Demoniche")

sd_seq<-c(0.5, 0.75,1, 1.25, 1.5)
#matrices_var<-matrix(0.45, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 
#k_seq<-c(1000,2000,4000,8000,16000,32000)
LDD_seq<-c(0.1, 0.5, 0.9)
kern_seq<-list(c(0.5,1,1,1),c(0.5,1,1,5), c(1,1,1,1), c(1,1,1,5))

var_grid<-expand.grid(sd_seq, LDD_seq, kern_seq)
colnames(var_grid)<-c("SD", "LDD", "Kern")

kern_mat<-matrix(c(rep(c(0.5,1,1,1), (nrow(var_grid)/length(unique(kern_seq)))),rep(c(0.5,1,1,5), (nrow(var_grid)/length(unique(kern_seq)))),rep(c(1,1,1,1),(nrow(var_grid)/length(unique(kern_seq)))),rep(c(1,1,1,5), (nrow(var_grid)/length(unique(kern_seq))))), ncol=4, byrow=T)


for (s in 1:nrow(var_grid)){

  print(paste (s, " out of ", nrow(var_grid) ), sep="")
  
  SD<-var_grid[s,1]
  LDD<-var_grid[s,2]
  
  
  matrices_var<-matrix(SD, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

start.time <- Sys.time()

dir.create(paste("D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Fake_Three_Vars_kern/Kern_", s,"LDD_",LDD,"SD_", SD,sep=""))

reps<-5

rep_demoniche<-function(i){
  library(demoniche)
  source("demoniche_model_me.R")
 demoniche_setup(modelname = "Capra_k_16000",Populations = Populations, Nichemap = fake_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = LDD, fraction_SDD = 0.5,
                  dispersal_constants = kern_mat[i,],
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=2000, Kweight = K_weight, 
                  sumweight =sumweight)
c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("Demoniche_Repetitions/Fake_Three_Vars_kern/Kern_", s,"LDD_",LDD,"SD_", SD,"/rep",i,sep=""))
}


#lapply(1:reps, rep_demoniche)

library(doParallel)

if (Sys.info()["nodename"] == "FIONA-PC"){
 cl <- makeCluster(4) 
} else {
 cl <- makeCluster(2)
}


registerDoParallel(cl)
foreach(i=(1:reps)) %dopar% rep_demoniche(i)
stopCluster(cl)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken 
}

```


* Scaling population matrices to habitat suitability â only have one stage matrix from a particular point in time
*	Other matrices are just transition matrices but available in good and bad conditions, use these to great upper and lower bounds of survival? â need to check location, date and existence of these matrices

*	Noise is currently not supported but a value of 1 imputes white noise, and values higher or lower than this give positive or negative temporal autocorrelation â more important when you have multiple matrices?

*	Transition_affected_niche has more impact when specified values are inputted â if(is.numeric(transition_affected_niche){}

*	Transition affected niche pulls out parts of the matrix that are multiplied by the niche value â so if just presence/absence then it is either no change or 0 

*	Potential problem with the way I have seeded the model â only ibex in the original populations whereas it might be more accurate to seed ibex more widely and then just sample from the original population sites.

* Calculate dispersal kernel from gps data?

* Density_individuals  = is the starting populations for each locations that is "seeded" in Populations

* Proportion_initial is how density individual is divided between stages, e.g all juveniles or  evenly spread etc 

* Need to check if you can run multiple matrices_var in one run






```{r, eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
#Running the demoniche model - running 9 different models, for each method of scaling carrying capacity I have run demoniche with 3 different dispersal probabilities (0.1, 0.5 and 0.9).

library(demoniche)
source("demoniche_model_me.R")


foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

k_relationships<-rep(list(links, sigks, ltks), each=3)  #need to change names of folders to match this

foldernames<-c("patch_low_disp" ,"patch_mid_disp" ,"patch_high_disp")

k_relationships<-40000 #need to change names of folders to match this

dispersal_levels<-rep(c(0.001,0.01,0.1, each=1))

for (i in 1:length(foldernames)){

  print(paste("processing of ", foldernames[i]," beginning, ", i, " of ", length(foldernames), sep=""))
  foldername = foldernames[i]
  dispersal = dispersal_levels[i]
  #K = matrix(unlist(k_relationships[i]),nrow=9)
  K = k_relationships
  
  demoniche_setup(modelname = foldername,Populations = Populations, Nichemap =patch_map_mine,
                matrices = matrices, matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = density_individuals,
                fraction_LDD = dispersal, 
                fraction_SDD = dispersal,
                dispersal_constants = c(0.7,0.7,0.1,1),
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=K, Kweight = K_weight, 
                sumweight =sumweight)

patch_run <- demoniche_model_me(modelname = foldernames[i], Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 10,
                                     foldername = foldernames[i])
years<-1450:2016
plot(years,patch_run[,"Meanpop","Reference_matrix"], type="l", xlim=c(1949,2016), main=foldernames[i])

}

```


```{r, eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}


#Extracting the predicted alpine ibex population trends for each population from the demoniche output.

foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

lpi<-read.csv("LPI_pops_20160523_edited.csv")

alpine<-lpi[lpi$ID == 10696 | lpi$ID == 10714 | lpi$ID == 10694 | lpi$ID == 10717 | lpi$ID == 10713 |lpi$ID == 10718 |lpi$ID == 10695 |lpi$ID == 539 |lpi$ID == 10710 ,]

xy<-cbind(alpine$Longitude, alpine$Latitude)

convert_pop_out<-function(foldername){
  
  pop_out<-read.csv(paste(wd, "/", foldername, "/pop_output.csv", sep=""), header = TRUE)
  pop_out<-pop_out[,-1]
  coordinates(pop_out) <- ~ X + Y
  gridded(pop_out) <- TRUE
  rasterDF <- stack(pop_out)
  trends<-extract(rasterDF,xy)
  trends_df<-data.frame(trends)
  write.csv(trends_df, paste(wd, "/", foldername, "/pop_trend_output.csv", sep=""))
}

lapply(foldernames, convert_pop_out)


```



```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}

#Plots of the real trends vs predicted trends

lpi<-read.csv("LPI_pops_20160523_edited.csv")

alpine<-lpi[lpi$ID == 10696 | lpi$ID == 10714 | lpi$ID == 10694 | lpi$ID == 10717 | lpi$ID == 10713 |lpi$ID == 10718 |lpi$ID == 10695 |lpi$ID == 539 |lpi$ID == 10710 ,]

pop<-3
years<-1950:2016

trends<-read.csv(paste(wd, "/patch_link_low_disp/pop_trend_output.csv", sep=""))

#plot(years, trends[pop,901:967], type="l", ylim=c(0,5000), xlim=c(1950,2016))
lpi_pop<-alpine[,c(65:130)]
pop_trends_pred<-data.frame(cbind(Populations$PatchID, trends))

library(reshape)
melt_pop<-melt(pop_trends_pred)

melt_pop<-melt_pop[-c(1:9),]

lpi_pop<-data.frame(cbind(Populations$PatchID, lpi_pop))
lpi_pop$Populations.PatchID<-as.character(lpi_pop$Populations.PatchID)
melt_lpi<-melt(lpi_pop, id.vars = "Populations.PatchID")


melt_pop$ID<-as.factor(lpi_pop$Populations.PatchID)
melt_pop<-melt_pop[-c(1:9),]
melt_pop$Year<-rep(1450:2016 , each=9)

melt_pop_1950<-subset(melt_pop, melt_pop$Year >=1950)

library(ggplot2)
#plot of predicted trends
# ggplot(data = melt_pop_1950, aes(y= value, x= Year, group=ID, col=ID))+
#   geom_line()

col_years<-paste("Year_", 1950:2015, sep="")
colnames(lpi_pop)<-col_years


melt_lpi$Year<-rep(1950:2015 , each=9)
melt_lpi$value<-as.numeric(as.character(melt_lpi$value))

#plot of actual trends
ggplot(data = melt_lpi, aes(y= value, x= Year, group=Populations.PatchID, col=Populations.PatchID))+
  geom_line()

melt_lpi$model_type<-"Real"
melt_lpi$ID<-as.numeric(melt_lpi$Populations.PatchID)/100
melt_lpi<-melt_lpi[-1]

```

```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}
library(reshape2)
foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

bdf<-data.frame()
for(i in 1:length(foldernames)){
trends<-read.csv(paste(wd, "/",foldernames[i],"/pop_trend_output.csv", sep=""))
trends<-trends[,-1]
m_t<-melt(trends)
m_t$Year<-rep(1450:2016, each=9)
m_t$model_type<-foldernames[i]
m_t$ID<-alpine$ID
bdf<-rbind(bdf,m_t)
#print(i)
}

bdf_lpi<-rbind(bdf,melt_lpi)

pop_pred_539<-bdf_lpi[bdf_lpi$ID == 539 & bdf_lpi$Year >=1950,]
pop_pred_10694<-bdf_lpi[bdf_lpi$ID == 10694 & bdf_lpi$Year >=1950,]
pop_pred_10695<-bdf_lpi[bdf_lpi$ID == 10695 & bdf_lpi$Year >=1950,]
pop_pred_10696<-bdf_lpi[bdf_lpi$ID == 10696 & bdf_lpi$Year >=1950,]
pop_pred_10710<-bdf_lpi[bdf_lpi$ID == 10710 & bdf_lpi$Year >=1950,]
pop_pred_10713<-bdf_lpi[bdf_lpi$ID == 10713 & bdf_lpi$Year >=1950,]
pop_pred_10714<-bdf_lpi[bdf_lpi$ID == 10714 & bdf_lpi$Year >=1950,]
pop_pred_10717<-bdf_lpi[bdf_lpi$ID == 10717 & bdf_lpi$Year >=1950,]
pop_pred_10718<-bdf_lpi[bdf_lpi$ID == 10718 & bdf_lpi$Year >=1950,]

ggplot(pop_pred_539, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 539")
  
ggplot(pop_pred_10694, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10694")
  
ggplot(pop_pred_10695, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10695")
  
ggplot(pop_pred_10696, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10696")
  
ggplot(pop_pred_10710, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10710")
  
ggplot(pop_pred_10713, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10713")
  
ggplot(pop_pred_10714, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10714")
  
ggplot(pop_pred_10717, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10717")
  
ggplot(pop_pred_10718, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10718")
  

```


```{r, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}

#Comparison of the demoniche models to the lpi correlation models
library(lme4)
dt<-read.csv("Mammals_scaled_ready_for_models.csv")

foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

m0<-lmer(lambda_mean ~ change_rate_scale+mean_slope_scale+change_rate_scale:mean_slope_scale+Bodymass_scale+(1|Binomial)+(1|loc_id),data=dt, REML=F)
m1b<-lmer(lambda_mean ~ change_rate_scale+(1|Binomial)+(1|loc_id),data=dt, REML=F)
m1c<-lmer(lambda_mean ~ mean_slope_scale+(1|Binomial)+(1|loc_id),data=dt)


capra_df<-dt[dt$ID == 10696 | dt$ID == 10714 |dt$ID == 10694 | dt$ID == 10717 | dt$ID == 10713 |dt$ID == 10718 |dt$ID == 10695 |dt$ID == 539 |dt$ID == 10710 ,]


capras<-which(dt$ID == 10696 | dt$ID == 10714 | dt$ID == 10694 | dt$ID == 10717 | dt$ID == 10713 |dt$ID == 10718 |dt$ID == 10695 |dt$ID == 539 |dt$ID == 10710 )


pred<-10^(predict(m0)[capras])
pred_clim<-10^predict(m1c)[capras]   #climate only model
pred_luc<-10^predict(m1b)[capras]   #land use only model
real<-10^capra_df$lambda_mean

dlnl<-read.csv(paste(wd, "/", foldernames[1], "/pop_trend_output.csv", sep=""))  
dlnm<-read.csv(paste(wd, "/", foldernames[2], "/pop_trend_output.csv", sep=""))  
dlnh<-read.csv(paste(wd, "/", foldernames[3], "/pop_trend_output.csv", sep=""))  
dsgl<-read.csv(paste(wd, "/", foldernames[4], "/pop_trend_output.csv", sep=""))  
dsgm<-read.csv(paste(wd, "/", foldernames[5], "/pop_trend_output.csv", sep=""))  
dsgh<-read.csv(paste(wd, "/", foldernames[6], "/pop_trend_output.csv", sep=""))  
dltl<-read.csv(paste(wd, "/", foldernames[7], "/pop_trend_output.csv", sep=""))  
dltm<-read.csv(paste(wd, "/", foldernames[8], "/pop_trend_output.csv", sep=""))  
dlth<-read.csv(paste(wd, "/", foldernames[9], "/pop_trend_output.csv", sep=""))  

demo_link_low<-10^rowMeans(diff(as.matrix(log10(dlnl[,c(900:967)]),nrow=9)))
demo_link_mid<-10^rowMeans(diff(as.matrix(log10(dlnm[,c(900:967)]),nrow=9)))
demo_link_high<-10^rowMeans(diff(as.matrix(log10(dlnh[,c(900:967)]),nrow=9)))
demo_sigk_low<-10^rowMeans(diff(as.matrix(log10(dsgl[,c(900:967)]),nrow=9)))
demo_sigk_mid<-10^rowMeans(diff(as.matrix(log10(dsgm[,c(900:967)]),nrow=9)))
demo_sigk_high<-10^rowMeans(diff(as.matrix(log10(dsgh[,c(900:967)]),nrow=9)))
demo_lt_low<-10^rowMeans(diff(as.matrix(log10(dltl[,c(900:967)]),nrow=9)))
demo_lt_mid<-10^rowMeans(diff(as.matrix(log10(dltm[,c(900:967)]),nrow=9)))
demo_lt_high<-10^rowMeans(diff(as.matrix(log10(dlth[,c(900:967)]),nrow=9)))

lambda_preds<-cbind(real,pred, pred_clim,pred_luc,  demo_link_low, demo_link_mid,demo_link_high,demo_sigk_low, demo_sigk_mid, demo_sigk_high,demo_lt_low,demo_lt_mid,demo_lt_high)


#pairs(lambda_preds)

```



```{r, eval=FALSE, echo=FALSE}
#Comparison of model predictions with the real values

par(mfrow=c(3,4))

for (i in 2:ncol(lambda_preds-1)){
  plot(lambda_preds[,1], lambda_preds[,i], main=colnames(lambda_preds)[i], ylab=colnames(lambda_preds)[i], xlab=colnames(lambda_preds)[1])
 #print(i) 
}


```


```{r, eval=FALSE, echo=FALSE, warning=FALSE}

patch_run_dz <- demoniche_model_VE(modelname = "Capra_ibex_patch", Niche = TRUE, 
                                     Dispersal = T, repetitions = 1,
                                     foldername = "damaris_function")

patch_run_dz[,"Meanpop","Reference_matrix"]

years<-1450:2016
#plot(RPyran_disp_niche[,"Meanpop","Reference_matrix"])
bleh<-(patch_run[,"Meanpop","Reference_matrix"])

plot(years, bleh, type="l", xlim=c(1950,2016))

```


```{r,cache=TRUE, echo=FALSE, warning=FALSE, eval=FALSE}


#Varying the carrying capacity - 16000, 4000, 2000, 1000


matrices_var<-matrix(1, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 

source("demoniche_setup_me.R")
  demoniche_setup_me(modelname = "Capra_k_16000",Populations = Populations, Nichemap = patch_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = 0.5, fraction_SDD = 0.5,
                  dispersal_constants = c(13.6, 77),
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=2671, Kweight = K_weight, 
                  sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_4000",Populations = Populations, Nichemap = patch_spin_up,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=4000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_2000",Populations = Populations, Nichemap = patch_spin_up,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=2000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_1000",Populations = Populations, Nichemap = patch_spin_up,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=1000, Kweight = K_weight, 
                sumweight =sumweight)

source("demoniche_model_me.R")
c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


c_ibex_k_4000 <- demoniche_model_me(modelname = "Capra_k_4000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 2,
                                     foldername = "non_damaris_function")

c_ibex_k_2000 <- demoniche_model(modelname = "Capra_k_2000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

c_ibex_k_1000 <- demoniche_model(modelname = "Capra_k_1000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

plot(c_ibex_k_4000[,"Meanpop","Reference_matrix"], type="l")
lines(c_ibex_k_2000[,"Meanpop","Reference_matrix"])

p_16000<-(c_ibex_k_16000[,"Meanpop",1])
p_4000<-(c_ibex_k_4000[,"Meanpop","Reference_matrix"])
p_2000<-(c_ibex_k_2000[,"Meanpop","Reference_matrix"])
p_1000<-(c_ibex_k_1000[,"Meanpop","Reference_matrix"])

plot(p_16000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="")
lines(p_4000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="",col="green")
lines(p_2000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="red")
lines(p_1000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="blue")

10^mean(diff(log10(na.omit(p_16000[900:966]))))
10^mean(diff(log10(p_4000[900:966])))
10^mean(diff(log10(p_2000[900:966])))
10^mean(diff(log10(p_1000[900:966])))

```



```{r, eval=FALSE, echo=FALSE}
# RPyran_disp_niche_scale <- demoniche_model(modelname = "Capra_ibex_scale", Niche = TRUE, 
#                                      Dispersal = TRUE, repetitions = 1,
#                                      foldername = "RPyran_disp_niche")



years<-1950:2016
years<-1450:2016
#plot(RPyran_disp_niche[,"Meanpop","Reference_matrix"])
bleh<-(RPyran_disp_niche_scale[,"Meanpop","Reference_matrix"])
link_years<-(RPyran_disp_niche_scale_lk[,"Meanpop","Reference_matrix"])
lk_years<-(RPyran_disp_niche_scale_link[,"Meanpop","Reference_matrix"])
#plot(years, bleh, type="l", ylab="Number of Alpine Ibex")


plot(years[(length(years-67)):length(years)], bleh[(length(years-67)):length(years)], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="")
lines(years[(length(years-67)):length(years)], lk_years[(length(years-67)):length(years)], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="", col="red")
lines(years[(length(years-67)):length(years)], link_years[(length(years-67)):length(years)], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="", col="green")


mean(diff(log10(bleh[900:967])), type="l")
mean(diff(log10(lk_years[900:967])), type="l")
mean(diff(log10(link_years[900:967])), type="l")

```


