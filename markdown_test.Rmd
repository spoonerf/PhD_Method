---
title: "Chapter Three Workflow"
author: "Fiona Spooner"
date: "September 6, 2017"
output: html_document
---
###Chapter 3 workflow

```{r, eval=FALSE, message=FALSE}
install.packages('climates',,'http://www.rforge.net/')
install.packages("dismo")
install.packages("maps")
install.packages("mapdata")
```

```{r, message= FALSE, warning=FALSE}
library(zoo)
library(dismo)
```

#####Creating Bioclim varibles for each year 1950-2016 for Europe - this only needs to be done once
```{r, eval=FALSE, message=FALSE, warning=FALSE}
rr<-brick(paste(wd, "/rr_0.25deg_reg_v15.0.nc", sep="")) #precipitation
tg<-brick(paste(wd, "/tg_0.25deg_reg_v15.0.nc", sep="")) #mean temp
tn<-brick(paste(wd, "/tn_0.25deg_reg_v15.0.nc", sep="")) #min temp
tx<-brick(paste(wd, "/tx_0.25deg_reg_v15.0.nc", sep="")) #max temp
#dates<-as.Date((gsub("X", "",names(rr))), format="%Y.%m.%d")


rr_mon<-zApply(rr, by=as.yearmon, fun = mean)
tg_mon<-zApply(tg, by=as.yearmon, fun = mean)
tn_mon<-zApply(tn, by=as.yearmon, fun = mean)
tx_mon<-zApply(tx, by=as.yearmon, fun = mean)

jans<-seq(1,804, by=12)
years<-as.character(1950:2016)

for (i in 1:length(years)){
  jan_sel<-jans[i]
  dec_sel<-jan_sel+11
  bio_vars_all<-biovars(rr_mon[[jan_sel:dec_sel]], tn_mon[[jan_sel:dec_sel]], tx_mon[[jan_sel:dec_sel]])  
  writeRaster(bio_vars_all, paste("C:/Users/Fiona/Documents/PhD/PhD_Method/Bioclim/", years[i],"_bioclim_variable_stack.tif", sep=""), overwrite=T)
  print(years[i])
  }
```

#####Dismo SDMs

Extracting Alpine ibex data from GBIF and adding in the locations from the LPI dataset - need to check the LPI populations are from after 1985. Formatting these points as a spatialpointsdataframe
```{r, cache=TRUE, message= FALSE, warning=FALSE}
library(dismo)
library(demoniche)
library(maps)
library(mapdata)
library(rgeos)


#Extracting Alpine ibex data from GBIF
wd<- getwd()
capra <-gbif("capra", "ibex", geo=FALSE)
capgeo <- subset(capra, !is.na(lon) & !is.na(lat) & (lon!="NA" & lat !="NA") | year!="NA") 
dups <- duplicated(capgeo[, c("lon", "lat")])
capg <-capgeo[!dups, ]
capg2 <- capg[capg$lon > 0 & capg$lon<16 & capg$lat > 43 & capg$lat < 47.9 & capg$year>=2006, ] 
capg2<-data.frame(capg2$lon,capg2$lat)
colnames(capg2)<-c("Longitude", "Latitude")

species<-"Capra_ibex"
df2<-read.csv("LPI_pops_20160523_edited.csv")
pyr<-subset(df2, Binomial ==species & Specific_location==1)    #record 11470 had wrong longitude - in Russia!
pyrs<-pyr[,c("Longitude","Latitude")]
capg2<-rbind(capg2, pyrs)
capg2<-na.omit(capg2)
capg2$presence<-rep(1)
capg2$ID<-1:nrow(capg2)

capc<-as.matrix(capg2[ , c( "Longitude","Latitude", "presence")])
capc<-matrix(capc[complete.cases(capc)], ncol=3)
xy<-as.matrix(capc[,c(1,2)])
df<-data.frame(capc[,3])
sp<-SpatialPointsDataFrame(coords=xy, data=df)
x <- circles(sp, d=50000, lonlat=TRUE)
pol <- polygons(x)
```

```{r, message=FALSE, warning=FALSE}
e<-extent(sp)
e_big<-e+4
maps:::map('world',c('Italy', 'Switzerland', 'Austria', 'Monaco','Liechtenstein','Germany', 'Slovenia', 'France'),  col="light grey", fill=T, xlim=c(e_big[1],e_big[2]), ylim=c(e_big[3],e_big[4]))
plot(pol,add=T)
points(sp, col="red", pch=20)

```

Creating the 1985-2016 average for each bioclim variable and pulling out the layers we want to use in the model.

I have picked out:

•	Bioclim 1 – Annual mean temperature

•	Bioclim 5 – Max temperature of the warmest month

•	Bioclim 6 – Min temperature of the coldest month

•	Bioclim 13 – Precipitation of the wettest month

•	Bioclim 15 – Precipitation seasonality (coefficient of variation)

•	Bioclim 18 – Precipitation of warmest quarter

•	Bioclim 19 – Precipitation of coldest quarter

Snow septh seems to be an important predictor for alpine ibex but I have struggled to find historical data on this. Existing papers are based on one weather stations historical data, which means there is no spatial variation and therefore it is not appropriate for these models.

```{r,cache=TRUE, message=FALSE, warning=FALSE}
e<-extent(sp)+4

lf<-list.files(paste(wd, "/Bioclim/", sep=""))

first<-which(grepl("2006_bioclim", lf)) #was initially 1985
last<-which(grepl("2016_bioclim", lf))
all_years<-stack(paste(wd, "/Bioclim/",lf[first:last], sep=""))

bios<-seq(1,nlayers(all_years), by=19)
cellStats(all_years[[bios]], stat="mean")
#creating a 1985-2016 average of each bioclim variable
for (i in 1:19){
  layers<-bios
  bio_layer<-mean(all_years[[layers]])
  writeRaster(bio_layer, paste(wd, "/Bioclim/Bio_",i,"_2006_2016_average.tif",sep=""), overwrite=TRUE) #was initially 1985_2016
  bios<-bios+1
  #print(layers)
}

#pulling out the bioclim layers i'm interested in
bio_layer_pred<-c(1,5,6,13,15,18,19)  #picking out the bioclim layers we want to use in the model
#pred_nf<-stack(paste(wd, "/Bioclim/Bio_", bio_layer_pred,"_1985_2016_average.tif",sep="" ))
```

```{r}
pred_nf<-stack(paste(wd, "/Bioclim/Bio_", bio_layer_pred,"_2006_2016_average.tif",sep="" ))
```

Creating training and testing presence and background data - each time I run this a different sample of randomPoints is selected and I am not sure if that is correct and to what extent it impacts the resulting models.
```{r, cache=TRUE, message=FALSE, warning=FALSE}

set.seed(10)

k<-4
#group_pres<-kfold(sp, k)
#write.csv(group_pres, "k_folds_presence.csv")
#write.csv(group_pres, "k_folds_presence_2006.csv")
#group_pres<-read.csv("k_folds_presence.csv")
group_pres<-read.csv("k_folds_presence_2006.csv")
group_pres<-group_pres[,-1]  #all presence points

sp_train<-sp[group_pres!=1,] #presence points split into training and test
sp_test<-sp[group_pres==1,]

#backg <- randomPoints(pred_nf, n=1000, ext=e, extf = 1.25)
#write.csv(backg, "background_random_points.csv") 

backg<-read.csv("background_random_points.csv")
backg<-backg[,-1]
colnames(backg) = c('lon', 'lat')
#group_back <- kfold(backg, k)
#write.csv(group_back, "k_folds_background.csv")
group_back<-read.csv("k_folds_background.csv")
group_back<-group_back[,-1]   #all background points

sp_backg_train <- backg[group_back != 1, ] #background points split into training and test
sp_backg_test <- backg[group_back == 1, ]

sp_train<-data.frame(sp_train)[,c(2,3)] #presence training points
colnames(sp_train)<-c("lon", "lat")
train <- rbind(sp_train, sp_backg_train)  #presence and background training points combined

sp_test<-data.frame(sp_test)[,c(2,3)]  #presence test points
colnames(sp_test)<-c("lon", "lat")
test<-rbind(sp_test, sp_backg_test)    #presence and background test points combined

pb_train <- c(rep(1, nrow(sp_train)), rep(0, nrow(sp_backg_train)))  
envtrain <- extract(pred_nf, train)
envtrain <- data.frame( cbind(pa=pb_train, envtrain) ) #training points with environmental  variables

pb_test<-c(rep(1, nrow(sp_test)), rep(0, nrow(sp_backg_test)))
envtest <- extract(pred_nf, test)
envtest <- data.frame( cbind(pa=pb_test, envtest) ) #test points with environmental  variables

env_all<-rbind(envtrain, envtest) #all of the training and test data with environmental variables

env_pres<-extract(pred_nf, sp)
pa<-rep(1, nrow(env_pres))
env_pres<-data.frame(pa, env_pres)  #presence points with environmental variables
colnames(env_pres)<-c("pa","Bio_1_2006_2016_average", "Bio_5_2006_2016_average","Bio_6_2006_2016_average","Bio_13_2006_2016_average","Bio_15_2006_2016_average","Bio_18_2006_2016_average","Bio_19_2006_2016_average")

env_back<-extract(pred_nf, backg)
ap<-rep(0, nrow(env_back))
env_back<-data.frame(ap, env_back) #background points with environmental variables
colnames(env_back)<-c("pa","Bio_1_2006_2016_average", "Bio_5_2006_2016_average","Bio_6_2006_2016_average","Bio_13_2006_2016_average","Bio_15_2006_2016_average","Bio_18_2006_2016_average","Bio_19_2006_2016_average")
```

#####Bioclim

Running the bioclim envelope model and evaluating it to get an AUC value

```{r, cache=TRUE, message=FALSE, warning=FALSE}

#group_back <- kfold(pb_train, k)
evl_bc<- list()
tss_bc<-list()
for (i in 1:k){
  pres_train<-sp[group_pres!=i,]
  pres_test<-sp[group_pres==i,]
  #backg_train<-sp[group_back!=i,]
  backg_test<-backg[group_back==i,]
  bc <- bioclim(pred_nf,pres_train)
  evl_bc[[i]] <- dismo:::evaluate(pres_test, backg_test, bc,pred_nf,type="response")#test presence, test absence, model, predictor variables (raster stack)
   tss_bc[[i]]<-evl_bc[[i]]@t[which.max(evl_bc[[i]]@TPR + evl_bc[[i]]@TNR -1)]
  #print(i)
}

auc_bc <- sapply( evl_bc, function(x){slot(x, "auc")} )
print(auc_bc)

kap_bc<-sapply( evl_bc, function(x){threshold(x)['kappa']} )
noem_bc<-sapply( evl_bc, function(x){threshold(x)['no_omission']} )

bc_auc<-mean(auc_bc)
# bc_kap<-mean(unlist(kap_bc))
# bc_noem<-mean(unlist(noem_bc))
# bc_tss<-mean(unlist(tss_bc))

bc_kap<-max(unlist(kap_bc))
bc_noem<-max(unlist(noem_bc))
bc_tss<-max(unlist(tss_bc))

```

#####GAM

Running a gam and evaluating it to get an AUC value

```{r, cache= TRUE, message=FALSE, warning=FALSE}
library(mgcv)
#gm1<-gam(pa~ s(Bio_1_1985_2016_average)+s(Bio_5_1985_2016_average)+ s(Bio_6_1985_2016_average)+ 
#           s(Bio_13_1985_2016_average)+ s(Bio_15_1985_2016_average)+ s(Bio_18_1985_2016_average)+ 
#           s(Bio_19_1985_2016_average), family = binomial(link = "logit"),data=env_all)

gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=env_all)

gp<-predict(pred_nf, gm1)
r<-calc(gp, fun=function(x){ exp(x)/(1+exp(x))})

evl_gam<- list()
tss_gam<-list()
for (i in 1:k){
  pres_train<-env_pres[group_pres!=i ,]
  pres_test<-env_pres[(group_pres==i) ,]
  back_test<-env_back[(group_back==i),]
  back_train<-env_back[(group_back!=i),]
  envtrain<-rbind(pres_train, back_train)
 # gm1<-gam(pa~ s(Bio_1_1985_2016_average)+ s(Bio_5_1985_2016_average)+ 
  #           s(Bio_6_1985_2016_average)+ s(Bio_13_1985_2016_average)+ 
   #          s(Bio_15_1985_2016_average)+ s(Bio_18_1985_2016_average)+ 
    #         s(Bio_19_1985_2016_average),family= binomial(link = "logit") , data=envtrain)
  gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=envtrain)

  evl_gam[[i]] <- dismo:::evaluate(pres_test, back_test, gm1, type="response")
  tss_gam[[i]]<-evl_gam[[i]]@t[which.max(evl_gam[[i]]@TPR + evl_gam[[i]]@TNR -1)]
  #print(i)
}

auc_gam <- sapply( evl_gam, function(x){slot(x, "auc")} )
print(auc_gam)
kap_gam<-sapply( evl_gam, function(x){threshold(x)['kappa']} )
noem_gam<-sapply( evl_gam, function(x){threshold(x)['no_omission']} )
print(kap_gam)
gam_auc<-mean(auc_gam)
# gam_kap<-mean(unlist(kap_gam))
# gam_noem<-mean(unlist(noem_gam))
# gam_tss<-mean(unlist(tss_gam))

gam_kap<-max(unlist(kap_gam))
gam_noem<-max(unlist(noem_gam))
gam_tss<-max(unlist(tss_gam))


```

#####Random Forest

Running the random forest envelope model and evaluating it to get an AUC value

```{r, cache= TRUE, message= FALSE, warning=FALSE}
library(randomForest)

#model<-pa~  Bio_1_1985_2016_average+Bio_5_1985_2016_average+ 
#  Bio_6_1985_2016_average+ Bio_13_1985_2016_average+ Bio_15_1985_2016_average+ 
#  Bio_18_1985_2016_average+ Bio_19_1985_2016_average

model<-pa~  Bio_1_2006_2016_average+Bio_5_2006_2016_average+ 
  Bio_6_2006_2016_average+ Bio_13_2006_2016_average+ Bio_15_2006_2016_average+ 
  Bio_18_2006_2016_average+ Bio_19_2006_2016_average


evl_rf<- list()
tss_rf<- list()
for (i in 1:k){
  pres_train<-env_pres[group_pres!=i,]
  pres_test<-env_pres[(group_pres==i) ,]
  back_test<-env_back[(group_back==i),]
  back_train<-env_back[group_back !=i,]
  envtrain<-rbind(pres_train, back_train)
  rf1 <- randomForest(model, data=envtrain)
  evl_rf[[i]] <- dismo:::evaluate(pres_test, back_test, rf1,type="response")
  tss_rf[[i]]<-evl_rf[[i]]@t[which.max(evl_rf[[i]]@TPR + evl_rf[[i]]@TNR -1)]
  
  }

auc_rf <- sapply( evl_rf, function(x){slot(x, "auc")} )
print(auc_rf)
kap_rf<-sapply( evl_rf, function(x){threshold(x)['kappa']} )
noem_rf<-sapply( evl_rf, function(x){threshold(x)['no_omission']} )

rf_auc<-mean(auc_rf)
# rf_kap<-mean(unlist(kap_rf))
# rf_noem<-mean(unlist(noem_rf))
# rf_tss<-mean(unlist(tss_rf))

rf_kap<-max(unlist(kap_rf))
rf_noem<-max(unlist(noem_rf))
rf_tss<-max(unlist(tss_rf))

```


#####Using the models to predict

Creating a weighted ensemble averaged suitability model for 1985-2016 which can be used to predict suitability backwards

```{r, cache=TRUE, warning=FALSE, message=FALSE}
#total models
bc <- bioclim(pred_nf, sp)
#gm1<-gam(pa~ s(Bio_1_1985_2016_average)+s(Bio_5_1985_2016_average)+ s(Bio_6_1985_2016_average)+ 
#           s(Bio_13_1985_2016_average)+ s(Bio_15_1985_2016_average)+ s(Bio_18_1985_2016_average)+ 
#           s(Bio_19_1985_2016_average), family = binomial(link = "logit"),data=env_all)
gm1<-gam(pa~ s(Bio_1_2006_2016_average)+s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ 
           s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+ s(Bio_18_2006_2016_average)+ 
           s(Bio_19_2006_2016_average), family = binomial(link = "logit"),data=env_all)

rf1 <- randomForest(model, data=env_all)

pb <- predict(pred_nf, bc, ext=e, progress='') #bioclim predict
pg <- predict(pred_nf, gm1, ext=e) #gam predict
pgl<-calc(pg, fun=function(x){ exp(x)/(1+exp(x))}) #backtransforming from logit space
pr <- predict(pred_nf, rf1, ext=e) #random forest predict

models <- stack(pb, pgl, pr)
names(models) <- c("bioclim", "gam", "random forest")
plot(models)

auc<-c(bc_auc, gam_auc, rf_auc)
w <- (auc-0.5)^2
wm <- weighted.mean( models[[c("bioclim", "gam", "random.forest")]], w)
plot(wm)
points(sp)
```

Not sure if the way I am calculating the TSS threshold is correct

```{r,eval=FALSE, warning=FALSE, message=FALSE}
#thresholds - perhaps redundant for now?

thresh_noem<-weighted.mean(c(bc_noem, gam_noem, rf_noem),w)
thresh_weighted_kap<-weighted.mean(c(bc_kap, gam_kap, rf_kap), w)
thresh_weighted_tss<-weighted.mean(c(bc_tss, gam_tss, rf_tss),w)

tholds<-c(thresh_noem, thresh_weighted_kap, thresh_weighted_tss)
names<-c("no omission", "kappa", "TSS")

cbind(names, tholds)
```

Using the ensemble model to predict suitability for each year - 1950-2016 and for each year creating a binary presence/absence map based on a few different thresholding techniques. Have used TSS in the rest of the analysis as per Allouche 2006 which said it outperformed kappa which I believe was previously most prominent.

```{r, cache=TRUE, eval=FALSE, message=FALSE, warning=FALSE}

bc <- bioclim(pred_nf, sp)
gm1<-mgcv:::gam(pa~ s(Bio_1_2006_2016_average)+ s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ s(Bio_13_2006_2016_average)+ s(Bio_15_2006_2016_average)+s(Bio_18_2006_2016_average)+ s(Bio_19_2006_2016_average), data=env_all)
rf1 <- randomForest:::randomForest(model, data=env_all)


years<-1950:2016
library(raster)
library(mgcv)
library(randomForest)
for (i in 1:length(years)){
  
  pred_nf<-stack(paste(wd, "/Bioclim/", years[i], "_bioclim_variable_stack.tif", sep="" ))  
  pred_nf<-pred_nf[[bio_layer_pred]]
 # names(pred_nf)<-c("Bio_1_1985_2016_average","Bio_5_1985_2016_average", "Bio_6_1985_2016_average", "Bio_13_1985_2016_average" ,"Bio_15_1985_2016_average","Bio_18_1985_2016_average", "Bio_19_1985_2016_average")
  names(pred_nf)<-c("Bio_1_2006_2016_average","Bio_5_2006_2016_average", "Bio_6_2006_2016_average", "Bio_13_2006_2016_average" ,"Bio_15_2006_2016_average","Bio_18_2006_2016_average", "Bio_19_2006_2016_average")
  
  pb <- predict(pred_nf, bc, ext=e, progress='')
  pg <- predict(pred_nf, gm1, ext=e) #gam predict
  pgl<-calc(pg, fun=function(x){ exp(x)/(1+exp(x))})
  pr <- predict(pred_nf, rf1, ext=e)
  
  models <- stack(pb, pgl, pr)
  names(models) <- c("bioclim", "gam", "random forest")
  wm <- weighted.mean( models[[c("bioclim", "gam", "random.forest")]], w)
  
  pa_noem<-wm>thresh_noem
  pa_k<-wm>thresh_weighted_kap
  pa_tss<- wm>thresh_weighted_tss
  
 writeRaster(wm , paste(wd, "/Alp_SDMs/Ensembles_2006_2016/weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)
  writeRaster(pa_noem , paste(wd, "/Alp_SDMs/Ensembles_2006_2016/pres_abs_no_emission_weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)
  writeRaster(pa_k , paste(wd, "/Alp_SDMs/Ensembles_2006_2016/pres_abs_kappa_weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)
  writeRaster(pa_tss, paste(wd, "/Alp_SDMs/Ensembles_2006_2016/pres_abs_true_skill_stat_weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE )
  
  print(years[i])
  # print(cellStats(pa, "max"))
  # print(cellStats(pa_k, "max"))
  # print(cellStats(pa_p, "max"))
  # print(cellStats(pa_e, "max"))
  plot(wm, main=years[i])
}

```


Trends in habitat suitability 1950-2016

```{r}
years<-1950:2016
t<-stack(paste(wd,"/Alp_SDMs/Ensembles_2006_2016/weighted_ensemble_sdm_", years,".tif", sep=""))
s<-round(seq(1,67,len=16))

plot(t[[s]])

patch<-stack(paste(wd,"/Alp_SDMs/Ensembles_2006_2016/pres_abs_no_emission_weighted_ensemble_sdm_", years,".tif", sep=""))
plot(patch[[s]])

patch_kap<-stack(paste(wd,"/Alp_SDMs/Ensembles_2006_2016/pres_abs_kappa_weighted_ensemble_sdm_", years,".tif", sep=""))
plot(patch_kap[[s]])

patch_tss<-stack(paste(wd,"/Alp_SDMs/Ensembles_2006_2016/pres_abs_true_skill_stat_weighted_ensemble_sdm_", years,".tif", sep=""))
plot(patch_tss[[s]])

m<-cellStats(t, stat="mean")
sd<-cellStats(t, stat="sd")

plot(years,m, type="l", main="Average habitat suitability over time", ylim=c(0,0.5), ylab="Suitability index", xlab="Years")
lines(years, m+(2*sd), col="red", lty=3)
lines(years, m-(2*sd), col="red", lty=3)




```

Patches
```{r, warning=FALSE}
year_patch<-data.frame(years = years, patch_num = numeric(length(years)) )

for (i in 1:length(years)){
c<-clump(patch[[i]])
year_patch[i,2]<-max(na.omit(values(c)))
#print(i)
}

year_patch_kap<-data.frame(years = years, patch_num = numeric(length(years)) )

for (i in 1:length(years)){
c<-clump(patch_kap[[i]])
year_patch_kap[i,2]<-max(na.omit(values(c)))
#print(i)
}

year_patch_tss<-data.frame(years = years, patch_num = numeric(length(years)) )

for (i in 1:length(years)){
c<-clump(patch_tss[[i]])
year_patch_tss[i,2]<-max(na.omit(values(c)))
#print(i)
}
par(mar=c(4,4,4,5))

mk<-cellStats(patch_kap, stat="sum")
plot(years,mk, type="l", main="Predicted patch presence - kappa", ylab="Suitable squares", xlab="Years", col="red")
par(new=TRUE)
par(mar=c(4,4,4,5))
plot(year_patch_kap$years, year_patch_kap$patch_num,type="l",col="blue",xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("Number of Patches",side=4,line=3)
legend("topright",col=c("red","blue"),lty=1,legend=c("Suitable Squares","Number of Patches"))

mno<-cellStats(patch, stat="sum")
par(mar=c(4,4,4,5))
plot(years,mno, type="l", main="Predicted patch presence - no omission", ylab="Suitable squares", xlab="Years", col="red")
par(new=TRUE)
par(mar=c(4,4,4,5))
plot(year_patch$years, year_patch$patch_num,type="l",col="blue",xaxt="n",yaxt="n",xlab="",ylab=" ")
axis(4)
mtext("Number of Patches",side=4,line=3)
legend("left",col=c("red","blue"),lty=1,legend=c("Suitable Squares","Number of Patches"))


mtss<-cellStats(patch_tss, stat="sum")
plot(years,mtss, type="l", main="Predicted patch presence - true skill statistic", ylab="Suitable squares", xlab="Years", col="red")
par(new=TRUE)
par(mar=c(4,4,4,5))
plot(year_patch_tss$years, year_patch_tss$patch_num,type="l",col="blue",xaxt="n",yaxt="n",xlab="",ylab=" ")
axis(4)
mtext("Number of Patches",side=4,line=3)
legend("topright",col=c("red","blue"),lty=1,legend=c("Suitable Squares","Number of Patches"))


```


#####Copying the 1950 files for the 900 year spin up
```{r, eval=FALSE, message=FALSE, warning=FALSE}
spin_years<-1050:1949
from_sdm<- paste(wd, "/Alp_SDMs/Ensembles/weighted_ensemble_sdm_1950.tif", sep="")
to_sdm<-paste(wd, "/Alp_SDMs/Ensembles/weighted_ensemble_sdm_",spin_years, ".tif", sep="")

from_pa<- paste(wd, "/Alp_SDMs/Ensembles/pres_abs_no_emission_weighted_ensemble_sdm_1950.tif", sep="")
to_pa<-paste(wd, "/Alp_SDMs/Ensembles/pres_abs_no_emission_weighted_ensemble_sdm_",spin_years, ".tif", sep="")

from_kap<- paste(wd, "/Alp_SDMs/Ensembles/pres_abs_kappa_weighted_ensemble_sdm_1950.tif", sep="")
to_kap<-paste(wd, "/Alp_SDMs/Ensembles/pres_abs_kappa_weighted_ensemble_sdm_",spin_years, ".tif", sep="")


file.copy(from_sdm,to_sdm, overwrite = T)
file.copy(from_pa,to_pa, overwrite = T)
file.copy(from_kap,to_kap, overwrite = T)


```

### Demoniche

Formatting the data for use in demoniche
```{r, warning=FALSE, message=FALSE}
library(demoniche)
library(rgdal)
library(raster)
species<-"Capra_ibex"

df2<-read.csv("LPI_pops_20160523_edited.csv")
pyr<-subset(df2, Binomial ==species & Specific_location==1)    #record 11470 had wrong longitude - in Russia!

#formatting the data for use in demoniche
pyrs<-pyr[,c("ID","Longitude","Latitude")]

id<-pyrs$ID*100
lam<-rep(1,length(id))    #not sure what the value here pertains to - think it sets starting population so should use values from LPI?
pyrxy<-SpatialPoints(pyr[,c("Longitude","Latitude")])

wd<-getwd()
sdm<-raster(paste(wd,"/Alp_SDMs/Ensembles/pres_abs_weighted_ensemble_sdm_1950.tif", sep=""))
e2<-extent(sdm)

r<-raster(e2, resolution=res(sdm))

rz<-rasterize(pyrxy,r,lam )
rid<-rasterize(pyrxy,r,id)
# plot(rz)
# plot(rid)

rz_spdf<-xyFromCell(rz, 1:ncell(rid))

rzm<-as.vector(rz)
ridm<-as.vector(rid)

df<-data.frame(ridm,rz_spdf,rzm)
colnames(df)<-c( "PatchID","X","Y","area")

Populations<-data.frame(na.omit(df)) 

```


```{r, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}

#formatting the sdm data


years<-1050:2016

sdm_patch_df<-data.frame(ID=1:ncell(rid))
sdm_df<-data.frame(ID=1:ncell(rid))


#formatting data for demoniche
for (i in 1:length(years)){
  
  #a selection of different threshold techniques for presence absence, as well as a suitability surface
  sdm<-raster(paste(wd,"/Alp_SDMs/Ensembles/weighted_ensemble_sdm_", years[i],".tif", sep=""))   #14.6
  #sdm<-raster(paste(wd,"/Alp_SDMs/Ensembles/pres_abs_weighted_ensemble_sdm_", years[i],".tif", sep="")) #15.4%  
  patch<-raster(paste(wd,"/Alp_SDMs/Ensembles/pres_abs_kappa_weighted_ensemble_sdm_", years[i],".tif", sep="")) #21.1%  
  #sdm<-raster(paste(wd,"/Alp_SDMs/Ensembles/pres_abs_prevalence_weighted_ensemble_sdm_", years[i],".tif", sep="")) #14,3%  
  #sdm<-raster(paste(wd,"/Alp_SDMs/Ensembles/pres_abs_equal_sens_spec_weighted_ensemble_sdm_", years[i],".tif", sep=""))  #13.1%
  #patch<-raster(paste(wd, "/Alp_SDMs/Ensembles/pres_abs_true_skill_stat_weighted_ensemble_sdm_", years[i],".tif", sep=""))
  if (i ==1){
    vec<-as.data.frame(sdm, xy = TRUE)
    vec_pat<-as.data.frame(patch, xy=TRUE)
  } else{
    vec<-as.data.frame(sdm)
    vec_pat<-as.data.frame(patch)
  }
  
  sdm_df<-cbind(sdm_df, vec)
  sdm_patch_df<-cbind(sdm_patch_df,vec_pat)
  #print(i)
}

sdm_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]
sdm_patch_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]

niche_map_mine<-sdm_df
colnames(niche_map_mine)[1:3]<-c("gridID", "X", "Y")


patch_map_mine<-sdm_patch_df
colnames(patch_map_mine)[1:3]<-c("gridID", "X", "Y")

col_years<-paste("Year_", 1950:2016, sep="")
col_years<-paste("Year_", 1050:2016, sep="")

colnames(niche_map_mine)[4:length(colnames(niche_map_mine))]<-col_years
colnames(patch_map_mine)[4:length(colnames(patch_map_mine))]<-col_years

#niche_formulas <- as.formula(paste(paste(colnames(niche_map_mine)[-c(1:3)], collapse="+"),"X+Y",sep="~"))

#print(levelplot(niche_formulas, niche_map_mine, col.regions=rev(heat.colors(100)), main = "Niche Values"))

no_yrs_mine<-1 #number of years each time period represents 


plot(years,colMeans(na.omit(niche_map_mine)[4:length(colnames(niche_map_mine))]), type="l", ylab="Mean suitability index")

years_short<-1950:2016
plot(years_short,colMeans(na.omit(niche_map_mine)[904:length(colnames(niche_map_mine))]), type="l", ylab="Mean suitability index")

niche_map_mine<-na.omit(niche_map_mine)
patch_map_mine<-na.omit(patch_map_mine)



```

#####Comadre

Accessing the population matrices from comadre - there are 5 matrices available for the alpine ibex but four are for the same area and only represent survival over two time periods in good/bad conditions.

```{r, warning=FALSE, message=FALSE}
#Population matrix set up


load(paste(wd, "COMADRE_v.2.0.1.RData", sep="/"))

#load(paste(wd, "COMADRE_v.1.0.0.RData", sep="/"))

species<-"Capra_ibex"

tempMetadata<-subset(comadre$metadata, SpeciesAccepted==species)

keep<-as.numeric(rownames(tempMetadata))

tempMat<-comadre$mat[keep]   #MatA is matrix pop model, can be split into U, F and/or C

MatList<-list(tempMat[[1]][[1]])  #varies depending on number of matrices - need to find a way to code this better - now have five matrices available so need to sort this
AllMat<-unlist(MatList)
matrices<-matrix(AllMat, ncol=length(MatList))
colnames(matrices)<- c("Reference_matrix")

#tempMat<-(tempMat[[2]][[1]] + tempMat[[3]][[1]] + tempMat[[4]][[1]]+ tempMat[[5]][[1]])/4
#MatList<-list(tempMat[[2]][[1]], tempMat[[3]][[1]] ,tempMat[[4]][[1]], tempMat[[5]][[1]])
# AllMat<-unlist(MatList)
# matrices<-matrix(AllMat, ncol=length(MatList))
# #matrices<-matrix(tempMat, ncol=1)
# colnames(matrices)<- c("Reference_matrix", "Matrix_1", "Matrix_2", "Matrix_3")

```

#####Demoniche setup
Parameterising the demoniche model

```{r, cache=TRUE,  message=FALSE, warning=FALSE}
prob_scenario<-c(0.5,0.5)    #need to check this

noise<-0.90     #not yet active in demoniche

stages<-comadre$matrixClass[keep][[1]]$MatrixClassAuthor
#stages<-comadre$matrixClass[keep][[2]]$MatrixClassAuthor
#stagesf<-stages[1:3]

list_names_matrices<-colnames(matrices)

sumweight<-rep(1, length(stages)) #weight of stages  - should be equal for all mine just 
#in plants seed not included in calculating population sizes - or if you wanted to just 
#calculate the female population it would be c(1,1,1,0,0,0)
#sumweightf<-c(1,1,1)

transition_affected_niche<-c(2,11,20)   #which parts of the matrix are affected by the c(1,2) is juveniles
#niche values

transition_affected_env <- "all"

transition_affected_demogr <- "all"

env_stochas_type<-"normal"   #can also be lognormal

matrices_var <- matrix(0.01, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd")) 
#standard deviation of matrices

proportion_initial<- rep(1/length(stages), length(stages)) #proportion of population in 
#each stage - no idea what this should be and will likely have a big impact on results! 
#- just doing eqaul splits for now
#proportion_initialf<- c(1/3,1/3,1/3)

density_individuals <- 4000  #4292.32 to 16096.2 based on density being between 8 and 30 per 100 ha and the area of each cell being 53654 ha - 


K_weight<-c(rep(1, length(stages)))  #the weight with which carrying capacity affects each stage was FALSE


#niche_map_mine[is.na(niche_map_mine)]<-0
patch_map_mine[is.na(patch_map_mine)]<-0
```

#####Estimating carrying capacity from LPI data

Code from piero to estimate carrying capacity based on LPI population trends, using MCMC. I have done this for each of the 9 populations, not sure if I have done it the correct way.
```{r, eval=FALSE, message=FALSE, warning=FALSE}

ibex<-read.csv("LPI_pops_20160523_edited.csv")
ibex<-ibex[ibex$ID == 539 | ibex$ID == 10692|ibex$ID == 10694|ibex$ID == 10695|ibex$ID == 10696|
             ibex$ID == 10710 |ibex$ID == 10713|ibex$ID == 10714|ibex$ID == 10717 |ibex$ID == 10718,]

pop_datab <- ibex[,c(65:130)]

#539
pop_539<-c(2767, 2873, 3367, 3541, 3370, 3674, 3822, 2803, 3222, 3537, 3266, 3513, 3822, 
           3203,3431,3382, 2746, 3158, 3116, 3590, 3754, 2410, 3084, 3042, 3234,
           3412, 3255, 3187, 3362, 3740, 3914, 4283, 4303, 4694, 4631, 4790, 4754, 4991, 4136,
           4360, 3998, 3581, 3701, 3674, 3632)
years_539<-1956:2000

#10692
pop_10692<-c(158,128,135,139,134,116,128,130,159,189,211,242,249,246,254,256,251,235,234,
             222,204,211,232,256,270,277,304,275,287,268,256,253,247,241,NA,250)
years_10692<-1950:1985
df_10692<-data.frame(pop_10692, years_10692)


pop_10692_gam<-mgcv:::gam(pop_10692 ~ s(years_10692, k=round(length(years_10692)/2)))
pred_10692<-predict(pop_10692_gam,df_10692,type="response",se=FALSE) 
pop_10692[which(is.na(pop_10692))]<-pred_10692[which(is.na(pop_10692))]

#10694
pop_10694<-c(45,36,34,34,36,38,37,44,44,48,51,58,63,61,58,54,51,51,51,54,51,47,46,44,44,42,33,30,26,26,25,21,21,21,23)
years_10694<-1950:1984

#10695 

pop_10695<-c(211,237,269,299,323,355,377,398,415,437,448,439,432,424,415,408,399,392,384,375,377,
             385,397,409,421,432,444,454,468,471,454)
years_10695<-1950:1980

#10696

pop_10696<-c(16,13,13,13,13,11,13,18,25,32,39,51,54,56,65,65,66,70,78,82,92,111,127,146,153,156,
             166,172,185,206,215,218,241,246,265)
years_10696<-1950:1984


#10710

pop_10710<-c(14,28,NA,NA,NA,NA,63,88,92,NA,NA,NA,NA,185,210,284,341)
years_10710<-1989:2005
df_10710<-data.frame(pop_10710, years_10710)

pop_10710_gam<-mgcv:::gam(pop_10710 ~ s(years_10710, k=round(length(years_10710)/2)))
pred_10710<-predict(pop_10710_gam,df_10710,type="response",se=FALSE) 
pop_10710[which(is.na(pop_10710))]<-pred_10710[which(is.na(pop_10710))]


#10713

pop_10713<-c(193,173,183,220,230,248,258,267,277,248,248,272,291,286,251,221,216,223,231,228,145,163,
             179,194,176,157,178,148,178,169,169,182,193,205,225,233,214,240,279,229)
years_10713<-1950:1989


#10714

pop_10714<-c(8,15,26,30,NA,31,32,47,50,58,64,66,72,75,90)

years_10714<-1950:1964
df_10714<-data.frame(pop_10714, years_10714)

pop_10714_gam<-mgcv:::gam(pop_10714 ~ s(years_10714, k=round(length(years_10714)/2)))
pred_10714<-predict(pop_10714_gam,df_10714,type="response",se=FALSE) 
pop_10714[which(is.na(pop_10714))]<-pred_10714[which(is.na(pop_10714))]

#10717
pop_10717<-c(23,32,34,36,42,44,46,55,60,73)
years_10717<-1955:1964

#10718
pop_10718<-c(652,353,387,464,481,515,626,523,531,694,762,531,821,855,787,889,
             847,761,864,1034,NA,949,957,1017,1094,NA,1076,1042,923,735,649,658,
             700,880,1067,999,1007,1212,1434,1519,1553,1596,1468,1280,1254,1152,1254,1263,
             1237,1220,1237,1075,801)
years_10718<-1950:2002
df_10718<-data.frame(pop_10718, years_10718)

pop_10718_gam<-mgcv:::gam(pop_10718 ~ s(years_10718, k=round(length(years_10718)/2)))
pred_10718<-predict(pop_10718_gam,df_10718,type="response",se=FALSE) 
pop_10718[which(is.na(pop_10718))]<-pred_10718[which(is.na(pop_10718))]


library(filzbach)
library(plotrix)
# transitions says which


pop_id<-pop_10718

transitions=rep(TRUE,length(pop_id))# this says which data point to use for model fitting
#transitions[c(3:5)]=FALSE # set to false years where elephants left KNP because of a drought
loglike_var=function(r,k,mu,sigma){
  res=matrix(nrow=nobs-1)
  prob=matrix(nrow=nobs-1)
  for (te in 2:nobs){
    if (transitions[te-1]){
      res[te-1]=(pop[te]/pop[te-1])-1-(r*(1-pop[te-1]/k))
      prob[te-1]=dnorm(res[te-1],mean=mu,sd=sigma)
      loglike=sum(log(prob),na.rm=TRUE)
    }
  }
  return(loglike)
} 

filz.par_var=list(r=c(-0.05,0.25,0.1,0,-1,1), # 1 st argument lower bound, 2nd upper bound, 3rd best guess. these are the only thing you need to change
                  k=c(300,2400,900,0,-1,1),
                  mu=c(-0.1,0.1,0,0,-1,1),
                  sigma=c(0,0.6,0.2,0,-1,1)) 


pop=pop_id # set training dataset to kruger elephant data in the no-culling period
t=length(pop_id)
nobs=t
No=pop_id[1] # starting population to the first data point
parameters_var=matrix(nrow=0,ncol=4)



# run MonteCarlo Markov Chain parameter optimization with 50,000 it burn-in and 40,000 sampling using the likelihood function
# above and the input parameters in filx.par_var. sample 1 in 10 parameters from posterior distribution
# run the sampler 5 times and rbind it all.
for (i in 1:5){
  parameters_var=rbind(parameters_var,runMCMC(50000,40000,loglike_var,nobs,filz.par_var,thinning=10)) 
}

summary(parameters_var) # growth rate, carrying capacity, mean and std of noise



colMeans(parameters_var)

hist(parameters_var[,1])
hist(parameters_var[,2])
hist(parameters_var[,3])
hist(parameters_var[,4])


quantile(parameters_var[,1],probs=c(0.025,0.5,0.975))


k_539<-parameters_var[,2]
k_10692<-parameters_var[,2]
k_10694<-parameters_var[,2]
k_10695<-parameters_var[,2]
k_10696<-parameters_var[,2]
k_10710<-parameters_var[,2]
k_10713<-parameters_var[,2]
k_10714<-parameters_var[,2]
k_10717<-parameters_var[,2]
k_10718<-parameters_var[,2]


k_539m<-mean(k_539)
k_10692m<-mean(k_10692)
k_10694m<-mean(k_10694)
k_10695m<-mean(k_10695)
k_10696m<-mean(k_10696)
k_10710m<-mean(k_10710)
k_10713m<-mean(k_10713)
k_10714m<-mean(k_10714)
k_10717m<-mean(k_10717)
k_10718m<-mean(k_10718)

ID<-c(539,10692,10694,10695,10696,10710,10713,10714,10717,10718)
ks<-c(k_539m,k_10692m, k_10694m, k_10695m, k_10696m, k_10710m, k_10713m, k_10714m, k_10717m, k_10718m)


dfk<-data.frame(ID, ks)

write.csv(dfk, "carrying_capacity_log_likelihood_capra_ibex.csv")


```

Scaling carrying capacity (as estimated above) in three different ways, linear, sigmoidal and linear threshold.


```{r, cache=TRUE, message=FALSE, warning=FALSE, eval=FALSE}
#plotting functions linking k and hsi

k<-4000 #set to one when using filzbach estimates - otherwise set to a standard value across all pops
lin<-function(x){
  x*k
  }

sig<-function(x){
  k*(1/(1+exp(-10*x+5)))
  }   #could also try with 18x + 9 - closer to SM in Damaris paper

lt<-function(x) { 
  val = (4/3) * x - (1/3)
  val[x < 0.25] = 0 
  val<-val*k
  return(val)
}


#carrying capacity function 

lf<-list.files(paste(wd,"/Alp_SDMs/Ensembles/", sep=""))   

files<-lf[grepl("^weighted_ensemble_sdm_.*.tif$", lf)]

sdms<-stack(paste(wd,"/Alp_SDMs/Ensembles/", files, sep=""))

ks_df<-read.csv("carrying_capacity_log_likelihood_capra_ibex.csv")
ks_df$PatchID<-ks_df$ID*100

#for 1950-2016
#sdms<-sdms[[901:967]]


ks_xy<-merge(Populations, ks_df[,c(2:4)], by="PatchID")


hsi<-extract(sdms, ks_xy[,c(2,3)])


link<-lin(hsi)
links<-link*ks_xy$ks

sigk<-sig(hsi)
sigks<-sigk*ks_xy$ks

ltk<-lt(hsi)
ltks<-ltk*ks_xy$ks

#plot(links[,c(900:967)], type="l")

```

Running the demoniche model - running 9 different models, for each method of scaling carrying capacity I have run demoniche with 3 different dispersal probabilities (0.1, 0.5 and 0.9).
```{r, eval=FALSE, message=FALSE, warning=FALSE}

library(demoniche)
source("demoniche_model_me.R")


foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

k_relationships<-rep(list(links, sigks, ltks), each=3)  #need to change names of folders to match this

foldernames<-c("patch_low_disp" ,"patch_mid_disp" ,"patch_high_disp")

k_relationships<-40000 #need to change names of folders to match this

dispersal_levels<-rep(c(0.001,0.01,0.1, each=1))

for (i in 1:length(foldernames)){

  print(paste("processing of ", foldernames[i]," beginning, ", i, " of ", length(foldernames), sep=""))
  foldername = foldernames[i]
  dispersal = dispersal_levels[i]
  #K = matrix(unlist(k_relationships[i]),nrow=9)
  K = k_relationships
  
  demoniche_setup(modelname = foldername,Populations = Populations, Nichemap =patch_map_mine,
                matrices = matrices, matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = density_individuals,
                fraction_LDD = dispersal, 
                fraction_SDD = dispersal,
                dispersal_constants = c(0.7,0.7,0.1,1),
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=K, Kweight = K_weight, 
                sumweight =sumweight)

patch_run <- demoniche_model_me(modelname = foldernames[i], Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = foldernames[i])
years<-1050:2016
plot(years,patch_run[,"Meanpop","Reference_matrix"], type="l", xlim=c(1949,2016), main=foldernames[i])

}

```


Extracting the predicted alpine ibex population trends for each population from the demoniche output.
```{r, eval=FALSE, message=FALSE, warning=FALSE}

foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

lpi<-read.csv("LPI_pops_20160523_edited.csv")

alpine<-lpi[lpi$ID == 10696 | lpi$ID == 10714 | lpi$ID == 10694 | lpi$ID == 10717 | lpi$ID == 10713 |lpi$ID == 10718 |lpi$ID == 10695 |lpi$ID == 539 |lpi$ID == 10710 ,]

xy<-cbind(alpine$Longitude, alpine$Latitude)

convert_pop_out<-function(foldername){
  
  pop_out<-read.csv(paste(wd, "/", foldername, "/pop_output.csv", sep=""), header = TRUE)
  pop_out<-pop_out[,-1]
  coordinates(pop_out) <- ~ X + Y
  gridded(pop_out) <- TRUE
  rasterDF <- stack(pop_out)
  trends<-extract(rasterDF,xy)
  trends_df<-data.frame(trends)
  write.csv(trends_df, paste(wd, "/", foldername, "/pop_trend_output.csv", sep=""))
}

lapply(foldernames, convert_pop_out)


```


Plots of the real trends vs predicted trends
```{r, message=FALSE, warning=FALSE}
lpi<-read.csv("LPI_pops_20160523_edited.csv")

alpine<-lpi[lpi$ID == 10696 | lpi$ID == 10714 | lpi$ID == 10694 | lpi$ID == 10717 | lpi$ID == 10713 |lpi$ID == 10718 |lpi$ID == 10695 |lpi$ID == 539 |lpi$ID == 10710 ,]

pop<-3
years<-1950:2016

trends<-read.csv(paste(wd, "/patch_link_low_disp/pop_trend_output.csv", sep=""))

#plot(years, trends[pop,901:967], type="l", ylim=c(0,5000), xlim=c(1950,2016))
lpi_pop<-alpine[,c(65:130)]
pop_trends_pred<-data.frame(cbind(Populations$PatchID, trends))

library(reshape)
melt_pop<-melt(pop_trends_pred)

melt_pop<-melt_pop[-c(1:9),]

lpi_pop<-data.frame(cbind(Populations$PatchID, lpi_pop))
lpi_pop$Populations.PatchID<-as.character(lpi_pop$Populations.PatchID)
melt_lpi<-melt(lpi_pop, id.vars = "Populations.PatchID")


melt_pop$ID<-as.factor(lpi_pop$Populations.PatchID)
melt_pop<-melt_pop[-c(1:9),]
melt_pop$Year<-rep(1050:2016 , each=9)

melt_pop_1950<-subset(melt_pop, melt_pop$Year >=1950)

library(ggplot2)
#plot of predicted trends
# ggplot(data = melt_pop_1950, aes(y= value, x= Year, group=ID, col=ID))+
#   geom_line()

col_years<-paste("Year_", 1950:2015, sep="")
colnames(lpi_pop)<-col_years


melt_lpi$Year<-rep(1950:2015 , each=9)
melt_lpi$value<-as.numeric(as.character(melt_lpi$value))

#plot of actual trends
ggplot(data = melt_lpi, aes(y= value, x= Year, group=Populations.PatchID, col=Populations.PatchID))+
  geom_line()

melt_lpi$model_type<-"Real"
melt_lpi$ID<-as.numeric(melt_lpi$Populations.PatchID)/100
melt_lpi<-melt_lpi[-1]

```

```{r, message=FALSE, warning=FALSE}
library(reshape2)
foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

bdf<-data.frame()
for(i in 1:length(foldernames)){
trends<-read.csv(paste(wd, "/",foldernames[i],"/pop_trend_output.csv", sep=""))
trends<-trends[,-1]
m_t<-melt(trends)
m_t$Year<-rep(1050:2016, each=9)
m_t$model_type<-foldernames[i]
m_t$ID<-alpine$ID
bdf<-rbind(bdf,m_t)
#print(i)
}

bdf_lpi<-rbind(bdf,melt_lpi)

pop_pred_539<-bdf_lpi[bdf_lpi$ID == 539 & bdf_lpi$Year >=1950,]
pop_pred_10694<-bdf_lpi[bdf_lpi$ID == 10694 & bdf_lpi$Year >=1950,]
pop_pred_10695<-bdf_lpi[bdf_lpi$ID == 10695 & bdf_lpi$Year >=1950,]
pop_pred_10696<-bdf_lpi[bdf_lpi$ID == 10696 & bdf_lpi$Year >=1950,]
pop_pred_10710<-bdf_lpi[bdf_lpi$ID == 10710 & bdf_lpi$Year >=1950,]
pop_pred_10713<-bdf_lpi[bdf_lpi$ID == 10713 & bdf_lpi$Year >=1950,]
pop_pred_10714<-bdf_lpi[bdf_lpi$ID == 10714 & bdf_lpi$Year >=1950,]
pop_pred_10717<-bdf_lpi[bdf_lpi$ID == 10717 & bdf_lpi$Year >=1950,]
pop_pred_10718<-bdf_lpi[bdf_lpi$ID == 10718 & bdf_lpi$Year >=1950,]

ggplot(pop_pred_539, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 539")
  
ggplot(pop_pred_10694, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10694")
  
ggplot(pop_pred_10695, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10695")
  
ggplot(pop_pred_10696, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10696")
  
ggplot(pop_pred_10710, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10710")
  
ggplot(pop_pred_10713, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10713")
  
ggplot(pop_pred_10714, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10714")
  
ggplot(pop_pred_10717, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10717")
  
ggplot(pop_pred_10718, aes(y=value, x=Year, group=model_type, col=model_type))+
  geom_line()+
  labs(title="Population 10718")
  

```

Comparison of the demoniche models to the lpi correlation models
```{r, message=FALSE, warning=FALSE}
library(lme4)
dt<-read.csv("Mammals_scaled_ready_for_models.csv")

foldernames<-c("patch_link_low_disp" ,"patch_link_mid_disp" ,"patch_link_high_disp","patch_sigk_low_disp" ,"patch_sigk_mid_disp" ,"patch_sigk_high_disp","patch_ltk_low_disp" ,"patch_ltk_mid_disp" ,"patch_ltk_high_disp" )

m0<-lmer(lambda_mean ~ change_rate_scale+mean_slope_scale+change_rate_scale:mean_slope_scale+Bodymass_scale+(1|Binomial)+(1|loc_id),data=dt, REML=F)
m1b<-lmer(lambda_mean ~ change_rate_scale+(1|Binomial)+(1|loc_id),data=dt, REML=F)
m1c<-lmer(lambda_mean ~ mean_slope_scale+(1|Binomial)+(1|loc_id),data=dt)


capra_df<-dt[dt$ID == 10696 | dt$ID == 10714 |dt$ID == 10694 | dt$ID == 10717 | dt$ID == 10713 |dt$ID == 10718 |dt$ID == 10695 |dt$ID == 539 |dt$ID == 10710 ,]


capras<-which(dt$ID == 10696 | dt$ID == 10714 | dt$ID == 10694 | dt$ID == 10717 | dt$ID == 10713 |dt$ID == 10718 |dt$ID == 10695 |dt$ID == 539 |dt$ID == 10710 )


pred<-10^(predict(m0)[capras])
pred_clim<-10^predict(m1c)[capras]   #climate only model
pred_luc<-10^predict(m1b)[capras]   #land use only model
real<-10^capra_df$lambda_mean

dlnl<-read.csv(paste(wd, "/", foldernames[1], "/pop_trend_output.csv", sep=""))  
dlnm<-read.csv(paste(wd, "/", foldernames[2], "/pop_trend_output.csv", sep=""))  
dlnh<-read.csv(paste(wd, "/", foldernames[3], "/pop_trend_output.csv", sep=""))  
dsgl<-read.csv(paste(wd, "/", foldernames[4], "/pop_trend_output.csv", sep=""))  
dsgm<-read.csv(paste(wd, "/", foldernames[5], "/pop_trend_output.csv", sep=""))  
dsgh<-read.csv(paste(wd, "/", foldernames[6], "/pop_trend_output.csv", sep=""))  
dltl<-read.csv(paste(wd, "/", foldernames[7], "/pop_trend_output.csv", sep=""))  
dltm<-read.csv(paste(wd, "/", foldernames[8], "/pop_trend_output.csv", sep=""))  
dlth<-read.csv(paste(wd, "/", foldernames[9], "/pop_trend_output.csv", sep=""))  

demo_link_low<-10^rowMeans(diff(as.matrix(log10(dlnl[,c(900:967)]),nrow=9)))
demo_link_mid<-10^rowMeans(diff(as.matrix(log10(dlnm[,c(900:967)]),nrow=9)))
demo_link_high<-10^rowMeans(diff(as.matrix(log10(dlnh[,c(900:967)]),nrow=9)))
demo_sigk_low<-10^rowMeans(diff(as.matrix(log10(dsgl[,c(900:967)]),nrow=9)))
demo_sigk_mid<-10^rowMeans(diff(as.matrix(log10(dsgm[,c(900:967)]),nrow=9)))
demo_sigk_high<-10^rowMeans(diff(as.matrix(log10(dsgh[,c(900:967)]),nrow=9)))
demo_lt_low<-10^rowMeans(diff(as.matrix(log10(dltl[,c(900:967)]),nrow=9)))
demo_lt_mid<-10^rowMeans(diff(as.matrix(log10(dltm[,c(900:967)]),nrow=9)))
demo_lt_high<-10^rowMeans(diff(as.matrix(log10(dlth[,c(900:967)]),nrow=9)))

lambda_preds<-cbind(real,pred, pred_clim,pred_luc,  demo_link_low, demo_link_mid,demo_link_high,demo_sigk_low, demo_sigk_mid, demo_sigk_high,demo_lt_low,demo_lt_mid,demo_lt_high)


#pairs(lambda_preds)

```

Comparison of model predictions with the real values

```{r}
par(mfrow=c(3,4))

for (i in 2:ncol(lambda_preds-1)){
  plot(lambda_preds[,1], lambda_preds[,i], main=colnames(lambda_preds)[i], ylab=colnames(lambda_preds)[i], xlab=colnames(lambda_preds)[1])
 #print(i) 
}


```


```{r, eval=FALSE, echo=FALSE, warning=FALSE}

patch_run_dz <- demoniche_model_VE(modelname = "Capra_ibex_patch", Niche = TRUE, 
                                     Dispersal = T, repetitions = 1,
                                     foldername = "damaris_function")

patch_run_dz[,"Meanpop","Reference_matrix"]

years<-1050:2016
#plot(RPyran_disp_niche[,"Meanpop","Reference_matrix"])
bleh<-(patch_run[,"Meanpop","Reference_matrix"])

plot(years, bleh, type="l", xlim=c(1950,2016))

```

#Varying the carrying capacity - 16000, 4000, 2000, 1000

<<<<<<< HEAD

```{r,cache=TRUE, echo=FALSE, warning=FALSE}
=======
```{r, eval=TRUE,  warning=FALSE}
>>>>>>> 8163f91484a294c85a951acc31986578905e4502

demoniche_setup(modelname = "Capra_k_16000",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_4000",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=4000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_2000",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=2000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_k_1000",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(0.7,0.7,0.1,2),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=1000, Kweight = K_weight, 
                sumweight =sumweight)

c_ibex_k_16000 <- demoniche_model(modelname = "Capra_k_16000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


c_ibex_k_4000 <- demoniche_model(modelname = "Capra_k_4000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

c_ibex_k_2000 <- demoniche_model(modelname = "Capra_k_2000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

c_ibex_k_1000 <- demoniche_model(modelname = "Capra_k_1000", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

plot(c_ibex_k_4000[,"Meanpop","Reference_matrix"], type="l")
lines(c_ibex_k_2000[,"Meanpop","Reference_matrix"])

p_16000<-(c_ibex_k_16000[,"Meanpop","Reference_matrix"])
p_4000<-(c_ibex_k_4000[,"Meanpop","Reference_matrix"])
p_2000<-(c_ibex_k_2000[,"Meanpop","Reference_matrix"])
p_1000<-(c_ibex_k_1000[,"Meanpop","Reference_matrix"])

plot(p_16000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", ylim=c(0,4700000))
lines(p_4000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="",col="green")
lines(p_2000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="red")
lines(p_1000[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="blue")

10^mean(diff(log10(p_16000[900:967])))
10^mean(diff(log10(p_4000[900:967])))
10^mean(diff(log10(p_2000[900:967])))
10^mean(diff(log10(p_1000[900:967])))

```

#Changing the shape of the dispersal kernel

<<<<<<< HEAD
```{r,cache=TRUE, echo=FALSE, warning=FALSE, "Dispersal Kernel"}
=======
```{r, eval=TRUE,  warning=FALSE, "Dispersal Kernel"}
>>>>>>> 8163f91484a294c85a951acc31986578905e4502

demoniche_setup(modelname = "Capra_disp_5",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(1,1,1,5),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_disp_1",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(1,1,1,1),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight,
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_disp_1_lt",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(1,1,0.1,1),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight,
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_disp_1_st",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(1,0.1,1,1),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight,
                sumweight =sumweight)


c_ibex_disp_5 <- demoniche_model(modelname = "Capra_disp_5", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


c_ibex_disp_1 <- demoniche_model(modelname = "Capra_disp_1", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


c_ibex_disp_1_lt <- demoniche_model(modelname = "Capra_disp_1_lt", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

c_ibex_disp_1_st <- demoniche_model(modelname = "Capra_disp_1_st", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


p_d_5<-(c_ibex_disp_5[,"Meanpop","Reference_matrix"])
p_d_1<-(c_ibex_disp_1[,"Meanpop","Reference_matrix"])
p_d_1_lt<-(c_ibex_disp_1_lt[,"Meanpop","Reference_matrix"])
p_d_1_st<-(c_ibex_disp_1_st[,"Meanpop","Reference_matrix"])

plot(p_d_5[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", ylim=c(0,5000000))
lines(p_d_1[900:967], type="l", ylab="Number of Alpine Ibex", xlab="",col="green")
lines(p_d_1_lt[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="red")
lines(p_d_1_st[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="blue")

10^mean(diff(log10(p_d_5[900:967])))
10^mean(diff(log10(p_d_1[900:967])))
10^mean(diff(log10(p_d_1_lt[900:967])))
10^mean(diff(log10(p_d_1_st[900:967])))

```

<<<<<<< HEAD
```{r, cache=TRUE, echo=FALSE, warning=FALSE, "Dispersal Proportion"}
=======
#Changing the proportion dispersed


```{r, eval=TRUE,  warning=FALSE, "Dispersal Proportion"}
>>>>>>> 8163f91484a294c85a951acc31986578905e4502

demoniche_setup(modelname = "Capra_disp_lsll",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.1,
                dispersal_constants = c(1,1,1,5),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight, 
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_disp_hsll",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.1, fraction_SDD = 0.9,
                dispersal_constants = c(1,1,1,5),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight,
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_disp_lshl",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.9, fraction_SDD = 0.1,
                dispersal_constants = c(1,1,1,5),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight,
                sumweight =sumweight)

demoniche_setup(modelname = "Capra_disp_hshl",Populations = Populations, Nichemap = patch_map_mine,
              matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                stages = stages, proportion_initial = proportion_initial,
                density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                fraction_LDD = 0.9, fraction_SDD = 0.9,
                dispersal_constants = c(1,1,1,5),
                transition_affected_niche = "all",
                transition_affected_demogr = transition_affected_demogr,
                transition_affected_env=transition_affected_env,
                env_stochas_type = env_stochas_type,
                no_yrs = no_yrs_mine, K=16000, Kweight = K_weight,
                sumweight =sumweight)


c_ibex_disp_lsll <- demoniche_model(modelname = "Capra_disp_lsll", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


c_ibex_disp_hsll <- demoniche_model(modelname = "Capra_disp_hsll", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


c_ibex_disp_lshl <- demoniche_model(modelname = "Capra_disp_lshl", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")

c_ibex_disp_hshl <- demoniche_model(modelname = "Capra_disp_hshl", Niche = TRUE, 
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = "non_damaris_function")


p_d_lsll<-(c_ibex_disp_lsll[,"Meanpop","Reference_matrix"])
p_d_hsll<-(c_ibex_disp_hsll[,"Meanpop","Reference_matrix"])
p_d_lshl<-(c_ibex_disp_lshl[,"Meanpop","Reference_matrix"])
p_d_hshl<-(c_ibex_disp_hshl[,"Meanpop","Reference_matrix"])

plot(p_d_lsll[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", ylim=c(0,12000000))
lines(p_d_hsll[900:967], type="l", ylab="Number of Alpine Ibex", xlab="",col="green")
lines(p_d_lshl[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="red")
lines(p_d_hshl[900:967], type="l", ylab="Number of Alpine Ibex", xlab="", col="blue")

10^mean(diff(log10(p_d_lsll[900:967])))
10^mean(diff(log10(p_d_hsll[900:967])))
10^mean(diff(log10(p_d_lshl[900:967])))
10^mean(diff(log10(p_d_hshl[900:967])))

```

```{r, eval=FALSE, echo=FALSE}
# RPyran_disp_niche_scale <- demoniche_model(modelname = "Capra_ibex_scale", Niche = TRUE, 
#                                      Dispersal = TRUE, repetitions = 1,
#                                      foldername = "RPyran_disp_niche")



years<-1950:2016
years<-1050:2016
#plot(RPyran_disp_niche[,"Meanpop","Reference_matrix"])
bleh<-(RPyran_disp_niche_scale[,"Meanpop","Reference_matrix"])
link_years<-(RPyran_disp_niche_scale_lk[,"Meanpop","Reference_matrix"])
lk_years<-(RPyran_disp_niche_scale_link[,"Meanpop","Reference_matrix"])
#plot(years, bleh, type="l", ylab="Number of Alpine Ibex")


plot(years[900:967], bleh[900:967], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="")
lines(years[900:967], lk_years[900:967], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="", col="red")
lines(years[900:967], link_years[900:967], type="l", ylab="Number of Alpine Ibex", ylim=c(0,1100000), xlim=c(1950,2016), xlab="", col="green")


mean(diff(log10(bleh[900:967])), type="l")
mean(diff(log10(lk_years[900:967])), type="l")
mean(diff(log10(link_years[900:967])), type="l")

```

```{r, eval=FALSE, echo=FALSE, warning=FALSE}

spin_up<-1050:1949
year0<-paste(wd, "/Alp_SDMs/Ensembles/pres_abs_true_skill_stat_weighted_ensemble_sdm_1950.tif", sep="")

spin_up_files<-paste(wd, "/Alp_SDMs/Ensembles/pres_abs_true_skill_stat_weighted_ensemble_sdm_", spin_up,".tif", sep="")


file.copy(year0, spin_up_files)



```

