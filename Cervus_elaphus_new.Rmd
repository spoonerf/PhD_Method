---
title: "Cervus_elaphus"
author: "Fiona Spooner"
date: "September 6, 2017"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
---

```{r Install packages, eval=FALSE, message=FALSE}
install.packages('climates',,'http://www.rforge.net/')
install.packages("dismo")
install.packages("maps")
install.packages("mapdata")
install.packages("popbio")
install.packages("demoniche", repos="http://R-Forge.R-project.org")

```

```{r Loading libraries, cache=TRUE, message= FALSE, warning=FALSE}
library(dismo)
library(demoniche)
library(maps)
library(mapdata)
library(rgeos)
library(zoo)
library(raster)
library(mgcv)
library(randomForest)
library(rgdal)
library(doParallel)
library(ggplot2)
library(dplyr)
library(data.table)
library(reshape2)
library(taRifx)
library(plyr)
library(sp)

```


```{r Constants - change for each species, message= FALSE, warning = FALSE}

wd<-getwd()
genus<-"Cervus"
species<-"elaphus"
Europe_only<-TRUE
binomial<-paste(genus, species, sep="_")
min_lat<- 35    #one degree more/less than the iucn range extent
max_lat<- 68
min_lon<- -11
max_lon<- 33
bioclim_layers<-c(2,4,5,6,7,10,11)   
no_background_points<-1000
bioclim_names<-c("Bio_2_2006_2016_average", "Bio_4_2006_2016_average","Bio_5_2006_2016_average","Bio_6_2006_2016_average","Bio_7_2006_2016_average","Bio_10_2006_2016_average","Bio_11_2006_2016_average")


#Comadre
transition_affected_niche<-"all"  #which parts of the matrix are affected by the c(1,2) is juveniles
#niche values
transition_affected_env <- "all"
transition_affected_demogr <- "all"

sd_seq<-0.5
LDD_seq<-c(0.1)
kern_seq<-list(c(49.7,284.2),c(13.7, 89.4), c(1000,1000))   #first values is median derived from median home range and second value is maximum dispersal distance

var_grid<-expand.grid(sd_seq, LDD_seq, kern_seq)
colnames(var_grid)<-c("SD", "LDD", "Kern")

kern_mat<-matrix(c(rep(c(49.7,284.2), (nrow(var_grid)/ncol(var_grid))),rep(c(13.7,89.4), (nrow(var_grid)/ncol(var_grid))),rep(c(1000,1000),(nrow(var_grid)/ncol(var_grid)))), ncol=2, byrow=T)

density_mine<- 1564  
carry_k<-1617

# density_mine<- 3000  
# carry_k<-3000



fraction_SDD<-0.25
fraction_LDD<-0.15
reps<-12

```

```{r, Same for all species}
binomial<-paste(genus, species, sep="_")

k<-4
years<-1950:2016
spin_years<-1850:1949
lpi<-read.csv("LPI_pops_20160523_edited.csv")
species_directory<-paste(wd, binomial, sep="/")
dir.create(species_directory)
sdm_folder<-paste(species_directory, "SDM_folder", sep = "/")
dir.create(sdm_folder)
demoniche_folder<-paste(species_directory, "Demoniche_Output", sep = "/")
dir.create(demoniche_folder)

source("demoniche_setup_me.R")
source("demoniche_model_me.R")
source("ensemble_evaluate.R")

no_yrs_mine<-1 
prob_scenario<-c(0.5,0.5)    #need to check this
noise<-0.90 

env_stochas_type<-"normal"   #can also be lognormal
```


####Species distribution modelling with dismo

Extracting Alpine ibex (*Capra ibex*) data from GBIF and with additional locations added from the LPI dataset. These points are then formatted to a SpatialPointsDataFrame.

```{r Downloading and filtering gbif data, cache=TRUE, message= FALSE, warning=FALSE, eval=FALSE}

wd<- getwd()
capra <-gbif(genus =genus, species = species)
capgeo <- subset(capra, !is.na(lon) & !is.na(lat) & (lon!="NA" & lat !="NA") | year!="NA")
dups <- duplicated(capgeo[, c("lon", "lat")])
capg <-capgeo[!dups, ]
capg2 <- capg[capg$lon > min_lon & capg$lon< max_lon & capg$lat > min_lat & capg$lat < max_lat & capg$year>=2006 & capg$coordinateUncertaintyInMeters <1000, ]
capg2<-data.frame(capg2$lon,capg2$lat)
colnames(capg2)<-c("Longitude", "Latitude")

pyr<-subset(lpi, Binomial == binomial & Specific_location==1 )  #10716 v.near two other populations  #record 11470 had wrong longitude - in Russia!
pyrs<-pyr[,c("Longitude","Latitude")]
capg2<-rbind(capg2, pyrs)
capg2<-na.omit(capg2)
capg2$presence<-rep(1)
capg2$ID<-1:nrow(capg2)

capc<-as.matrix(capg2[ , c( "Longitude","Latitude", "presence")])
capc<-matrix(capc[complete.cases(capc)], ncol=3)
xy<-as.matrix(capc[,c(1,2)])
df<-data.frame(capc[,3])

write.csv(df, paste(species_directory,"/", binomial,"_gbif.csv", sep=""), row.names = FALSE)
write.csv(xy, paste(species_directory,"/",binomial, "_locs.csv", sep=""), row.names=FALSE)
```

```{r Plotting occurrence points, message=FALSE, warning=FALSE}
library(sp)
library(raster)

df<-read.csv(paste(species_directory, "/",binomial, "_gbif.csv", sep="") )
xy<-read.csv(paste(species_directory,"/" ,binomial, "_locs.csv", sep=""))

sp<-sp:::SpatialPointsDataFrame(coords=xy, data=df)
sp<-sp[sp@coords[,1] > min_lon & sp@coords[,1]< max_lon &sp@coords[,2] >min_lat & sp@coords[,2] <max_lat,]

e<-raster:::extent(sp)

e_big<-e+2

maps:::map('world',  col="light grey", fill=T, xlim=c(e_big[1],e_big[2]), ylim=c(e_big[3],e_big[4]))

points(sp, col="red", pch=20)

```

```{r Creating 2006-2016 bioclim average,cache=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

if (Europe_only){
lf<-list.files(paste(wd, "/Bioclim/", sep=""))
} else{
lf<-list.files(paste(wd, "/Bioclim/Global", sep=""))
}

first<-which(grepl("2006_bioclim", lf)) #was initially 1985
last<-which(grepl("2016_bioclim", lf))

if (Europe_only){
all_years<-stack(paste(wd, "/Bioclim/",lf[first:last], sep=""))
} else{
all_years<-stack(paste(wd, "/Bioclim/Global/",lf[first:last], sep=""))
}

bios<-seq(1,nlayers(all_years), by=19)
cellStats(all_years[[bios]], stat="mean")
#creating a 1985-2016 average of each bioclim variable
for (i in 1:19){
  layers<-bios
  bio_layer<-mean(all_years[[layers]])
  if (Europe_only){
  writeRaster(bio_layer, paste(wd, "/Bioclim/Bio_",i,"_2006_2016_average.tif",sep=""), overwrite=TRUE)
  } else {
  writeRaster(bio_layer, paste(wd, "/Bioclim/Global/Bio_",i,"_2006_2016_average.tif",sep=""), overwrite=TRUE)
  }
  bios<-bios+1
  #print(layers)
}

#pred_nf<-stack(paste(wd, "/Bioclim/Bio_", bio_layer_pred,"_1985_2016_average.tif",sep="" ))
```

Selecting out the bioclim layers I'm interested in:

```{r Stacking bioclim layers}

if (Europe_only){
pred_nf<-stack(paste(wd, "/Bioclim/Bio_", bioclim_layers,"_2006_2016_average.tif",sep="" ))
} else {
pred_nf<-stack(paste(wd, "/Bioclim/Global/Bio_", bioclim_layers,"_2006_2016_average.tif",sep="" ))
}

pred_crop<-crop(pred_nf, e_big)
plot(pred_crop)

```


####Creating the testing and training datasets

Using K=4 so 75% of points are used for training and 25% for testing.

```{r Presence Data, message=FALSE, warning=FALSE}
library(dismo)

set.seed(10)

group_pres<-kfold(sp, k)
#write.csv(group_pres, paste(species_directory, "k_folds_presence_2006.csv", sep="/"))
group_pres<-read.csv(paste(species_directory, "k_folds_presence_2006.csv", sep="/"))
group_pres<-group_pres[,-1]  #all presence points

sp_train<-sp[group_pres!=1,] #presence points split into training and test
sp_test<-sp[group_pres ==1,]
```


```{r Background/Pseudo-absence data, cache=TRUE, message=FALSE, warning=FALSE}
bg_sam<- randomPoints(pred_crop[[1]], no_background_points )

#write.csv(bg_sam, paste(species_directory, "background_random_points2.csv", sep="/"))
bg_pse<-read.csv(paste(species_directory, "background_random_points2.csv", sep="/"))
bg_pse<-bg_pse[,-1]

group_back<-kfold(bg_pse, k)
#write.csv(group_back, paste(species_directory, "k_folds_background2.csv", sep="/"))
group_back<-read.csv(paste(species_directory, "k_folds_background2.csv", sep="/"))
group_back<-group_back[,-1]

```

```{r Testing and training data}
sp_backg_train <- bg_pse[group_back != 1, ] #background points split into training and test
sp_backg_test <- bg_pse[group_back == 1, ]
colnames(sp_backg_train)<-c("lon", "lat")
colnames(sp_backg_test)<-c("lon", "lat")

sp_train<-sp_train@coords #presence training points
colnames(sp_train)<-c("lon", "lat")
train <- rbind(sp_train, sp_backg_train)  #presence and background training points combined

sp_test<-sp_test@coords #presence test points
colnames(sp_test)<-c("lon", "lat")
test<-rbind(sp_test, sp_backg_test)    #presence and background test points combined

pb_train <- c(rep(1, nrow(sp_train)), rep(0, nrow(sp_backg_train)))
envtrain <- extract(pred_nf, train)
envtrain <- data.frame( cbind(pa=pb_train, envtrain) ) #training points with environmental  variables

envtrain<-na.omit(envtrain)

pb_test<-c(rep(1, nrow(sp_test)), rep(0, nrow(sp_backg_test)))
envtest <- extract(pred_nf, test)
envtest <- data.frame( cbind(pa=pb_test, envtest) ) #test points with environmental  variables
envtest<-na.omit(envtest)

env_all<-rbind(envtrain, envtest) #all of the training and test data with environmental variables

env_pres<-extract(pred_nf, sp)
pa<-rep(1, nrow(env_pres))
env_pres<-data.frame(pa, env_pres)  #presence points with environmental variables
colnames(env_pres)<-c("pa", bioclim_names)
env_pres_xy<-data.frame(sp@coords, env_pres)
env_pres_xy<-na.omit(env_pres_xy)

env_back<-extract(pred_nf, bg_pse)
ap<-rep(0, nrow(env_back))
env_back<-data.frame(ap, env_back) #background points with environmental variables
colnames(env_back)<-c("pa",bioclim_names)
env_back_xy<-data.frame(bg_pse, env_back)
env_back_xy<-na.omit(env_back_xy)

group_pres<-group_pres[1:nrow(env_pres_xy)]
group_back<-group_back[1:nrow(env_back_xy)]

```

####Bioclim

Running the Bioclim envelope model and evaluating it using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r Bioclim model, cache=TRUE, message=FALSE, warning=FALSE}

evl_bc<- list()
tss_bc<-list()
for (i in 1:k){
  pres_train<-sp[group_pres!=i,]
  pres_test<-sp[group_pres==i,]
  backg_test<-bg_pse[group_back==i,]
  bc <- bioclim(pred_nf,pres_train)
  evl_bc[[i]] <- dismo:::evaluate(pres_test, backg_test, bc,pred_nf,type="response")#test presence, test absence, model, predictor variables
     #print(i)
}

auc_bc <- sapply( evl_bc, function(x){slot(x, "auc")} )
print(auc_bc)
bc_auc<-mean(auc_bc)

```

####GAM

Running a GAM and evaluating it to get an AUC value using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r GAM, cache= TRUE, message=FALSE, warning=FALSE}
#library(mgcv)

evl_gam<- list()
tss_gam<-list()
for (i in 1:k){
  pres_train<-env_pres_xy[group_pres!=i ,-c(1,2)]
  pres_test<-env_pres_xy[(group_pres==i) ,-c(1,2)]
  back_test<-env_back_xy[(group_back==i),-c(1,2)]
  back_train<-env_back_xy[(group_back!=i),-c(1,2)]
  envtrain<-rbind(pres_train, back_train)
  gm1<-gam(pa~ s(Bio_2_2006_2016_average)+s(Bio_4_2006_2016_average)+ s(Bio_5_2006_2016_average)+ 
           s(Bio_6_2006_2016_average)+ s(Bio_7_2006_2016_average)+ s(Bio_10_2006_2016_average)+ 
           s(Bio_11_2006_2016_average), family = binomial(link = "logit"),data=envtrain)


  evl_gam[[i]] <- dismo:::evaluate(p = pres_test, a = back_test,model= gm1,type="response")
    }

auc_gam <- sapply( evl_gam, function(x){slot(x, "auc")} )
print(auc_gam)

gam_auc<-mean(auc_gam)

```

####Random Forest

Running a random forest model and evaluating it using three different thresholds (kappa, no omission and true skill statistic) to get AUC values.

```{r Random forest model , cache= TRUE, message= FALSE, warning=FALSE}



model<-pa~  Bio_2_2006_2016_average+Bio_4_2006_2016_average+ 
  Bio_5_2006_2016_average+ Bio_6_2006_2016_average+ Bio_7_2006_2016_average+ 
  Bio_10_2006_2016_average+ Bio_11_2006_2016_average


evl_rf<- list()
for (i in 1:k){
  pres_train<-env_pres_xy[group_pres!=i,-c(1,2)]
  pres_test<-env_pres_xy[(group_pres==i) ,-c(1,2)]
  back_test<-env_back_xy[(group_back==i),-c(1,2)]
  back_train<-env_back_xy[group_back !=i,-c(1,2)]
  envtrain<-rbind(pres_train, back_train)
  rf1 <- randomForest(model, data=envtrain)
  evl_rf[[i]] <- dismo:::evaluate(pres_test, back_test, rf1,type="response")
  }

auc_rf <- sapply( evl_rf, function(x){slot(x, "auc")} )
print(auc_rf)

rf_auc<-mean(auc_rf)

```


#### Ensemble Model

Creating a weighted (based on AUC) ensemble average suitability model for 2006-2016 from the Bioclim, GAM and Random Forest models. This will be used to predict habitat suitability for Alpine ibex for each year 1950-2016.


```{r Weighted ensemble one, cache=TRUE, warning=FALSE, message=FALSE}
#total models
library(randomForest)
bc <- bioclim(pred_nf, sp)
gm1<-gam(pa~ s(Bio_2_2006_2016_average)+s(Bio_4_2006_2016_average)+ s(Bio_5_2006_2016_average)+ 
           s(Bio_6_2006_2016_average)+ s(Bio_7_2006_2016_average)+ s(Bio_10_2006_2016_average)+ 
           s(Bio_11_2006_2016_average), family = binomial(link = "logit"),data=env_all)
rf1 <- randomForest(model, data=env_all)

pb <- predict(pred_nf, bc, ext=e_big, progress='') #bioclim predict
pg <- predict(pred_nf, gm1, ext=e_big) #gam predict
pgl<-raster:::calc(pg, fun=function(x){ exp(x)/(1+exp(x))}) #backtransforming from logit space
pr <- predict(pred_nf, rf1, ext=e_big) #random forest predict

models <- stack(pb, pgl, pr)
names(models) <- c("bioclim", "gam", "random forest")
plot(models)

auc<-c(bc_auc, gam_auc, rf_auc)
w <- (auc-0.5)^2
wm <- weighted.mean( models[[c("bioclim", "gam", "random.forest")]], w)
plot(wm, main="Ensemble model")
points(sp)

```


####Weighted Threshold

```{r Weighted threshold}

abs_xy<-env_back_xy[,c(1,2)]

ens<-ensemble_evaluate(sp,abs_xy , wm)
thresh<-threshold(ens, stat="spec_sens")

thresh
```


####Annual Habitat Suitability Predictions

Using the ensemble model to predict suitability for each year - 1950-2016 and for each year creating a binary presence/absence map based on a three different thresholding techniques. I will go forward using true skill statistic based on Allouche 2006.

```{r Historical predictions, cache=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

bc <- bioclim(pred_nf, sp)
gm1<-mgcv:::gam(pa~ s(Bio_2_2006_2016_average)+ s(Bio_4_2006_2016_average)+ s(Bio_5_2006_2016_average)+ s(Bio_6_2006_2016_average)+ s(Bio_7_2006_2016_average)+s(Bio_10_2006_2016_average)+ s(Bio_11_2006_2016_average), data=env_all)
rf1 <- randomForest:::randomForest(model, data=env_all)

for (i in 1:length(years)){

  pred_nf<-stack(paste(wd, "/Bioclim/", years[i], "_bioclim_variable_stack.tif", sep="" ))
  pred_nf<-pred_nf[[bioclim_layers]]
  names(pred_nf)<-bioclim_names

  pb <- predict(pred_nf, bc, ext=e_big, progress='')
  pg <- predict(pred_nf, gm1, ext=e_big) #gam predict
  pgl<-raster:::calc(pg, fun=function(x){ exp(x)/(1+exp(x))})
  pr <- predict(pred_nf, rf1, ext=e_big)

  models <- stack(pb, pgl, pr)
  names(models) <- c("bioclim", "gam", "random forest")
  wm <- weighted.mean( models[[c("bioclim", "gam", "random.forest")]], w)

  pa_sss<-wm>thresh

 writeRaster(wm , paste(sdm_folder, "/weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)
 writeRaster(pa_sss , paste(sdm_folder, "/pres_abs_sss_weighted_ensemble_sdm_", years[i], ".tif", sep=""), overwrite=TRUE)

  plot(pa_sss, main=years[i])
}

```

####Trends in habitat suitability 1950-2016

```{r}

t<-stack(paste(sdm_folder, "/weighted_ensemble_sdm_", years,".tif", sep=""))
s<-round(seq(1,nlayers(t),len=16))

plot(t[[s]])

patch<-stack(paste(sdm_folder, "/pres_abs_sss_weighted_ensemble_sdm_", years,".tif", sep=""))
plot(patch[[s]])
#patch<-projectRaster(patch, crs = "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs")


m<-cellStats(t, stat="mean")
sd<-cellStats(t, stat="sd")

plot(years,m, type="l", main="Average habitat suitability over time", ylim=c(0,(max(m)+(2*max(sd)))), ylab="Suitability index", xlab="Years")
lines(years, m+(2*sd), col="red", lty=3)
lines(years, m-(2*sd), col="red", lty=3)


```

####Patches

Plots of the number of cells with predicted presence and number of patches (contiguous presence) over 1950-2016.

```{r, warning=FALSE, echo=FALSE, eval=FALSE}
year_patch<-data.frame(years = years, patch_num = numeric(length(years)) )

for (i in 1:length(years)){
c<-clump(patch[[i]])
year_patch[i,2]<-max(na.omit(values(c)))
#print(i)
}
par(mar=c(4,4,4,5))

mk<-cellStats(patch, stat="sum")
plot(years,mk, type="l", main="Predicted patch presence", ylab="Suitable squares", xlab="Years", col="red")
par(new=TRUE)
par(mar=c(4,4,4,5))
plot(year_patch$years, year_patch$patch_num,type="l",col="blue",xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("Number of Patches",side=4,line=3)
legend("topright",col=c("red","blue"),lty=1,legend=c("Suitable Squares","Number of Patches"))

```



## Demoniche

####Formatting the population occurrence points

Formatting the LPI population data for use in Demoniche, they start as the "seed" populations. Might be better to use GBIF data for this - unrealistic that the LPI populations are the only existing populations in 1950 - alternatively a historical map of where the ibex were in 1950?

```{r, warning=FALSE, message=FALSE}

pyr<-subset(lpi, Binomial ==binomial & Specific_location==1)    #record 11470 had wrong longitude - in Russia!

spr<-rasterize(sp,sdm)
spr<-spr[[2]]

p <- rasterToPoints(spr, function(x) x == 1)
p<-cbind(1,p)
pyr<-data.frame(p)



colnames(pyr)<-c("ID","Longitude","Latitude", "blah") #new add
#formatting the data for use in demoniche
pyrs<-pyr[,c("ID","Longitude","Latitude")]
#pyrs$ID<-pyrs$ID * 100 
pyrs$ID<-(pyrs$ID * 100000) + as.numeric(row.names(pyr))
xy<-data.frame(pyrs$Longitude, pyrs$Latitude)
coordinates(xy)<-c("pyrs.Longitude", "pyrs.Latitude")
proj4string(xy) <- CRS("+init=epsg:4326") # WGS 84
#CRS.new <- CRS("+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs")
#xy <- spTransform(xy, CRS.new)
xy<-data.frame(xy)
Populations<-data.frame(pyrs$ID, xy$pyrs.Longitude, xy$pyrs.Latitude)
colnames(Populations)<-c("PatchID", "X", "Y")
Populations$area<-1

first_year<-function(x){
  pop_first<-min(which(!is.na(x)))
  pop_value<-x[pop_first]
  return(pop_value)
}
pop_values<-apply(pop_years, 1, first_year)

density_mine<-as.numeric(pop_values)


id<-pyrs$ID*100
lam<-rep(1,length(id))    #not sure what the value here pertains to - think it sets starting population so should use values from LPI?
pyrxy<-SpatialPoints(pyr[,c("Longitude","Latitude")])
wd<-getwd()
sdm<-raster(paste(sdm_folder, "/pres_abs_sss_weighted_ensemble_sdm_1950.tif", sep=""))
e2<-extent(sdm)
r<-raster(e2, resolution=res(sdm))
rz<-rasterize(pyrxy,r,lam )
crs(rz)<-"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
rid<-rasterize(pyrxy,r,id)
crs(rid)<-"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
rz_spdf<-xyFromCell(rz, 1:ncell(rid))
rzm<-as.vector(rz)
ridm<-as.vector(rid)
df<-data.frame(ridm,rz_spdf,rzm)
colnames(df)<-c( "PatchID","X","Y","area")
#df<-data.frame(na.omit(df))
#Populations<-data.frame(na.omit(df))







```

####Formatting the habitat suitability models

Formatting the habitat suitability model maps into vectors for use in Demoniche and plotting the average habitat suitability over time.
Here we also create a fake set of habitat suitability models where the suitability is driven down at a constant rate over time.

```{r, cache=TRUE, message=FALSE, warning=FALSE}
patch<-raster(paste(sdm_folder,"/pres_abs_sss_weighted_ensemble_sdm_", years[1],".tif", sep=""))

sdm_patch_df<-data.frame(ID=1:ncell(patch))
sdm_df<-data.frame(ID=1:ncell(patch))



#formatting data for demoniche
for (i in 1:length(years)){
  sdm<-raster(paste(sdm_folder,"/weighted_ensemble_sdm_", years[i],".tif", sep=""))   #14.6
  patch<-raster(paste(sdm_folder,"/pres_abs_sss_weighted_ensemble_sdm_", years[i],".tif", sep=""))

  sdm<-crop(sdm, e_pop)
  patch<-crop(patch, e_pop)
  if (i ==1){
    vec<-as.data.frame(sdm, xy = TRUE)
    vec_pat<-as.data.frame(patch, xy=TRUE)
  } else{
    vec<-as.data.frame(sdm)
    vec_pat<-as.data.frame(patch)
  }

  sdm_df<-cbind(sdm_df, vec)
  sdm_patch_df<-cbind(sdm_patch_df,vec_pat)
}

sdm_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]
sdm_patch_df$ID[which(!is.na(df$PatchID))]<-df$PatchID[!is.na(df$PatchID)]

niche_map_mine<-sdm_df
colnames(niche_map_mine)[1:3]<-c("gridID", "X", "Y")

patch_map_mine<-sdm_patch_df
colnames(patch_map_mine)[1:3]<-c("gridID", "X", "Y")


niche_spin_up<-matrix(rep(niche_map_mine[,4], length(spin_years)), nrow=nrow(niche_map_mine))
niche_spin_up<-cbind(niche_map_mine[,1:3],niche_spin_up, niche_map_mine[,4:ncol(niche_map_mine)])


patch_spin_up<-matrix(rep(patch_map_mine[,4], length(spin_years)), nrow=nrow(patch_map_mine))
patch_spin_up<-cbind(patch_map_mine[,1:3],patch_spin_up, patch_map_mine[,4:ncol(patch_map_mine)]) #last patch used to be niche


niche_spin_up<-matrix(rep(niche_map_mine[,4], length(spin_years)), nrow=nrow(niche_map_mine))
niche_spin_up<-cbind(niche_map_mine[,1:3],niche_spin_up, niche_map_mine[,4:ncol(niche_map_mine)])

#test#
opt_patch_map_mine[!is.na(patch_map_mine[,4]),4]<-1
#
opt_patch_spin_up<-matrix(rep(patch_map_mine[,4], length(spin_years)), nrow=nrow(opt_patch_map_mine))
opt_patch_spin_up<-cbind(opt_patch_map_mine[,1:3],opt_patch_spin_up, opt_patch_map_mine[,4:ncol(opt_patch_map_mine)]) #last patch used to be niche


col_years_short<-paste("Year_", years, sep="")
col_years<-paste("Year_", min(spin_years):max(years), sep="")

colnames(niche_map_mine)[4:length(colnames(niche_map_mine))]<-col_years_short
colnames(patch_map_mine)[4:length(colnames(patch_map_mine))]<-col_years_short


colnames(niche_spin_up)[4:length(colnames(niche_spin_up))]<-col_years
colnames(patch_spin_up)[4:length(colnames(patch_spin_up))]<-col_years



# niche_map_mine<-na.omit(niche_map_mine)
# patch_map_mine<-na.omit(patch_map_mine)
# #fake_map_mine<-na.omit(fake_map_mine)
# 
# niche_spin_up<-na.omit(niche_spin_up)
# patch_spin_up<-na.omit(patch_spin_up)
#fake_spin_up<-na.omit(fake_spin_up)

plot(years,colMeans(na.omit(niche_map_mine)[4:length(colnames(niche_map_mine))]), type="l", ylab="Mean suitability index")

patch_map_mine[is.na(patch_map_mine)]<-0


niche_spin_up[is.na(niche_spin_up)]<-0
patch_spin_up[is.na(patch_spin_up)]<-0
```

####COMADRE

Accessing the population matrices from COMADRE - there are 5 matrices available for the alpine ibex but four are for the same area and only represent survival over two time periods in good/bad conditions.

<span style="color:red">Could I use these to calibrate the survival aspect of the matrices?</span>


```{r, warning=FALSE, message=FALSE}

load(paste(wd, "COMADRE_v.2.0.1.RData", sep="/"))

tempMetadata<-subset(comadre$metadata, SpeciesAccepted==binomial)

keep<-as.numeric(rownames(tempMetadata))

tempMat<-comadre$mat[keep]   #MatA is matrix pop model, can be split into U, F and/or C

MatList<-list(tempMat[[2]][[1]])  #varies depending on number of matrices - need to find a way to code this better - now have five matrices available so need to sort this
AllMat<-unlist(MatList)
matrices<-matrix(AllMat, ncol=length(MatList))
colnames(matrices)<- c("Reference_matrix")


MatListA<-list(tempMat[[3]][[1]])  #varies depending on number of matrices - need to find a way to code this better - now have five matrices available so need to sort this
AllMatA<-unlist(MatListA)
matricesA<-matrix(AllMatA, ncol=length(MatListA))
colnames(matricesA)<- c("Matrix A")

MatListB<-list(tempMat[[4]][[1]])  #varies depending on number of matrices - need to find a way to code this better - now have five matrices available so need to sort this
AllMatB<-unlist(MatListB)
matricesB<-matrix(AllMatB, ncol=length(MatListB))
colnames(matricesB)<- c("Matrix B")


matrices<-cbind(matrices, matricesA, matricesB)


    #not yet active in demoniche

stages<-comadre$matrixClass[keep][[2]]$MatrixClassAuthor
#stages<-comadre$matrixClass[keep][[2]]$MatrixClassAuthor
#stagesf<-stages[1:3]
proportion_initial<- rep(1/length(stages), length(stages)) #Think spin up sorts this
sumweight<-rep(1, length(stages))#weight of stages  - should be equal for all mine just
#in plants seed not included in calculating population sizes
list_names_matrices<-colnames(matrices)
K_weight<-c(rep(1, length(stages)))  #the weight with which carrying capacity affects each stage was FALSE

```


```{r Scaling Carrying Capacity, cache=TRUE, message=FALSE, warning=FALSE,  echo=FALSE}

#Scaling carrying capacity (as estimated above) in three different ways, linear, sigmoidal and linear threshold.
#plotting functions linking k and hsi

lin<-function(x){
  x*carry_k
  }

sig<-function(x){
  carry_k*(1/(1+exp(-10*x+5)))
  }   #could also try with 18x + 9 - closer to SM in Damaris paper

lt<-function(x) {
  val = (4/3) * x - (1/3)
  val[x < 0.25] = 0
  val<-val*carry_k
  return(val)
}
```


#carrying capacity function
```{r, warning = FALSE, message = FALSE}
lf<-list.files(sdm_folder)

files<-lf[grepl("^weighted_ensemble_sdm_.*.tif$", lf)]

sdms<-stack(paste(sdm_folder, files, sep="/"))
#sdms<-projectRaster(sdms, crs = "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs")

hsi<-raster:::extract(sdms, Populations[,c(2,3)])


link<-lin(hsi)
#sigk<-sig(hsi)
#ltk<-lt(hsi)

spin<-replicate(length(spin_years),link[,1])
link_spin<-cbind(spin, link)

colnames(link_spin)[1:length(spin_years)]<-paste("weighted_ensemble_sdm_", spin_years, sep="")


Populations<-Populations[-which(is.na(link_spin)[,1]),]
link_spin<-link_spin[-which(is.na(link_spin)[,1]),]


```

####Varying standard deviation of population matrix, long distance dispersal and kernel shape


Changed the demoniche_setup function (now demoniche_setup_me.R) to change the dispersal function to a decay curve where the half-life is the median estimated dispersal distance.This was based on Bowman et al 2012 where it suggests that the maximum dispersal is 40x the square root of a species home range and median dispersal is 7x the square root of HR.



```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
reps<-12
for (s in 1:nrow(var_grid)){

  print(paste (s, " out of ", nrow(var_grid) ), sep="")

  SD<-var_grid[s,1]
  LDD<-var_grid[s,2]


  matrices_var<-matrix(SD, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd"))

start.time <- Sys.time()

 max_disp<-as.character(kern_mat[s,1])
  dir.create(paste(demoniche_folder,"/new_patch_disp_test_",max_disp,sep=""),showWarnings = TRUE)


rep_demoniche<-function(i){
  library(demoniche)
  library(doParallel)
  source("demoniche_setup_me.R")
  source("demoniche_model_me.R")
  source("demoniche_dispersal_me.R")
  source("demoniche_population_function.R")
 demoniche_setup(modelname = binomial ,Populations = Populations, Nichemap = patch_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = density_mine,
                  fraction_LDD = 0.5, fraction_SDD = 0.5,
                  dispersal_constants = kern_mat[s,],
                transition_affected_niche = transition_affected_niche,
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=link_spin, Kweight = K_weight, Ktype="ceiling",
                  sumweight =sumweight)


c_ibex_k_16000 <- demoniche_model_me(modelname = binomial, Niche = TRUE,
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste(binomial,"/Demoniche_Output/new_patch_disp_test_",max_disp,"/",i,sep=""))



    }


if (Sys.info()["nodename"] == "FIONA-PC"){
 cl <- makeCluster(4)
} else {
 cl <- makeCluster(2)
}


registerDoParallel(cl)
foreach(i=(1:reps)) %dopar% rep_demoniche(i)
stopCluster(cl)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
}


```

```{r,message=FALSE, warning=FALSE, echo=FALSE}

 rep_df_all<-data.frame()
 plot_rep<-function(proj_path){

  load(proj_path)
  id<-gsub(paste(demoniche_folder, "/new_patch_disp_test_", sep=""), "", proj_path)
  id<-gsub("Projection_rep1_Reference_matrix.rda", "",id)
  md_id<-strsplit(id, "/")[[1]][1]
  rep_id<- gsub(".*[/]([^/]+)[/]*", "\\1", id)
  p<-Projection
  trend<-colSums(p[1,1,1:length(p[1,1,,1]),])
  tid<-cbind(md_id, rep_id, trend)
  return(tid)
  }

#wd_new<-paste(wd, "/Demoniche_Repetitions/Kern_kap_new/", sep="")

folders<-list.files(demoniche_folder)
#folders<-folders[1:4]

for (folder in folders){

  print(folder)

  f<-paste(demoniche_folder,folder, sep="/")

  lf<-list.dirs(f, recursive = F)

  path<-paste(lf,"/Projection_rep1_Reference_matrix.rda", sep="")

  reps<-lapply(path, plot_rep)
  rep_df<-do.call(rbind,reps)
  year<-row.names(rep_df)
  rep_df<-data.frame(rep_df)
  rep_df$year<-as.numeric(gsub("Year_", "", year),warnings=FALSE)
  rep_df$md_id<-as.factor(rep_df$md_id)
  rep_df_short<-rep_df[rep_df$year >=1950,]
  rep_df_all<-rbind(rep_df,rep_df_all)
  
  
}

write.csv(rep_df_all, paste(species_directory, "my_disp_function_test.csv", sep="/"))
```

```{r, message=FALSE, warning=FALSE}

#rep_df_all<-read.csv(paste(species_directory, "kern_kap_new_params_0_5sd.csv", sep="/"))
#rep_df_all<-read.csv(paste(species_directory, "my_disp_function.csv", sep="/"))
rep_df_all<-read.csv(paste(species_directory, "my_disp_function_test.csv", sep="/"))
rep_df_all$rep_id<-factor(rep_df_all$rep_id)
rep_df_all$md_id<-factor(rep_df_all$md_id)

rep_df_all$trend<-as.numeric(as.character(rep_df_all$trend))

```


```{r}
library(ggplot2)
p01<-ggplot(rep_df_all, aes(x=year, y=trend, group=interaction(rep_id, md_id),colour=md_id))+
  geom_line()+
   theme(text = element_text(size=9))+
  labs(color='Maximum \ndispersal \ndistance')
p01
```


```{r}

rep_df_small<-rep_df_all[rep_df_all$md_id != "1000"& rep_df_all$year>1949,]
library(ggplot2)

p01<-ggplot(rep_df_small, aes(x=year, y=trend, group=interaction(rep_id, md_id),colour=md_id))+
  geom_line()+
   theme(text = element_text(size=9))+
  labs(color='Maximum \ndispersal \ndistance')
p01
```



```{r}
library(reshape2)

l<-list.files(demoniche_folder)
nf<-length(list.files(paste(demoniche_folder, l[1], sep="/")))

highfoldernames<-list.files(demoniche_folder)
lowfoldernames<-rep(1:nf, each=length(l))

foldernames<-paste(highfoldernames, lowfoldernames, sep="/")

sp_lpi<-lpi[lpi$Binomial == binomial & lpi$Specific_location ==1,]

xy<-data.frame(sp_lpi$Longitude, sp_lpi$Latitude)
coordinates(xy)<-c("sp_lpi.Longitude", "sp_lpi.Latitude")
proj4string(xy) <- CRS("+init=epsg:4326") # WGS 84
#CRS.new <- CRS("+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs")
#xy <- spTransform(xy, CRS.new)

convert_pop_out<-function(foldername){

  pop_out<-read.csv(paste(demoniche_folder ,foldername, "Reference_matrix_pop_output.csv", sep="/"), header = TRUE)
  pop_out<-pop_out[,-1]
  coordinates(pop_out) <- ~ X + Y
  gridded(pop_out) <- TRUE
  rasterDF <- stack(pop_out)
  #proj4string(rasterDF)<-CRS("+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs")
  trends<-raster:::extract(rasterDF,xy)
  max_disp<-strsplit(foldername, "[/_]")[[1]][5]
  rep_id<-strsplit(foldername, "[/_]")[[1]][6]
  trends_df<-data.frame(sp_lpi$ID,max_disp, rep_id,trends)
}

demoniche_pop_out<-lapply(foldernames, convert_pop_out)
df <- do.call("rbind", demoniche_pop_out)
dfm<-as.matrix(df)

lambda<-function(x){

  l10<-10^diff(log10(as.numeric(x[4:length(x)])))

}

dft<-t(apply(dfm,1,lambda))

df_lambda<-data.frame(dfm[,1:3],dft)

colnames(df_lambda)[4:ncol(df_lambda)]<-colnames(dfm)[5:ncol(dfm)]

melt_df<-melt(df, id=1:3)
melt_df$year<-as.numeric(gsub("Year_", "", melt_df$variable))

melt_lambda<-melt(df_lambda, id=1:3)
melt_lambda$year<-as.numeric(gsub("Year_", "", melt_lambda$variable))

melt_short<-melt_df[melt_df$year>spin_years[length(spin_years)] ,]
melt_short$sp_lpi.ID<-as.factor(melt_short$sp_lpi.ID)

melt_lambda_short<-melt_lambda[melt_lambda$year>years[1] ,]
melt_lambda_short$sp_lpi.ID<-as.factor(melt_lambda_short$sp_lpi.ID)

ggplot(melt_short, aes(x= year, y=value, group=interaction(rep_id, max_disp), colour= sp_lpi.ID))+
  geom_line()+
  facet_grid(max_disp~ sp_lpi.ID)

ggplot(melt_lambda_short, aes(x= year, y=value, group=interaction(rep_id, max_disp), colour= sp_lpi.ID))+
  geom_line()+
  facet_grid(max_disp~ sp_lpi.ID)



```

```{r Removing unlimited dispersal}

melt_short<-melt_short[melt_short$max_disp != "13.5975" ,]

melt_lambda_short<-melt_lambda_short[melt_lambda_short$max_disp != "13.5975",]

ddply(melt_lambda_short, .(max_disp, sp_lpi.ID), summarize, foo = sum(value))

melt_lambda_short<-melt_lambda_short[melt_lambda_short$max_disp != "15.141875"& melt_lambda_short$sp_lpi.ID != "10710",]

```



```{r, message=FALSE , warning=FALSE}

library(taRifx)
library(plyr)
library(mgcv)

pops<-sp_lpi[,c(1,65:130)]
colnames(pops)[2:ncol(pops)]<-paste("Year", 1950:2015, sep="_")
pops[pops=="NULL"]<-NA
pops$rep_id<-"Observed"
pops$md_id<-"Observed"

popsm<-as.matrix(pops)

gam_lpi<-function(x){
   #subsetting the population data by each population
  spid = x[2:(length(x)-2)]                     #subsetting only the dates
  names(spid)<-1950:2015              #renaming the date column names as R doesn't like numbered column names
  spid<-as.numeric(spid)
  pop_datab <- (!is.na(spid) )
  points = sum(pop_datab)
  id<-x[1]
  Date<-1950:2015
  spidt<-destring(t(spid))
  time<-length(min(which(!is.na(spidt))):max(which(!is.na(spidt))))
  missing<-time-points

  Year<-Date[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population<-spidt[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population[Population == 0] <- mean(Population, na.rm=TRUE)*0.01 #if a population is zero one year thhis is replaced with 1% of the average population estimate - because you can log zeros

  df<-data.frame(Year,Population)

  #not sure what this does - adding a constant of 1 so that logging doesn't go weird?
  if (sum(na.omit(df$Population<1))>0) {
    df$Population<-df$Population+1
  }


  if (points >=6) {
    PopN = df$Population
    if (length(na.omit(PopN)) >=6) {
      SmoothParm = round(length(na.omit(PopN))/2)
    } else {
      SmoothParm=3
    }

    mg2<-mgcv:::gam(PopN ~ s(Year, k=SmoothParm), fx=TRUE)
    pv2 <- predict(mg2,df,type="response",se=TRUE)
    R_sq2<-summary(mg2)$r.sq
    model<-1
    pv2$fit[pv2$fit <= 0] <- NA


    lambda2<-pv2$fit

    ial<-data.frame(id, Year,lambda2)

    colnames(ial)<-c("ID", "Year", "Abundance")
  }

  return(ial)
}

gam_lpi_r<-apply(popsm,  1, gam_lpi)
gam_r<-do.call( "rbind", gam_lpi_r)

fill<-data.frame(rep(pops$ID, each=length(1950:2015)), 1950:2015)
colnames(fill)<-c("ID", "Year")

all_year_ab<-join(fill, gam_r, type="right")

all_year_ab$max_disp<-"Observed"
all_year_ab$rep_id<-"Observed"

colnames(all_year_ab)[1:3]<-c("sp_lpi.ID", "year", "value")


```

```{r}
mldab<-melt_short[,-4]
all_year_ab$sp_lpi.ID<-as.factor(all_year_ab$sp_lpi.ID)
all_year_ab$max_disp<-as.factor(all_year_ab$max_disp)
all_year_ab$rep_id<-as.factor(all_year_ab$rep_id)
all_year_ab$value<-as.numeric(all_year_ab$value)
all_year_ab$year<-as.numeric(all_year_ab$year)


both_df_ab<-rbind(mldab, all_year_ab)

both_df_ab[both_df_ab$sp_lpi.ID == "  539",]$sp_lpi.ID<-539

```

```{r}
library(mgcv)

gam_demon<-function(id){
#for (i in 1:length(unique(melt_short$sp_lpi.ID))){

  #id<-unique(melt_short$sp_lpi.ID)[i]

  df<-melt_short[melt_short$sp_lpi.ID ==id,]
  PopN = df$value
  Year = df$year
  max_disp = df$max_disp
  rep_id = df$rep_id
  SmoothParm = round(length(na.omit(PopN))/2)

  mg2<-mgcv:::gam(PopN ~ s(Year, k=15), fx=TRUE)
  pv2<-unique(fitted.values(mg2))

  ial<-data.frame(id, unique(Year),pv2)

  colnames(ial)<-c("sp_lpi.ID", "Year", "Abundance")
  #print(id)
  return(ial)
    }



gam_demon_r<-lapply(unique(melt_short$sp_lpi.ID), gam_demon)
gam_r<-do.call( "rbind", gam_demon_r)


```

```{r}


library(mgcv)

gam_demon<-function(id){
  df<-melt_lambda_short[melt_lambda_short$sp_lpi.ID ==id,]
  PopN = df$value
  Year = df$year
  max_disp = df$max_disp
  rep_id = df$rep_id
  SmoothParm = round(length(na.omit(PopN))/2)

  mg2<-mgcv:::gam(PopN ~ s(Year, k=10), fx=TRUE)
  pv2<-unique(fitted.values(mg2))

  ial<-data.frame(id, unique(Year),pv2)

  colnames(ial)<-c("sp_lpi.ID", "Year", "Abundance")
  return(ial)
    }

gam_demon_r_lambda<-lapply(unique(melt_lambda_short$sp_lpi.ID), gam_demon)
gam_r_lambda<-do.call( "rbind", gam_demon_r_lambda)



```


```{r}
library(ggplot2)


ggplot(mldab, aes(x= year, y=value, group=interaction(rep_id, max_disp, sp_lpi.ID), colour= sp_lpi.ID))+
  geom_line(colour="grey")+
  geom_line(data=both_df_ab[both_df_ab$max_disp=="Observed",], aes(x=year, y=value), colour="red")+
  geom_line(data =  gam_r, aes(x =Year, y = Abundance, group=sp_lpi.ID), colour = "blue" )+
  facet_grid(.~ sp_lpi.ID)


```

```{r, warning=FALSE, message=FALSE}


pops<-sp_lpi[,c(1,65:130)]
colnames(pops)[2:ncol(pops)]<-paste("Year", 1950:2015, sep="_")
pops[pops=="NULL"]<-NA
pops$rep_id<-"Observed"
pops$md_id<-"Observed"

library(taRifx)
popsm<-as.matrix(pops)

gam_lpi<-function(x){
   #subsetting the population data by each population
  spid = x[2:(length(x)-2)]                     #subsetting only the dates
  names(spid)<-1950:2015              #renaming the date column names as R doesn't like numbered column names
  spid<-as.numeric(spid)
  pop_datab <- (!is.na(spid) )
  points = sum(pop_datab)
  id<-x[1]
  Date<-1950:2015
  spidt<-destring(t(spid))
  time<-length(min(which(!is.na(spidt))):max(which(!is.na(spidt))))
  missing<-time-points

  Year<-Date[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population<-spidt[min(which(!is.na(spidt))):max(which(!is.na(spidt)))]
  Population[Population == 0] <- mean(Population, na.rm=TRUE)*0.01 #if a population is zero one year thhis is replaced with 1% of the average population estimate - because you can log zeros

  df<-data.frame(Year,Population)

  #not sure what this does - adding a constant of 1 so that logging doesn't go weird?
  if (sum(na.omit(df$Population<1))>0) {
    df$Population<-df$Population+1
  }


  if (points >=6) {
    PopN = log10(df$Population)
    if (length(na.omit(PopN)) >=6) {
      SmoothParm = round(length(na.omit(PopN))/2)
    } else {
      SmoothParm=3
    }

    mg2<-mgcv:::gam(PopN ~ s(Year, k=SmoothParm), fx=TRUE)
    pv2 <- predict(mg2,df,type="response",se=TRUE)
    R_sq2<-summary(mg2)$r.sq
    model<-1
    pv2$fit[pv2$fit <= 0] <- NA


    lambda2<-diff(pv2$fit)

    ial<-data.frame(id, Year[-length(Year)], 10^lambda2)

    colnames(ial)<-c("ID", "Year", "R")
  }

  return(ial)
}

gam_lpi_r<-apply(popsm,  1, gam_lpi)
gam_r<-do.call( "rbind", gam_lpi_r)

fill<-data.frame(rep(pops$ID, each=length(1950:2015)), 1950:2015)
colnames(fill)<-c("ID", "Year")

all_year_r<-join(fill, gam_r, type="right")

all_year_r$max_disp<-"Observed"
all_year_r$rep_id<-"Observed"

colnames(all_year_r)[1:3]<-c("sp_lpi.ID", "year", "value")

```



```{r}

mld<-melt_lambda_short[,-4]
all_year_r$sp_lpi.ID<-as.factor(all_year_r$sp_lpi.ID)
all_year_r$max_disp<-as.factor(all_year_r$max_disp)
all_year_r$rep_id<-as.factor(all_year_r$rep_id)
all_year_r$value<-as.numeric(all_year_r$value)
all_year_r$year<-as.numeric(all_year_r$year)


both_df<-rbind(mld, all_year_r)

```


need to add in x axis. do plots separately for each of the dispersal options?
```{r}
library(ggplot2)

both_df<-both_df[both_df$max_disp != "1000",]




ggplot(both_df, aes(x= year, y=value, group=interaction(rep_id, max_disp,sp_lpi.ID), colour= sp_lpi.ID))+
  geom_line(colour="grey")+
  geom_line(data=both_df[both_df$max_disp=="Observed",], aes(x=year, y=value), colour="red")+
  geom_line(data =  gam_r_lambda, aes(x =Year, y = Abundance, group=sp_lpi.ID), colour = "blue" )+
  facet_grid(.~ sp_lpi.ID)


for (i in 1:length(unique(both_df$sp_lpi.ID))){
pp<-ggplot(both_df[both_df$sp_lpi.ID == unique(both_df$sp_lpi.ID)[i],], aes(x= year, y=value, group=interaction(rep_id, max_disp)))+
  geom_line(colour="grey")+
  geom_line(data=both_df[both_df$max_disp=="Observed" & both_df$sp_lpi.ID == both_df$sp_lpi.ID[i],], aes(x=year, y=value), colour="red")+
  geom_line(data =  gam_r_lambda[gam_r_lambda$sp_lpi.ID ==gam_r_lambda$sp_lpi.ID[i], ], aes(x =Year, y = Abundance, group=sp_lpi.ID), colour = "blue" )
plot(pp)
}

```

Raster population plots
```{r}
patch<-stack(paste(sdm_folder, "/pres_abs_sss_weighted_ensemble_sdm_", years,".tif", sep=""))
plot(patch[[s]])
#patch<-projectRaster(patch, crs = "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs")

raster_read<-function(x){
  b<-read.csv(paste(demoniche_folder ,"new_patch_disp_test_19.775/",x,"/Reference_matrix_pop_output.csv", sep="/"))
  bef_ab_map<-rasterize(b[,c(1,2)],patch,b[,-c(1,2)])
  return(bef_ab_map)
}

all_rep_stack<-lapply(1:12, raster_read)
big_stack<-stack(unlist(all_rep_stack))

year_seq<-seq(1, nlayers(big_stack),(nlayers(big_stack)/length(all_rep_stack)))

all_years_stack<-stack()
year_seq<-seq(1, nlayers(big_stack),(nlayers(big_stack)/length(all_rep_stack)))
for(i in 1:((nlayers(big_stack)/length(all_rep_stack)))-1){
  year_avg<-mean(big_stack[[year_seq]])
  all_years_stack<-stack(all_years_stack, year_avg)
  year_seq<-year_seq+1
  print(year_seq[1])
}

writeRaster(all_years_stack, "Alpine_Ibex_Projection_disp_old.tif", overwrite=T)

#b<-read.csv(paste(demoniche_folder ,"new_patch_disp_113000/1/Reference_matrix_pop_output.csv", sep="/"))
#b<-b[,-1]
#bef_ab_map<-rasterize(b[,c(1,2)],rid,b[,-c(1,2)] )
#plot(bef_ab_map[[1]])
#plot(bef_ab_map[[100:167]])
#bef_ab_map_proj<-bef_ab_map[[100:167]]
#writeRaster(bef_ab_map_proj, "Alpine_Ibex_Projection.tif")
```

![](alpine_ibex.gif)


#ignore vvv

####Using simulated habitat data

Basing the models on environmental data where the trend is known and constant - to better understand the impacts of the other variables.

```{r, message=FALSE, warning=FALSE, cache=TRUE, eval=FALSE}

plot(years_short,colMeans(na.omit(fake_map_mine)[4:length(colnames(fake_map_mine))]), type="l", ylab="Mean fake suitability index")

#setwd("C:Users/Fiona/Documents/Demoniche")

sd_seq<-c(0.5, 0.75,1, 1.25, 1.5)
#matrices_var<-matrix(0.45, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd"))
#k_seq<-c(1000,2000,4000,8000,16000,32000)
LDD_seq<-c(0.1, 0.5, 0.9)
kern_seq<-list(c(0.5,1,1,1),c(0.5,1,1,5), c(1,1,1,1), c(1,1,1,5))

var_grid<-expand.grid(sd_seq, LDD_seq, kern_seq)
colnames(var_grid)<-c("SD", "LDD", "Kern")

kern_mat<-matrix(c(rep(c(0.5,1,1,1), (nrow(var_grid)/length(unique(kern_seq)))),rep(c(0.5,1,1,5), (nrow(var_grid)/length(unique(kern_seq)))),rep(c(1,1,1,1),(nrow(var_grid)/length(unique(kern_seq)))),rep(c(1,1,1,5), (nrow(var_grid)/length(unique(kern_seq))))), ncol=4, byrow=T)


for (s in 1:nrow(var_grid)){

  print(paste (s, " out of ", nrow(var_grid) ), sep="")

  SD<-var_grid[s,1]
  LDD<-var_grid[s,2]


  matrices_var<-matrix(SD, ncol = 1, nrow = nrow(matrices), dimnames = list(NULL, "sd"))

start.time <- Sys.time()

dir.create(paste("D:/Fiona/Git_Method/Git_Method/Demoniche_Repetitions/Fake_Three_Vars_kern/Kern_", s,"LDD_",LDD,"SD_", SD,sep=""))

reps<-5

rep_demoniche<-function(i){
  library(demoniche)
  source("demoniche_model_me.R")
 demoniche_setup(modelname = "Capra_k_16000",Populations = Populations, Nichemap = fake_spin_up,
                matrices = matrices,matrices_var = matrices_var, prob_scenario = prob_scenario,
                  stages = stages, proportion_initial = proportion_initial,
                  density_individuals = 400,  #number of individuals at the start of each population - can be a vector of length(Populations)
                  fraction_LDD = LDD, fraction_SDD = 0.5,
                  dispersal_constants = kern_mat[i,],
                  transition_affected_niche = "all",
                  transition_affected_demogr = transition_affected_demogr,
                  transition_affected_env=transition_affected_env,
                  env_stochas_type = env_stochas_type,
                  no_yrs = no_yrs_mine, K=2000, Kweight = K_weight,
                  sumweight =sumweight)
c_ibex_k_16000 <- demoniche_model_me(modelname = "Capra_k_16000", Niche = TRUE,
                                     Dispersal = TRUE, repetitions = 1,
                                     foldername = paste("Demoniche_Repetitions/Fake_Three_Vars_kern/Kern_", s,"LDD_",LDD,"SD_", SD,"/rep",i,sep=""))
}


#lapply(1:reps, rep_demoniche)

library(doParallel)

if (Sys.info()["nodename"] == "FIONA-PC"){
 cl <- makeCluster(4)
} else {
 cl <- makeCluster(2)
}


registerDoParallel(cl)
foreach(i=(1:reps)) %dopar% rep_demoniche(i)
stopCluster(cl)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
}

```


* Scaling population matrices to habitat suitability – only have one stage matrix from a particular point in time
*	Other matrices are just transition matrices but available in good and bad conditions, use these to great upper and lower bounds of survival? – need to check location, date and existence of these matrices

*	Noise is currently not supported but a value of 1 imputes white noise, and values higher or lower than this give positive or negative temporal autocorrelation – more important when you have multiple matrices?

*	Transition_affected_niche has more impact when specified values are inputted – if(is.numeric(transition_affected_niche){}

*	Transition affected niche pulls out parts of the matrix that are multiplied by the niche value – so if just presence/absence then it is either no change or 0

*	Potential problem with the way I have seeded the model – only ibex in the original populations whereas it might be more accurate to seed ibex more widely and then just sample from the original population sites.

* Calculate dispersal kernel from gps data?

* Density_individuals  = is the starting populations for each locations that is "seeded" in Populations

* Proportion_initial is how density individual is divided between stages, e.g all juveniles or  evenly spread etc

* Need to check if you can run multiple matrices_var in one run
